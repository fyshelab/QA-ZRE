{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on http://nlp.cs.washington.edu/zeroshot/evaluate.py\n",
    "import pandas as pd\n",
    "import os\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "PUNCTUATION = set(string.punctuation)\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_latin(text):\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r'', text)\n",
    "\n",
    "def unk_zero_re_eval(test_file, answer_file):\n",
    "    q_aprf = unk_read_results(test_file, answer_file)\n",
    "    return pretify(q_aprf)\n",
    "\n",
    "def unk_read_results(test_set, answer_file):\n",
    "    with codecs.open(test_set, \"r\", \"utf-8\") as fin:\n",
    "        data = [line.strip().split(\"\\t\") for line in fin]\n",
    "    metadata = [x[:4] for x in data]\n",
    "    gold = [set(x[4:]) for x in data]\n",
    "\n",
    "    with codecs.open(answer_file, \"r\", \"utf-8\") as fin:\n",
    "        answers = [line.strip() for line in fin]\n",
    "\n",
    "    new_answers = []\n",
    "    for answer in answers[1:]:\n",
    "        if answer != \"no_answer\":\n",
    "            new_answers.append(answer)\n",
    "        else:\n",
    "            new_answers.append(\"\")\n",
    "\n",
    "    telemetry = []\n",
    "    for m, g, a in zip(metadata, gold, new_answers):\n",
    "        stats = score(g, a)\n",
    "        telemetry.append([m[0], m[1], str(len(g) > 0), stats])\n",
    "    return aprf(telemetry)\n",
    "\n",
    "def parse_no_answers(results):\n",
    "    p_answer = [\n",
    "        a for i, a in sorted([(int(i), a) for i, a in results[0][\"scores\"].items()])\n",
    "    ]\n",
    "    p_no_answer = [\n",
    "        a for i, a in sorted([(int(i), a) for i, a in results[0][\"na\"].items()])\n",
    "    ]\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    return [answer > no_answer for answer, no_answer in zip(p_answer, p_no_answer)]\n",
    "\n",
    "\n",
    "def gb(collection, keyfunc):\n",
    "    return [(k, list(g)) for k, g in groupby(sorted(collection, key=keyfunc), keyfunc)]\n",
    "\n",
    "\n",
    "def aprf(g):\n",
    "    tp, tn, sys_pos, real_pos = sum(map(lambda x: x[-1], g))\n",
    "    total = len(g)\n",
    "    # a = float(tp + tn) / total\n",
    "    # nr = tn / float(total - real_pos)\n",
    "    # npr = tn / float(total - sys_pos)\n",
    "    if tp == 0:\n",
    "        p = r = f = 0.0\n",
    "    else:\n",
    "        p = tp / float(sys_pos)\n",
    "        r = tp / float(real_pos)\n",
    "        f = 2 * p * r / (p + r)\n",
    "    # return np.array((a, p, r, f, npr, nr))\n",
    "    return np.array((p, r, f))\n",
    "\n",
    "\n",
    "def score(gold, answer):\n",
    "    if len(gold) > 0:\n",
    "        gold = set.union(*[simplify(g) for g in gold])\n",
    "    answer = simplify(answer)\n",
    "    result = np.zeros(4)\n",
    "    if answer == gold:\n",
    "        if len(gold) > 0:\n",
    "            result[0] += 1\n",
    "        else:\n",
    "            result[1] += 1\n",
    "    if len(answer) > 0:\n",
    "        result[2] += 1\n",
    "    if len(gold) > 0:\n",
    "        result[3] += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def simplify(answer):\n",
    "    return set(\n",
    "        \"\".join(c for c in t if c not in PUNCTUATION)\n",
    "        for t in answer.strip().lower().split()\n",
    "    ) - {\"the\", \"a\", \"an\", \"and\", \"\"}\n",
    "\n",
    "\n",
    "def pretify(results):\n",
    "    return \" \\t \".join(\n",
    "        [\n",
    "            \": \".join((k, v))\n",
    "            for k, v in zip(\n",
    "                [\"Precision\", \"Recall\", \"F1\"],\n",
    "                map(lambda r: \"{0:.2f}%\".format(r * 100), results),\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "device = \"cuda\"\n",
    "model_id = \"gpt2-large\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def compute_perplexity_for_questions(main_path, file):\n",
    "    ppls = []\n",
    "    df = pd.read_csv(os.path.join(main_path, file), sep=',')\n",
    "    questions = df[\"question_predictions\"].tolist()\n",
    "    for question in questions:\n",
    "        encodings = tokenizer(question, return_tensors=\"pt\")\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        b_sz, length = input_ids.size()\n",
    "        target_ids = input_ids.clone()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            neg_log_likelihood = outputs[0]\n",
    "            ppl = torch.exp(neg_log_likelihood)\n",
    "        ppls.append(ppl)\n",
    "    ppl = torch.stack(ppls).mean()\n",
    "    return ppl\n",
    "\n",
    "def gold_compute_perplexity_for_questions(main_path, file):\n",
    "    ppls = []\n",
    "    df = pd.read_csv(os.path.join(main_path, file), sep=',')\n",
    "    inputs = df[\"input_str\"].tolist()\n",
    "    for inp in inputs:\n",
    "        question = inp.split(\"context:\")[0].replace(\"question:\", \"\").strip()\n",
    "        encodings = tokenizer(question, return_tensors=\"pt\")\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        b_sz, length = input_ids.size()\n",
    "        target_ids = input_ids.clone()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            neg_log_likelihood = outputs[0]\n",
    "            ppl = torch.exp(neg_log_likelihood)\n",
    "        ppls.append(ppl)\n",
    "    ppl = torch.stack(ppls).mean()\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_the_prediction_files(main_path, list_of_files):\n",
    "    for file in list_of_files:\n",
    "        df = pd.read_csv(os.path.join(main_path, file), sep=',')\n",
    "        df[\"predictions_str\"].to_csv(os.path.join(\"/tmp/\", file), sep='\\t', header=True, index=False)\n",
    "\n",
    "def unk_eval_the_prediction_files(list_of_files, gold_file):\n",
    "    scores = {}\n",
    "    scores_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    for file in list_of_files:\n",
    "        score = unk_zero_re_eval(gold_file, os.path.join(\"/tmp/\", file))\n",
    "        arr = score.split()\n",
    "        f1_score = float(arr[-1][0:-1])\n",
    "        precision = float(arr[1][0:-1])\n",
    "        recall = float(arr[3][0:-1])\n",
    "        scores[f1_score] = file\n",
    "        scores_list.append(f1_score)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "    f1s = np.array(scores_list)\n",
    "    precisions = np.array(precision_list)\n",
    "    recalls = np.array(recall_list)\n",
    "    max_f1 = max(scores.keys())\n",
    "    return scores[max_f1],  max_f1, f1s, scores, precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for fold_i in range(1, 11, 1):\n",
    "    results[fold_i] = {'mml-pgg-off-sim': {},\n",
    "                       'mml-pgg-on-sim': {},\n",
    "                       'mml-mml-off-sim': {},\n",
    "                       'mml-mml-on-sim': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mml-pgg-off-sim 1 mml-pgg-off-sim.fold.1.dev.predictions.step.500.csv 49.45\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 1 mml-pgg-on-sim.fold.1.dev.predictions.step.300.csv 53.57\n",
      "\n",
      "\n",
      "mml-mml-off-sim 1 mml-mml-off-sim.fold.1.dev.predictions.step.500.csv 48.79\n",
      "\n",
      "\n",
      "mml-mml-on-sim 1 mml-mml-on-sim.fold.1.dev.predictions.step.8900.csv 50.56\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 2 mml-pgg-off-sim.fold.2.dev.predictions.step.9300.csv 64.03\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 2 mml-pgg-on-sim.dev.predictions.fold.2.step.9200.csv 62.0\n",
      "\n",
      "\n",
      "mml-mml-off-sim 2 mml-mml-off-sim.dev.predictions.fold.2.step.9300.csv 64.77\n",
      "\n",
      "\n",
      "mml-mml-on-sim 2 mml-mml-on-sim.dev.predictions.fold.2.step.9400.csv 62.34\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 3 mml-pgg-off-sim.fold.3.dev.predictions.step.5300.csv 58.42\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 3 mml-pgg-on-sim.dev.predictions.fold.3.step.300.csv 57.72\n",
      "\n",
      "\n",
      "mml-mml-off-sim 3 mml-mml-off-sim.dev.predictions.fold.3.step.3800.csv 59.03\n",
      "\n",
      "\n",
      "mml-mml-on-sim 3 mml-mml-on-sim.dev.predictions.fold.3.step.2000.csv 61.22\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 4 mml-pgg-off-sim.fold.4.dev.predictions.step.1100.csv 67.0\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 4 mml-pgg-on-sim.dev.predictions.fold.4.step.500.csv 65.9\n",
      "\n",
      "\n",
      "mml-mml-off-sim 4 mml-mml-off-sim.dev.predictions.fold.4.step.2300.csv 66.22\n",
      "\n",
      "\n",
      "mml-mml-on-sim 4 mml-mml-on-sim.dev.predictions.fold.4.step.4200.csv 65.58\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 5 mml-pgg-off-sim.fold.5.dev.predictions.step.6400.csv 70.31\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 5 mml-pgg-on-sim.dev.predictions.fold.5.step.12600.csv 67.48\n",
      "\n",
      "\n",
      "mml-mml-off-sim 5 mml-mml-off-sim.dev.predictions.fold.5.step.3000.csv 64.89\n",
      "\n",
      "\n",
      "mml-mml-on-sim 5 mml-mml-on-sim.dev.predictions.fold.5.step.12800.csv 68.98\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 6 mml-pgg-off-sim.fold.6.dev.predictions.step.700.csv 66.1\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 6 mml-pgg-on-sim.dev.predictions.fold.6.step.300.csv 68.18\n",
      "\n",
      "\n",
      "mml-mml-off-sim 6 mml-mml-off-sim.dev.predictions.fold.6.step.300.csv 67.46\n",
      "\n",
      "\n",
      "mml-mml-on-sim 6 mml-mml-on-sim.dev.predictions.fold.6.step.2200.csv 66.56\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 7 mml-pgg-off-sim.fold.7.dev.predictions.step.14900.csv 61.15\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 7 mml-pgg-on-sim.dev.predictions.fold.7.step.9800.csv 64.96\n",
      "\n",
      "\n",
      "mml-mml-off-sim 7 mml-mml-off-sim.dev.predictions.fold.7.step.13400.csv 59.66\n",
      "\n",
      "\n",
      "mml-mml-on-sim 7 mml-mml-on-sim.dev.predictions.fold.7.step.16600.csv 61.81\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 8 mml-pgg-off-sim.fold.8.dev.predictions.step.8600.csv 63.73\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 8 mml-pgg-on-sim.dev.predictions.fold.8.step.17000.csv 63.89\n",
      "\n",
      "\n",
      "mml-mml-off-sim 8 mml-mml-off-sim.dev.predictions.fold.8.step.7900.csv 63.78\n",
      "\n",
      "\n",
      "mml-mml-on-sim 8 mml-mml-on-sim.dev.predictions.fold.8.step.7200.csv 60.88\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 9 mml-pgg-off-sim.fold.9.dev.predictions.step.2900.csv 64.04\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 9 mml-pgg-on-sim.dev.predictions.fold.9.step.2300.csv 64.04\n",
      "\n",
      "\n",
      "mml-mml-off-sim 9 mml-mml-off-sim.dev.predictions.fold.9.step.4700.csv 59.57\n",
      "\n",
      "\n",
      "mml-mml-on-sim 9 mml-mml-on-sim.dev.predictions.fold.9.step.1900.csv 62.96\n",
      "\n",
      "\n",
      "NEXT\n",
      "mml-pgg-off-sim 10 mml-pgg-off-sim.fold.10.dev.predictions.step.8600.csv 56.5\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 10 mml-pgg-on-sim.dev.predictions.fold.10.step.4300.csv 55.12\n",
      "\n",
      "\n",
      "mml-mml-off-sim 10 mml-mml-off-sim.dev.predictions.fold.10.step.1500.csv 54.51\n",
      "\n",
      "\n",
      "mml-mml-on-sim 10 mml-mml-on-sim.dev.predictions.fold.10.step.5800.csv 56.43\n",
      "\n",
      "\n",
      "NEXT\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the dev predictions on the RE-QA dataset on fold 1.\n",
    "folders = [\"mml-pgg-off-sim\", \"mml-pgg-on-sim\", \"mml-mml-off-sim\", \"mml-mml-on-sim\"]\n",
    "\n",
    "for fold_i in range(1, 11, 1):\n",
    "    for folder in folders:\n",
    "        fold_gold_file = \"./zero-shot-extraction/relation_splits/dev.{}\".format(fold_i-1)\n",
    "        fold_path = \"~/fold_{}/{}/\".format(fold_i, folder)\n",
    "        if fold_i == 1:\n",
    "            fold_files = [\"{}.fold.{}.dev.predictions.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 101, 1)]\n",
    "        elif 2 <= fold_i <= 4:\n",
    "            if folder == \"mml-pgg-off-sim\":\n",
    "                fold_files = [\"{}.fold.{}.dev.predictions.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 101, 1)]\n",
    "            else:\n",
    "                fold_files = [\"{}.dev.predictions.fold.{}.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 101, 1)]\n",
    "        else:\n",
    "            if folder == \"mml-pgg-off-sim\":\n",
    "                fold_files = [\"{}.fold.{}.dev.predictions.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 201, 1)]\n",
    "            else:\n",
    "                fold_files = [\"{}.dev.predictions.fold.{}.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 201, 1)]\n",
    "    \n",
    "        preprocess_the_prediction_files(fold_path, fold_files)\n",
    "        max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "        print(folder, fold_i, max_file, max_f1)\n",
    "        print(\"\\n\")\n",
    "        results[fold_i][folder] = max_file\n",
    "    print(\"NEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mml-pgg-on-sim 1 mml-pgg-on-sim.fold.1.test.predictions.step.300.csv 59.19\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 2 mml-pgg-on-sim.test.predictions.fold.2.step.9200.csv 44.62\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 3 mml-pgg-on-sim.test.predictions.fold.3.step.300.csv 55.39\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 4 mml-pgg-on-sim.test.predictions.fold.4.step.500.csv 61.62\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 5 mml-pgg-on-sim.test.predictions.fold.5.step.12600.csv 53.77\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 6 mml-pgg-on-sim.test.predictions.fold.6.step.300.csv 55.71\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 7 mml-pgg-on-sim.test.predictions.fold.7.step.9800.csv 59.5\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 8 mml-pgg-on-sim.test.predictions.fold.8.step.17000.csv 56.03\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 9 mml-pgg-on-sim.test.predictions.fold.9.step.2300.csv 51.6\n",
      "\n",
      "\n",
      "mml-pgg-on-sim 10 mml-pgg-on-sim.test.predictions.fold.10.step.4300.csv 47.59\n",
      "\n",
      "\n",
      "mml-pgg-on-sim f1 54.501999999999995\n",
      "mml-pgg-on-sim p 57.011\n",
      "mml-pgg-on-sim r 52.552\n",
      "NEXT\n",
      "mml-mml-off-sim 1 mml-mml-off-sim.fold.1.test.predictions.step.500.csv 63.37\n",
      "\n",
      "\n",
      "mml-mml-off-sim 2 mml-mml-off-sim.test.predictions.fold.2.step.9300.csv 43.18\n",
      "\n",
      "\n",
      "mml-mml-off-sim 3 mml-mml-off-sim.test.predictions.fold.3.step.3800.csv 57.6\n",
      "\n",
      "\n",
      "mml-mml-off-sim 4 mml-mml-off-sim.test.predictions.fold.4.step.2300.csv 61.05\n",
      "\n",
      "\n",
      "mml-mml-off-sim 5 mml-mml-off-sim.test.predictions.fold.5.step.3000.csv 56.35\n",
      "\n",
      "\n",
      "mml-mml-off-sim 6 mml-mml-off-sim.test.predictions.fold.6.step.300.csv 56.39\n",
      "\n",
      "\n",
      "mml-mml-off-sim 7 mml-mml-off-sim.test.predictions.fold.7.step.13400.csv 52.59\n",
      "\n",
      "\n",
      "mml-mml-off-sim 8 mml-mml-off-sim.test.predictions.fold.8.step.7900.csv 58.98\n",
      "\n",
      "\n",
      "mml-mml-off-sim 9 mml-mml-off-sim.test.predictions.fold.9.step.4700.csv 52.31\n",
      "\n",
      "\n",
      "mml-mml-off-sim 10 mml-mml-off-sim.test.predictions.fold.10.step.1500.csv 55.38\n",
      "\n",
      "\n",
      "mml-mml-off-sim f1 55.720000000000006\n",
      "mml-mml-off-sim p 60.55500000000001\n",
      "mml-mml-off-sim r 52.08299999999999\n",
      "NEXT\n",
      "mml-mml-on-sim 1 mml-mml-on-sim.fold.1.test.predictions.step.8900.csv 60.52\n",
      "\n",
      "\n",
      "mml-mml-on-sim 2 mml-mml-on-sim.test.predictions.fold.2.step.9400.csv 42.82\n",
      "\n",
      "\n",
      "mml-mml-on-sim 3 mml-mml-on-sim.test.predictions.fold.3.step.2000.csv 55.83\n",
      "\n",
      "\n",
      "mml-mml-on-sim 4 mml-mml-on-sim.test.predictions.fold.4.step.4200.csv 54.76\n",
      "\n",
      "\n",
      "mml-mml-on-sim 5 mml-mml-on-sim.test.predictions.fold.5.step.12800.csv 53.28\n",
      "\n",
      "\n",
      "mml-mml-on-sim 6 mml-mml-on-sim.test.predictions.fold.6.step.2200.csv 56.3\n",
      "\n",
      "\n",
      "mml-mml-on-sim 7 mml-mml-on-sim.test.predictions.fold.7.step.16600.csv 57.62\n",
      "\n",
      "\n",
      "mml-mml-on-sim 8 mml-mml-on-sim.test.predictions.fold.8.step.7200.csv 56.73\n",
      "\n",
      "\n",
      "mml-mml-on-sim 9 mml-mml-on-sim.test.predictions.fold.9.step.1900.csv 54.19\n",
      "\n",
      "\n",
      "mml-mml-on-sim 10 mml-mml-on-sim.test.predictions.fold.10.step.5800.csv 51.58\n",
      "\n",
      "\n",
      "mml-mml-on-sim f1 54.363000000000014\n",
      "mml-mml-on-sim p 57.18499999999999\n",
      "mml-mml-on-sim r 51.931999999999995\n",
      "NEXT\n",
      "mml-pgg-off-sim 1 mml-pgg-off-sim.fold.1.test.predictions.step.500.csv 60.85\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 2 mml-pgg-off-sim.fold.2.test.predictions.step.9300.csv 44.8\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 3 mml-pgg-off-sim.fold.3.test.predictions.step.5300.csv 60.52\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 4 mml-pgg-off-sim.fold.4.test.predictions.step.1100.csv 60.69\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 5 mml-pgg-off-sim.fold.5.test.predictions.step.6400.csv 55.8\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 6 mml-pgg-off-sim.fold.6.test.predictions.step.700.csv 55.91\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 7 mml-pgg-off-sim.fold.7.test.predictions.step.14900.csv 54.86\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 8 mml-pgg-off-sim.fold.8.test.predictions.step.8600.csv 61.41\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 9 mml_pgg_off_sim.test.predictions.step.2900.csv 50.89\n",
      "\n",
      "\n",
      "mml-pgg-off-sim 10 mml-pgg-off-sim.fold.10.test.predictions.step.8600.csv 53.52\n",
      "\n",
      "\n",
      "mml-pgg-off-sim f1 55.925\n",
      "mml-pgg-off-sim p 57.609\n",
      "mml-pgg-off-sim r 54.447\n",
      "NEXT\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the dev predictions on the RE-QA dataset on fold 1.\n",
    "folders = [\"mml-pgg-on-sim\", \"mml-mml-off-sim\", \"mml-mml-on-sim\", \"mml-pgg-off-sim\"]\n",
    "\n",
    "#results[1][\"mml-pgg-off-sim\"] = \"mml-pgg-off-sim.fold.1.test.predictions.step.500.csv\"\n",
    "#results[2][\"mml-pgg-off-sim\"] = \"mml-pgg-off-sim.fold.2.test.predictions.step.22700.csv\"\n",
    "#results[3][\"mml-pgg-off-sim\"] = \"mml-pgg-off-sim.fold.3.test.predictions.step.12400.csv\"\n",
    "#results[4][\"mml-pgg-off-sim\"] = \"mml-pgg-off-sim.fold.4.test.predictions.step.1100.csv\"\n",
    "#results[5][\"mml-pgg-off-sim\"] = \"mml-pgg-off-sim.fold.5.test.predictions.step.6400.csv\"\n",
    "#results[6][\"mml-pgg-off-sim\"] = \"mml-pgg-off-sim.fold.6.test.predictions.step.700.csv\"\n",
    "#results[7][\"mml-pgg-off-sim\"] = \"mml-pgg-off-sim.fold.7.test.predictions.step.14900.csv\"\n",
    "results[9][\"mml-pgg-off-sim\"] = \"mml_pgg_off_sim.test.predictions.step.2900.csv\"\n",
    "#results[8][\"mml-pgg-off-sim\"] = \"mml-pgg-off-sim.fold.8.test.predictions.step.8600.csv\"\n",
    "#results[10][\"mml-pgg-off-sim\"] = \"mml_pgg_off_sim.test.predictions.step.29000.csv\"\n",
    "\n",
    "for folder in folders:\n",
    "    avg_f1 = {\"mml-mml-off-sim\": 0, \"mml-mml-on-sim\": 0, \"mml-pgg-on-sim\": 0, \"mml-pgg-off-sim\": 0}\n",
    "    avg_p = {\"mml-mml-off-sim\": 0, \"mml-mml-on-sim\": 0, \"mml-pgg-on-sim\": 0, \"mml-pgg-off-sim\": 0}\n",
    "    avg_r = {\"mml-mml-off-sim\": 0, \"mml-mml-on-sim\": 0, \"mml-pgg-on-sim\": 0, \"mml-pgg-off-sim\": 0}\n",
    "    for fold_i in range(1, 11, 1):\n",
    "        fold_gold_file = \"./zero-shot-extraction/relation_splits/test.{}\".format(fold_i-1)\n",
    "        fold_path = \"~/fold_{}/{}\".format(fold_i, folder)\n",
    "        fold_files = [results[fold_i][folder].replace(\"dev\", \"test\")]\n",
    "        preprocess_the_prediction_files(fold_path, fold_files)\n",
    "        max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "        print(folder, fold_i, max_file, max_f1)\n",
    "        avg_f1[folder] += max_f1\n",
    "        avg_p[folder] += precisions[0]\n",
    "        avg_r[folder] += recalls[0]\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(folder, \"f1\", avg_f1[folder] / 10.0)\n",
    "    print(folder, \"p\", avg_p[folder] / 10.0)\n",
    "    print(folder, \"r\", avg_r[folder] / 10.0)\n",
    "    print(\"NEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmml-pgg-on-sim.fold.1.test.predictions.step.300.csv tensor(1260.9260, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.2.step.9200.csv tensor(235.0195, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.3.step.300.csv tensor(1381.7130, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.4.step.500.csv tensor(387.9579, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.5.step.12600.csv tensor(132.0265, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.6.step.300.csv tensor(896.1946, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.7.step.9800.csv tensor(2560.6672, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.8.step.17000.csv tensor(132.0265, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.9.step.2300.csv tensor(5997.6045, device='cuda:0')\\nmml-pgg-on-sim.test.predictions.fold.10.step.4300.csv tensor(172.6929, device='cuda:0')\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mml-pgg-on-sim.fold.1.test.predictions.step.300.csv tensor(1260.9260, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.2.step.9200.csv tensor(235.0195, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.3.step.300.csv tensor(1381.7130, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.4.step.500.csv tensor(387.9579, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.5.step.12600.csv tensor(132.0265, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.6.step.300.csv tensor(896.1946, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.7.step.9800.csv tensor(2560.6672, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.8.step.17000.csv tensor(132.0265, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.9.step.2300.csv tensor(5997.6045, device='cuda:0')\n",
    "mml-pgg-on-sim.test.predictions.fold.10.step.4300.csv tensor(172.6929, device='cuda:0')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mml-mml-off-sim.fold.1.test.predictions.step.500.csv tensor(256.7630, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.2.step.9300.csv tensor(113.4473, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.3.step.3800.csv tensor(125.6059, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.4.step.2300.csv tensor(168.9407, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.5.step.3000.csv tensor(226.4696, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.6.step.300.csv tensor(136.6262, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.7.step.13400.csv tensor(181.6257, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.8.step.7900.csv tensor(158.8159, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.9.step.4700.csv tensor(113.4427, device='cuda:0')\n",
      "mml-mml-off-sim.test.predictions.fold.10.step.1500.csv tensor(29.8569, device='cuda:0')\n",
      "\n",
      "\n",
      "mml-mml-off-sim pp tensor(151.1594, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "folders = [\"mml-mml-off-sim\"]\n",
    "\n",
    "for folder in folders:\n",
    "    avg_pp = {\"mml-mml-off-sim\": 0, \"mml-mml-on-sim\": 0, \"mml-pgg-on-sim\": 0, \"mml-pgg-off-sim\": 0}\n",
    "    for fold_i in range(1, 11, 1):\n",
    "        fold_path = \"~/fold_{}/{}\".format(fold_i, folder)\n",
    "        fold_file = results[fold_i][folder].replace(\"dev\", \"test\")\n",
    "        pp = compute_perplexity_for_questions(fold_path, fold_file)\n",
    "        avg_pp[folder] += pp\n",
    "        print(fold_file, pp)\n",
    "    print(\"\\n\")\n",
    "    print(folder, \"pp\", avg_pp[folder] / 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mml-pgg-off-sim.fold.2.test.predictions.step.9300.csv tensor(125.3252, device='cuda:0')\n",
      "mml-pgg-off-sim.fold.3.test.predictions.step.5300.csv tensor(134.4366, device='cuda:0')\n",
      "mml-pgg-off-sim.fold.10.test.predictions.step.8600.csv tensor(162.4130, device='cuda:0')\n",
      "\n",
      "\n",
      "mml-pgg-off-sim pp tensor(42.2175, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "folders = [\"mml-pgg-off-sim\"]\n",
    "\n",
    "for folder in folders:\n",
    "    avg_pp = {\"mml-mml-off-sim\": 0, \"mml-mml-on-sim\": 0, \"mml-pgg-on-sim\": 0, \"mml-pgg-off-sim\": 0}\n",
    "    for fold_i in [2, 3, 10]:\n",
    "        fold_path = \"~/fold_{}/{}\".format(fold_i, folder)\n",
    "        fold_file = results[fold_i][folder].replace(\"dev\", \"test\")\n",
    "        pp = compute_perplexity_for_questions(fold_path, fold_file)\n",
    "        avg_pp[folder] += pp\n",
    "        print(fold_file, pp)\n",
    "    print(\"\\n\")\n",
    "    print(folder, \"pp\", avg_pp[folder] / 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mml-pgg-off-sim.fold.1.test.predictions.step.500.csv tensor(222.5217, device='cuda:0')\n",
    "mml-pgg-off-sim.fold.4.test.predictions.step.1100.csv tensor(156.0715, device='cuda:0')\n",
    "mml-pgg-off-sim.fold.5.test.predictions.step.6400.csv tensor(166.6490, device='cuda:0')\n",
    "mml-pgg-off-sim.fold.6.test.predictions.step.700.csv tensor(124.1455, device='cuda:0')\n",
    "mml-pgg-off-sim.fold.7.test.predictions.step.14900.csv tensor(154.3446, device='cuda:0')\n",
    "mml-pgg-off-sim.fold.8.test.predictions.step.8600.csv tensor(119.3474, device='cuda:0')\n",
    "mml_pgg_off_sim.test.predictions.step.2900.csv tensor(101.8666, device='cuda:0')\n",
    "mml-pgg-off-sim.fold.2.test.predictions.step.9300.csv tensor(125.3252, device='cuda:0')\n",
    "mml-pgg-off-sim.fold.3.test.predictions.step.5300.csv tensor(134.4366, device='cuda:0')\n",
    "mml-pgg-off-sim.fold.10.test.predictions.step.8600.csv tensor(162.4130, device='cuda:0')\n",
    "\n",
    "mml-mml-on-sim.fold.1.test.predictions.step.8900.csv tensor(5113.3140, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.2.step.9400.csv tensor(1238.2205, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.3.step.2000.csv tensor(407.7806, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.4.step.4200.csv tensor(14371.8291, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.5.step.12800.csv tensor(716.9070, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.6.step.2200.csv tensor(30948.2246, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.7.step.16600.csv tensor(2601.8579, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.8.step.7200.csv tensor(42924.8516, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.9.step.1900.csv tensor(1510.6766, device='cuda:0')\n",
    "mml-mml-on-sim.test.predictions.fold.10.step.5800.csv tensor(29.8569, device='cuda:0')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mml-mml-on-sim.test.predictions.fold.10.step.5800.csv tensor(29.8569, device='cuda:0')\n",
      "\n",
      "\n",
      "mml-mml-on-sim pp tensor(2.9857, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "folders = [\"mml-mml-on-sim\"]\n",
    "\n",
    "for folder in folders:\n",
    "    avg_pp = {\"mml-mml-off-sim\": 0, \"mml-mml-on-sim\": 0, \"mml-pgg-on-sim\": 0, \"mml-pgg-off-sim\": 0}\n",
    "    for fold_i in range(10, 11, 1):\n",
    "        fold_path = \"~/fold_{}/{}\".format(fold_i, folder)\n",
    "        fold_file = results[fold_i][folder].replace(\"dev\", \"test\")\n",
    "        pp = compute_perplexity_for_questions(fold_path, fold_file)\n",
    "        avg_pp[folder] += pp\n",
    "        print(fold_file, pp)\n",
    "    print(\"\\n\")\n",
    "    print(folder, \"pp\", avg_pp[folder] / 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_base_fold.1.test.predictions.step.csv tensor(215.8548, device='cuda:0')\n",
      "base_base_fold.2.test.predictions.step.csv tensor(181.5120, device='cuda:0')\n",
      "base_base_fold.3.test.predictions.step.csv tensor(128.0450, device='cuda:0')\n",
      "base_base_fold.4.test.predictions.step.csv tensor(185.9727, device='cuda:0')\n",
      "base_base_fold.5.test.predictions.step.csv tensor(196.0677, device='cuda:0')\n",
      "base_base_fold.6.test.predictions.step.csv tensor(138.5674, device='cuda:0')\n",
      "base_base_fold.7.test.predictions.step.csv tensor(219.6459, device='cuda:0')\n",
      "base_base_fold.8.test.predictions.step.csv tensor(206.5881, device='cuda:0')\n",
      "base_base_fold.9.test.predictions.step.csv tensor(163.6257, device='cuda:0')\n",
      "base_base_fold.10.test.predictions.step.csv tensor(179.0245, device='cuda:0')\n",
      "\n",
      "\n",
      "pp tensor(181.4904, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# PP for the base-base predictions.\n",
    "avg_pp = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    fold_path = \"~/\"\n",
    "    fold_file = \"base_base_fold.{}.test.predictions.step.csv\".format(fold_i)\n",
    "    pp = compute_perplexity_for_questions(fold_path, fold_file)\n",
    "    avg_pp += pp\n",
    "    print(fold_file, pp)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"pp\", avg_pp / 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_fold.1.test.predictions.step..csv tensor(406.0290, device='cuda:0')\n",
      "gold_fold.2.test.predictions.step..csv tensor(505.0843, device='cuda:0')\n",
      "gold_fold.3.test.predictions.step..csv tensor(392.8392, device='cuda:0')\n",
      "gold_fold.4.test.predictions.step..csv tensor(448.9874, device='cuda:0')\n",
      "gold_fold.5.test.predictions.step..csv tensor(483.6721, device='cuda:0')\n",
      "gold_fold.6.test.predictions.step..csv tensor(367.5929, device='cuda:0')\n",
      "gold_fold.7.test.predictions.step..csv tensor(465.3640, device='cuda:0')\n",
      "gold_fold.8.test.predictions.step..csv tensor(483.6915, device='cuda:0')\n",
      "gold_fold.9.test.predictions.step..csv tensor(375.0452, device='cuda:0')\n",
      "gold_fold.10.test.predictions.step..csv tensor(544.9185, device='cuda:0')\n",
      "\n",
      "\n",
      "pp tensor(447.3224, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# PP for the gold predictions.\n",
    "avg_pp = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    fold_path = \"~/\"\n",
    "    fold_file = \"gold_fold.{}.test.predictions.step..csv\".format(fold_i)\n",
    "    pp = gold_compute_perplexity_for_questions(fold_path, fold_file)\n",
    "    avg_pp += pp\n",
    "    print(fold_file, pp)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"pp\", avg_pp / 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/saeednjf/scratch/feb-15-2022-arr/fold_3/mml-pgg-off-sim/mml-pgg-off-sim.fold.3.dev.predictions.step.100.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     fold_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.fold.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.dev.predictions.step.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(folder, fold_i, \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m, \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m---> 12\u001b[0m \u001b[43mpreprocess_the_prediction_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m max_file,  max_f1, f1s, scores, precisions, recalls \u001b[38;5;241m=\u001b[39m unk_eval_the_prediction_files(fold_files, fold_gold_file)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(fold_i, max_file, max_f1)\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mpreprocess_the_prediction_files\u001b[0;34m(main_path, list_of_files)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_the_prediction_files\u001b[39m(main_path, list_of_files):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m list_of_files:\n\u001b[0;32m----> 3\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions_str\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/\u001b[39m\u001b[38;5;124m\"\u001b[39m, file), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/QA-ZRE/env/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/QA-ZRE/env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/QA-ZRE/env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/QA-ZRE/env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/QA-ZRE/env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/QA-ZRE/env/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/saeednjf/scratch/feb-15-2022-arr/fold_3/mml-pgg-off-sim/mml-pgg-off-sim.fold.3.dev.predictions.step.100.csv'"
     ]
    }
   ],
   "source": [
    "# Evaluating the dev predictions on the RE-QA dataset on fold 1.\n",
    "folders = [\"mml-pgg-off-sim\", \"mml-pgg-on-sim\", \"mml-mml-off-sim\", \"mml-mml-on-sim\"]\n",
    "fold_i = 3\n",
    "\n",
    "for folder in folders:\n",
    "    fold_gold_file = \"./zero-shot-extraction/relation_splits/dev.{}\".format(fold_i-1)\n",
    "    fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_{}/{}/\".format(fold_i, folder)\n",
    "    if folder != \"mml-pgg-off-sim\":\n",
    "        fold_files = [\"{}.dev.predictions.fold.{}.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 101, 1)]\n",
    "    else:\n",
    "        fold_files = [\"{}.fold.{}.dev.predictions.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 101, 1)]\n",
    "    preprocess_the_prediction_files(fold_path, fold_files)\n",
    "    max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "    print(fold_i, max_file, max_f1)\n",
    "\n",
    "    results[fold_i][folder][\"p\"] = precisions\n",
    "    results[fold_i][folder][\"r\"] = recalls\n",
    "    results[fold_i][folder][\"f\"] = f1s\n",
    "\n",
    "# Test predictions\n",
    "fold_gold_file = \"./zero-shot-extraction/relation_splits/test.2\"\n",
    "fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_3/mml-pgg-off-sim/\"\n",
    "fold_files = [\"mml-pgg-off-sim.fold.3.test.predictions.step.12400.csv\"]\n",
    "preprocess_the_prediction_files(fold_path, fold_files)\n",
    "max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "print(scores)\n",
    "\n",
    "fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_3/mml-pgg-on-sim/\"\n",
    "fold_files = [\"mml-pgg-on-sim.test.predictions.fold.3.step.300.csv\"]\n",
    "preprocess_the_prediction_files(fold_path, fold_files)\n",
    "max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "print(scores)\n",
    "\n",
    "fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_3/mml-mml-off-sim/\"\n",
    "fold_files = [\"mml-mml-off-sim.test.predictions.fold.3.step.3800.csv\"]\n",
    "preprocess_the_prediction_files(fold_path, fold_files)\n",
    "max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "print(scores)\n",
    "\n",
    "fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_3/mml-mml-on-sim/\"\n",
    "fold_files = [\"mml-mml-on-sim.test.predictions.fold.3.step.2000.csv\"]\n",
    "preprocess_the_prediction_files(fold_path, fold_files)\n",
    "max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the dev predictions on the RE-QA dataset on fold 1.\n",
    "folders = [\"mml-pgg-off-sim\", \"mml-pgg-on-sim\", \"mml-mml-off-sim\", \"mml-mml-on-sim\"]\n",
    "fold_i = 4\n",
    "for folder in folders:\n",
    "    fold_gold_file = \"./zero-shot-extraction/relation_splits/dev.{}\".format(fold_i-1)\n",
    "    fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_{}/{}/\".format(fold_i, folder)\n",
    "    if folder != \"mml-pgg-off-sim\":\n",
    "        fold_files = [\"{}.dev.predictions.fold.{}.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 101, 1)]\n",
    "    else:\n",
    "        fold_files = [\"{}.fold.{}.dev.predictions.step.{}.csv\".format(folder, fold_i, 100 * i) for i in range(1, 101, 1)]\n",
    "    preprocess_the_prediction_files(fold_path, fold_files)\n",
    "    max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "    print(fold_i, max_file, max_f1)\n",
    "\n",
    "    results[fold_i][folder][\"p\"] = precisions\n",
    "    results[fold_i][folder][\"r\"] = recalls\n",
    "    results[fold_i][folder][\"f\"] = f1s\n",
    "    \n",
    "# Test predictions\n",
    "fold_gold_file = \"./zero-shot-extraction/relation_splits/test.3\"\n",
    "fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_4/mml-pgg-off-sim/\"\n",
    "fold_files = [\"mml-pgg-off-sim.fold.3.test.predictions.step.1100.csv\"]\n",
    "preprocess_the_prediction_files(fold_path, fold_files)\n",
    "max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "print(scores)\n",
    "\n",
    "fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_4/mml-pgg-on-sim/\"\n",
    "fold_files = [\"mml-pgg-on-sim.test.predictions.fold.3.step.500.csv\"]\n",
    "preprocess_the_prediction_files(fold_path, fold_files)\n",
    "max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "print(scores)\n",
    "\n",
    "fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_4/mml-mml-off-sim/\"\n",
    "fold_files = [\"mml-mml-off-sim.test.predictions.fold.3.step.2300.csv\"]\n",
    "preprocess_the_prediction_files(fold_path, fold_files)\n",
    "max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "print(scores)\n",
    "\n",
    "fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_4/mml-mml-on-sim/\"\n",
    "fold_files = [\"mml-mml-on-sim.test.predictions.fold.3.step.4200.csv\"]\n",
    "preprocess_the_prediction_files(fold_path, fold_files)\n",
    "max_file,  max_f1, f1s, scores, precisions, recalls = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABzVUlEQVR4nO2dd5xb1Zn+nyNpVEbSaHrzjHsvFGOwMSWYTmghCQkEQjqbLKRtNtlkS8ovm5BOymYTSHazbBICGyBAQuimGQLYxhgbd489Y894etdIGpXz++PVuU1XXZoZjc/38/FHnqt21Z773Oe85z2Mcw6JRCKRlB6W6d4BiUQikeSGFHCJRCIpUaSASyQSSYkiBVwikUhKFCngEolEUqLYpvLJamtr+fz586fyKSUSiaTk2b59ez/nvM64fUoFfP78+di2bdtUPqVEIpGUPIyxdrPtMkKRSCSSEkUKuEQikZQoUsAlEomkRMlIwBljRxljuxhjbzLGtmm2f5oxto8x9jZj7HvF202JRCKRGMlmEHMT57xf/MEY2wTgWgCncs5DjLH6gu+dRCKRSJKST4TyKQDf4ZyHAIBz3luYXZJIJBJJJmQq4BzAU4yx7YyxW+PblgI4jzH2GmPsBcbYmWZ3ZIzdyhjbxhjb1tfXV4h9lkgkEgkyj1DO5Zx3xmOSpxlj++L3rQawAcCZAP6PMbaQG/rTcs7vBnA3AKxbt2729K7dsgUIhYCLLpruPZFIJCcpGTlwznln/LIXwJ8AnAXgOICHOPE6gBiA2mLtaF70Fjjd+e1vgU2bgNtuK+zjSiQSSRakFXDGmJsx5hX/B3ApgN0AHgawKb59KQA7gP4kDzN97NkDNDYCf/tbYR7vBz8AbrkFsFqB9nZALoghkUimiUwceAOALYyxnQBeB/AY5/wJAP8NYCFjbDeA+wB8yBifzAjefJNEdv/+/B/ru98FvvhF4PrrgW99CwgGC+/uJRKJJEPSZuCc8zYAp5psnwRwczF2qqAcOkSXPT35P9Z99wEbNwJ/+APw17/StvZ2oKEh/8eWSCSSLJn9MzELKOBjwz0YX76Q4pN582hju6HHzG9/C5x+OvDGG3k/n0QikaRCCnimcI6bN3bjI81b6e9kAv7YYxTbnHMO8Lvf5fecEolEkoIpbSc7LRw+TJf5CvjoKI5WcJTZ/fS3z0f/jAJ+4ACwYQPgcAAf/CCwezfwne/k99wSiURiwux24KOj6iBjvgLe14cxBzBsmVS3zZunF3DOScDXrweefhq48UYa+BwZye+5JRKJxITZLeDCfdfWFkbA7cAwguo2o4CfOAH4/cCSJUBZGXDllbS9uzu/55ZIJBITZreAi/x740agvx+IRHJ/rN5ecuBRP5RqSaOAHzhAl0uX0mVjI11KAZdIJEVgdgu4cOAbN1K80Z/7PKNw7wmEbECUR+EPx3PwefMoHhERiRRwiUQyhcxuAT90iER00SL6O48YZbyvS/n/cHCY/mOsRDlwgAYvW1vpbyngEomkiMx+AV+0SJ1ok4eAjw2oAj4UGKL/CAE/epQuDx6k/NsSf1urqigLL6aAP/MMsHdv8R5fomd8HJBdNSUzhNkv4IsXqwKex7T3sWFV/FM68CVL1DtZLPTcxRTwD3yApvVLpobPfQ64+OLp3guJBMBsFvBAAOjs1At4Pg58WBV/RcDr6wGnkwQ8EqHMXeTfgsbGwkzjN2N4mNygdIRTx6uv0hlPLDbdeyKRzGIBb2ujy8WLgYoKyqbzEfDxAeX/ioAzBsydSwLe3g6Ew4kCbubAY7HCdEcUVTYDA6lvJykMk5PUFC0cLt5BWSLJgtkr4ELcFi0ioW1oyE/AJ4aV/ysCDqilhMYKFEFjY6KAP/ooVca8/XbO+wNAfY15VNdIsmD/frUUtaNjevdFIsHJIOCLF9NlPgLOOcaC6mzKrAW8txeIRtVt+/bRpRj8zBXpwKeW3bvV/0sBl8wAZqWAc87xavvLQHU1VYIA+Qn42BjGLOokIJ2Az59PAr1zJ/VGqavT37exkcRbK7JHjtBlvoObBw/S5fg4nd5LisuuXXQ2B0gBl8wIZqWAP3/0eZxd8ye8dXqzujEfAe/rw7id/lvjqsFQcEi9TlSiPPMMVaCIH7hA1IJrn1sI+IkTue2PQDhwQLrwqWD3bmDFChpTkQIumQHMSgHvm6CqjMF59erGhgZyyplUD9x7L7WEVR6Q+qBYYUGjpzExQgGAY8cS4xPAfDJPIQVcnGHIHLz47NoFrFlDA9dSwCUzgFkp4OPxAcfAHM1KOQ0NFGUMDqZ/gM98Rt8CNt6J0Gtzo8pVZS7ggLmAixJGIeDRqFo3no+Ai06LZ51Ff0sHXlzGxmjMYvVqtfJIIplmZqWA+3uOAQCCTbXqxmxqwScm9LMb4w7c6/Ci0lmpF/DmZlqhB8jMgXd1URmadlsuiPhk/Xq6lAJeXETFkHTgkhnE7BTw3k4AQKCuSt2YqYBzTosV79+vVo7EOxF6nRWJAm6zAS0t9H8zAfd4gPJyVaxFfFJfn58DFwK+YQNdSgEvLqICRTjwgQFqHSyRTCOzU8DHKSYJuh3qxkwFfHKSRDwUUsW2rw9jLgu8Th8qHQYBB9QYRTuNXsCYfjameMyNG0nARWvabBEVKMKBywy8uOzaRQfiBQtIwAEa95BIppHZKeAiA3dqVozLVMADAfX/Ikbp68OYuwweuweVzkqMhEYQ45rB0GXL6EddUWH+mNrJPEeOkKifdRYdJIaHM3tRjz6q7+Vy6BDFN9XVJCzSgReX3buBVauov404YMsYRTLNzE4BD4wBAIJ2TUlfZSXFHekEPKhZcWfPHrrs68OY0wKvw4sqVxViPIbxyXH1dnfcAWzenPwxjQI+Z44qApnk4D09wLXXAv/yL+o20agLAGpqpIAXG1GBAqgOXAq4ZJrJSMAZY0cZY7sYY28yxrYZrvsCY4wzxmqT3X+q8U+SgAeiIXWjxUK5czYOXCvgDsBrp0FMQNNSFiABFT3HzTAK+IIFQFMT/Z1JDv7KK3T5wAPk2gG1dS1AS8ZJAS8evb3UMGz1avq7uZm+T1LAJdNMNg58E+f8NM75OrGBMdYK4FIAM+qb7A9PAACCkaD+ClELngqzCKW3F2O2mE7AE3LwVDQ0kMCGw7kJ+Msv0+XwMPDXv1JJW0+PdOBTxa5ddCkcuM1GZ1FSwCXTTL4Ryp0AvgQgx5G44jAeIREOhAP6KzKZjSkilHnzSMA5p5mYlohSRghkKeCilPDYMWpxm4sDX7+eziB+/3t1qTitgMtBzOIhKlCEgAOylFAyI8hUwDmApxhj2xljtwIAY+xaAJ2c852p7sgYu5Uxto0xtq1vivpW+znFDKYOPNMIZe1a6jGybx8mw0FMsmjuDlwI+Ouv0wFhwQIa8HQ602fgwSCwfTtw/vnADTcAf/kLsC2eYkkHPjXs2kUxVb1mZq8UcMkMIFMBP5dzvhbAFQBuY4ydD+CfAXw13R0553dzztdxztfVGRs9FQk/qLFTIJLEgacq3RMO/Iwz6PKFFzAW74OStwMXPcAXLKBKlKam9A58+3YqbTznHOCmmygD//736Toh4LW1wNCQvuOhpHDs2wesXKnvczN3Lp1RyYUdZhd+Pxm3EiEjAeecd8YvewH8CcA7ACwAsJMxdhRAC4A3GGONRdrPrPAz6hxo6sAnJ9VV5M3QOnCABDxeTp63A9cKOJCZgIsBzLPPBs48kwYuDxygx/R46LqaGjooZVqSKMmOw4cTB6nnzqXvUh7L9ElmIDfeCFx//XTvRcakFXDGmJsx5hX/Bw1abuWc13PO53PO5wM4DmAt53z6l1+fnITfRg7b1IEDqWOUQABfvwB4oqydhNHgwH0OH4AcBjEBYMcOWuS4Od4lMRMBf/llctr19eQAb7qJtgv3DdB+AjIHLwYTExRzmQk4IGOU2UQsBrzwApmmXCfYTTGZOPAGAFsYYzsBvA7gMc75E8XdrTwYGIA/LrimDhxILeDBIH6yHvhd5+N02nzihOLAPXYPrBYrKhwV+pay6XA4qA49EqHBUdE7xWy1Hi2c05fpnHPUbULAtbM+hYDLHLzwiKX5Fi7UbxcCLptazR7a2qhJ3Oho/outTBFpBZxz3sY5PzX+bxXnPGEJ9LgTnxH2j/f3w19G/zetQgFSi2YggJAN6J4cpN7PgOrA7V4ASOyHomEyOonBgEnHQxGjiPgEIAc+PKwvXdRy6BDVH2/cqG5bvBj44Q+BT35S3VYbL8FPJuBdXWpNuyQ7hIAX2oH391MkJloiSKaf7dvV/+9MWZsxY5h1MzFDfScQi7+qBAfe2kqXqVxTIICQFegO9pMDBzDmoSOC15FewH/4yg9x2i9PS7wimYADyQ8oIv/WCjgA/MM/qG1kgfQO/KabSirXm1GIkk2jA/f5AK83dwHfsYOqicRnLJl+3niDIk7GgLfemu69yYhZJ+D+fjVTTsjAKyvJrWpXsjEQCfgRswDdgT7VgdeScGfiwA8NHsLx0ePgxgwtVwH3+ZQDSVJSCfihQ8Dzz8t8PFfa2qjkU7zHAsbyKyXs6qJLubr9zGH7dqr1X7xYOvDpYnxQFcMEBw7Qh5NCwENBKiEaCAxgchkNFI5VuQFk5sAHg4Pg4JiMGtaoNBNwsS3ZQObLL1P1iSXNx+T10uxAM5H+zW/ocmws9WNIzDl8mNy3cak8oDACnu+6qBLKrN/znvy6Q3JODvyMM4BTT5UCPl34h8jRuGyuxAwcSC/gAbUGtLeyDPB6MV7hBJCZAxf5d4L7T+XAzQR8aIgWETDGJ2YwZt4PJRIB/ud/6P+BAP0tyY62tuR9bqQDnxm88grw0ENUQZIrR4/Sb27tWhLww4dLwvTMPgEfodmeNeU1yR34sWP6roMaQqEJ5f/d/h7gttswtmoxyixlcNioHMW0J3gcIeAJz71+PQnB8uXqtro6ctdmAr5lC12ed57p8yRgNhvzySdJKMRjlNAEhRlBNEq9a4z5t6C+npboy2UClXTghePAAbrMJyYUA5jCgQNqD5wZzOwT8FESsdry2kQXDJCAc64urGAgFFJXWeke7wbuuANjyxcq8QlADnw0NKrvCR5HceBG93/BBeT8tT3DrVaqjDH7Eb/wAmC3qws2pMNMwP/rv+ggceON9PfoaGaPJSG6umiyTjIHXlNDtcO5TKCSDrxw7N9Pl/m06njjDYoh16wBTjmFtpXAQObsE/D4ajw1rhQOHEgao4QmNQ58nIR1bHJMiU8AEnAOjpFg4ozOpBFKMpJN5nnhBRJvlyuzxzE2tOrtBf78Z+CWW9QBuBI4JZxRJKtAEeRTfy8FvHAIAc/Xga9aRf2J5s6lgocSyMFnn4D7hwGQA4/EIojEDLlvOgEPmQh4aAweu0fZXuWitTaNMUogHFAOGqYHDzMaGxMFfHSUHME73pHZYwCJGfhvf0uZ98c+RoOcgBTwbElWAy7IVcBjMfrMLRYSHbHItSQ1oRD1xDdWeOUr4JyTgIv+R4yRC5cCPvX4gxQT1Ljox5UgpNXVdHRNJuCa6EPnwA0RCpAo4NoJPKYDqGaYOfCXX6YfeTYCLiIU8eX+/e/Jwa9YIQU8Vw4fpphLzB8wkquAi97wy5bR31PUpTMv2tqmf3r5gw/SfIbXXlO3+f3A8eP0/1wF/Ngx+kyEgAOUg7/11oxvVlbaAv7ww8D8+dSvIo4/SCJVW06zExOElLGUlSihsCr4J8ZJWMdCiREKkEbAs4lQenv1A2EvvEB53NlnZ/YYAIlJOEwDle3tNFHkve+l66SA50ZbG7U+KCszvz5XARfxiWiYNtMHMtvbqXXDI49M736I6e2vv65uEzNZ7fbcD4RiAFN8HgAJuN9vPlY2Ojpj8vHSFvC//pW+XGLlHM6V1XhqypM4cCCNgJPwllnK8nLgGUcoTU10lNd++V54gaZZu92ZPQagF5OHH6b/v+tddDlDBPzF9hexu3f3tO6Dju5u4NOfBp57zvz6trbk+TeQv4CffjpdzvQc/PBh+o5Od6Qg6ry3blW3ifhk3brcHfgbb9CZlqg+AdSBTLPX/O//Tp/dSy/l9nwFpLQFfMcOuty3jy7HxjBui4GBodpVDSCJE16yhI7mk5MJVwkH3upr1WXgWTvwTCMU42Qev5+mWGcTnwBqP5T+fhLw1avVvH+GCPgtf7oFX3v+a9O6DwAoCvj1ryle+o//AL7xDfPbmbWR1eLz0Q8/Xwc+0wVc7G+K+RNTgohKxIImgCrgZ59Nn0Mukcf27fRd0BYMrF5NYxRmAr5lCz3PjTdO+wzn0hXwcFit0xQCHu9EWM7sKC8rB5DCgcdipj1RQvGFkOf55qF7vBucc4xPjhcvQlmzhr4o3/2u2n0wEkkp4F977mt44ahh0oJwgwcOAC++qLpvYEYI+ER4Au0j7frFoKcDzuG/7krEbv0EuaxbbiEnZTz9HhkhQUjlwBnLbTUkIYinnUaXMz1CEfs73Y23hAPfv18tid2/n6pGWlvpNz2Uw/fr7bf17hsgMV+6NFHAQyES/Msuo+/MRz4yrWMDpSvge/eqK7SLCGVgAP4ywG11wmmj2ZNJZ2MCpo5CEfDKeZgIT2BsciwhQqlwVICBJbSUzSlCWbKETsnuvx/4xS8oPrFa9S1kDXzvle/hwb0P6jcKAb/nHvoiawXc4aBMfRrrwA8O0I8/qz7qRSB6rAMLlj6OX//TJRSdfPaz9H79+c/6G6arQBHkKuC1tUBVFcVkM92Bi7PD6Xbgx47RTGYx7R0gw7Jsmf4MNBuCQXpcbXtmwdq16jKIgjffpDP3T3wC+MEPaInDH/84l1dTEEpXwEV8snRpggN3l5XDZaPToZS14CaOIhTvYTLPNw8A0D7cjkgsonPgFmZBhaOiMBEKAPzTPwHvfCfw+c8D995LXxyv1/SmnHMEI8HExxcC/vTTQEuLfkCGMZpANI0O/MAAzZYbCaVYDWkKGNu1DX1u4MCSajrzOf10Gqj805/0N0zWB9xILgtKd3XRqvZA6p7wnNOB+I9/zO7xC41w4AMDuTncQjAxQbNer7uO/t66ld6f/ftJwMVyjcbP4q9/TX2AFdU1ZgJ+0UV08NqtGbcRq2qdfTZw++30+fzTP6kmcoopbQEvLweuvpqEOBJRHbjdozpwsyijro4E0syBx6gmVwj4wUESea0DB6gW3EzAhdBnHKEAJCT/+7/0Yz5yJGV8Is4QglHDgamqioRa/OiNzZe83mkV8P0DlFWaTX7Kmp076TXmcEYxuocO/MNeG21gjB7r6af170+6STyCXB24WJUp1ULbAwNU+SH62UwXXV3q92m6XLjIv8UBd+tWOvCNjSV34ENDwFVXAb/6VfLHFSZOu8KV4LLL6PIJzfo1r75KcU1zM70nd91FZ1G33TYtUUrpCvgbb1ButWoVndIcPao6cIcXrrIUDjxFKWEoRg58fuV8AOqpv3YiD2De0GowOIhmb3Py501FTQ05rbo6ffxhQDjvhMe3WknEAfP7zxQBD40kttrNll/+koTt7rtT366jI+FHNXbobQDAMNe8f9ddR3Gc9ofa1kafic+X+jnyFfDGxuQCLgbotmzJrd9KLJa0509WnDhBYzXA9OXgIv9uaaEKrW3b1PdHK+DasQzx+aeKqMTrMXPgc+bQ69Z+L/72N315b3098O1vUxx3333Zv648KU0Bj8Uoi1q7VunZjb17gcFBcuDlvtQZOGAu4LEYQqAfyrxKgwO36x24qYAHBlFbXgu71Z5dhCI46yz6sqXIv4Vwmz5+TQ1NUjr//MTrplvA++nHFolFsjs7McI55Y4AcOed6jiIkX37KC8VJZVxRo/Sfug+u3PPJQEQMUo0Smd46fJvIHECVTqiUXKOWgeeLEIRTZpyrTv+l3+h30c+Tcw4VxuiMTZ9DlwIeGsrCfiRI+piGEuXmjtw0SkyVcR16BBN7hPmx8jll9Mg9/g4vQ8dHcCGDfrb3HorlTF+4QtTPs5UmgLe1kZidPrp6my2ffvIgTstcNs9qTNwgAT8yBF9i9VgEKH4cpXN3mbYLLakEUq1qxp9E/rKhcHAIKpd1dTKNleRMus7rUE8runruvJK4DOfMZ94Mo0CzjnHgYEDcFipm2PKGCUYpKwzGW++SafTN9xAP6jf/c78dk8/TQf6zZu1O4KxTpqYoRNwqxW45hrgsceo+uS976XBq/e/P/2Lq6mhg4hmMllKentpv7QCPjhoWtKK/fvVXvAvvpjZ42t55RU6M/3Od7K/r2BkhFoRL1xI7ne6I5Q5c0gsARovcrlI1MvL6V+2An7woLn7Flx2GVW8Pf88xSdA4gQ7qxX4z/+kA/HXprZMtjQFXIxAr11LR86GBkXAx50WeNJl4AAJeCSi7+ccXw8TABxWBxrcDUqEYnTgrRWtODZyTBcHKAJe5so+QsmQpBEKQI40WU3zNAp4r78XI6ERnN5EE1dSDmT+67/SlOZk9bx//jMd5H78YzqAf//75rcVvaG1S5Z1dGA0Hp0k7MN115F7OvVUimd+8hNaui4d2U7m6eykS22EApCwGxEVFvPn5zZpZM8eeq9+8IPcF+kVA5hNTSR00xmh1NVRsykx5f3tt2mfxEGutlYfoQjXns6BpxLwc8+lA8MTT5CA2+3qBCwtZ55JTvxnP5vSstDSFPAdO8hlrlpFf69YoTpwO4O7zJ06AwfMSwnjDtwOGxhjaPQ0KtPpjQ58nm8e/GG/rpRQCLjT5swvJkiBEqFk+/jpBNzvJ5dRBET+fVYzreOZ0oEfPEhik2zW35//TD1eGhqAL32JXKpxijfn5FgZo8fxx1sE796tLFCdUM548cWAx0M/vj/+kc5kMiFbAReCqHXggHlOKyoszj+fXk82Ywd9fSRcn/scCdyXvpT5fbWIEsLm5rSLoRSVY8fUnjQ+H8UmgHoGDpCAZ+PARQmh2QCmwOEALryQBPxvfyPT6HCY3/b66ykim8KKlNIU8DfeIPG2x3+Ny5fTmzYwAL8tBrfdnT4DF/mm9gsZd+AORja80dOoXGV04HN9tCp5+zBNBpqMTmJ8clyNUHLJwDMgZYSSCq83dT73X/9FX9QiNFYS+fdZc+ICnsqBCyeqHTgSdHXR4NXVV9Pf730v5dxiEpRg3z56HdddRz8oMfX67bcxGv/tDQeH9YOpTicdHF59lZbnypR8BVw4cKOAR6P03Vy6lAS8r08dtMsEISKXXUZlbn/8Y24xjHZ/Fy8mMcyl/3m+HD+ubyp25pl0qRXwurrsBDxVCaGWyy+nqiTjAKYRoSmigmkKKD0B55wcuLbOeflyYGgI/MB++K0xuMvcKLOUwcIsyYVO1I1q89b4ivQOC2XIOgE3OvD4IGfHCH1JxAzDYkcoKQcxUyEceDIX195O14lT/AIi8u/V9asBpHHg4gDy+OOJ1z32GF0KAbfZgH/8R+pOp41KRHwiXKeo3X37bWWB6kgsgomwIbe+4AJ1dmSmiMGzbATcYqHqBUB14MbT7vZ2ysWFAweyE+A9e+hy5Urgi18k8fvCFzK/v3Z/ATVCAabHhWsdOKAKuHDiQHIHPj5uXo2TqoRQiygnjEZTC3hrKyUDUsBT0NVFP3JtDhVfpiw0MYYY43Db3WCMpY4y7HZyXVpXGgySA7eQs8/IgY+QAxeTeIodoaTMwFNRUUFZcSDJfokfarIFlvNg/8B+LKlZovRRT+nA+/pI4F55hQbQtDz6KNUAr16tbvvQh+i1/eIX6rYXXyTBOess+m5oBHy0qVq5WUFmhQoHnulknq4uEm1bfLAlWYQi3PbSpSQwjY3ZC7jHQwOP5eU0c3DbtuSffzJOnKCDv8eTcgJcURkfJ9ff0qJuu+wyGtDUVmxpM/BIhN5rYdTMDrDiQJTOgS9erLprYwWKFquVxitmmoAzxo4yxnYxxt5kjG2Lb/s+Y2wfY+wtxtifGGOVRd3TOCNbX8KORugdeLyU0B8vvnCXURc/ly2NE66o0IuEcOBWvYA7rA6UWfWVHXXldXDanIoD1wp4MSOUrBeMEKTrh1JkAV9Wsww+B9VUJ3XgoRAdUC++mNzOM8+o101M0N9XX62v1HG7qZ/JH/9IIso5OfB3vINud/bZJODRKLBnD8bq1CXtCiLg1fEDQjYOXMQnAImr15vowEUJ4bJl9DrOP59eV6Y5+J499LsQ75Vwr+JzzhTt/prFjlOBtoRQsHw5xSraiVa1tfT9DoXoexyNqgOeZgfYgwdTlxBqef/7KbZN1htesGjRzBPwOJs456dxzuM1PHgawGrO+SkADgD4SsH3zoQfvnUXNn4MiKxeqW6Muwx/PBJ320nAnTZnaiH1+fQOXGTg8XI3IeDGSTwAwBjDXN9cUwde1CqUuLPPaRATmHIBD0fDaBtqw7KaZfA6vGBgyR24+JFdfTV9Ntoc/Omn6TRYxCdaPvlJiht+8xv68XR1qbNZN26kx336aSAQwGil2nGuIAJeVkZGIFcBB8xnY+7fTzX9IqI5/3wSLJMGbKbs3UvxiUBM3c9FwJua6P8uV/FKCX/0IzqrNjtAiRLCdOKpddsiPhFn6skEPJ37Fnzzm5m10xUCPkWzMnOOUDjnT3HORRH1qwBaUt2+UByaPIFgGdADdfFhWCzAsmWJDrzMlTjlXEtFRWKEYk0UcGP+LZjrm2vqwKeiCiUYCWY3ozGVgIvJGkDBBfzI8BFEYhEsrVkKC7PA6/Amd+Di9LepiVz444/Tvo2PU549Z455m4FVq2iiyV13qZU0IjcWmeWvfw0AGPPYlbsVrLFWNrMxtX1QBGazMUUJoXDQ2eTgw8P0PFoBFweNbMc4TpzQH3AWL04eofzyl/rFFrLh/vupxt9s/7SzMFOhnY0p7iPO1M0EPF0JoRaLhSKSdCxaRGf1qeYyFJBMBZwDeIoxtp0xdqvJ9R8FYDLqBDDGbmWMbWOMbesrQIVDOx8GoK6Wo7BiheLAhWNO68DNIhQb4LAZBNxuLuDzfPOmPELRPq7oi5IRqQR8ZESdiFJgARcVKMtqqVrA5/Ald+Di+1FXB1xxBf2Y336bOgYePEjrfCYr4frkJ8n5fOc7dH8xQ3fFCnLz8VLDUYf6uU6JgA8MAP/8z1TxMDlJr9HMgRsjFFFCKFi1ik73tROTkiEqUPJ14OLArt3fJUvMHfjoKPUD+djHsu/JPTKi9vgWq+NoOXaMDmTGA58R7WzMdA48kxLCXJjiSpRMBfxczvlaAFcAuI0xpszVZoz9C4AIgN+b3ZFzfjfnfB3nfF2dOMXJgw5GAtQ1ZvgiLl+OcUOEkjYDN0YowoGXUQliJg68e7wbwUgQg4FBpUth2ufNA+3jZvUcqQRc+6Mu8CQEUQO+rCYu4M4MBVyM/N9+O/Df/w185SvApk3Jn+g976Ef8OHD5FaFc7VYaOApEgFaWzEWnUBrBZ2KT4mAP/wwcMcdJMBf/jJtSxehiHUetRUWFgsd1P7yF/3sYTNEBYo4iAH0XXe5snPgw8MkdEYH3teXOMD86qsk3Lt3q60OMuWll1TRF5P0tBw7Ru+R3Z54nRajgFdV0aC32KYl0xLCbJmJAs4574xf9gL4E4CzAIAx9mEAVwG4iefdoSg94WgYXTZyiifGDE7xoovgb6YDhIhQ0kYZyRx4XMA9dg88dk9KBw4Ax0ePYzAwiCpnFSzMUtwqFM3j5iTgZrXgQsBbW4viwOvK65QKFJ/Dlz5Cqauj0+U1a2jgbv164OtfT/1EDgfw0Y/S/40xy8aNdLlqFUZDo2j1TaGAi/f28stppiyQKOCNjdQ5T/R1ERGF1oED1KRsYEBfMmnGnj1UYTV/vrqNMXrebBy4toRQkKyUcMsWOsi0tgLf+lZ2GfDmzfT5LVpkLuDGGvBkaFvKdnTQfWw2EnKjgGdaQpgtYlB1pgg4Y8zNGPOK/wO4FMBuxtjlAL4E4BrOeYaNIPKjc6wTsbixSohQNm6E/+7/AKBx4OkGE80GMa2Ao0wd6Jrnm4c6t/mZg3Yyz2BwUFnGzVU2NRFKVs+RiQNfu5YEvIDH4gODB7C0RnWSaR24xaJWdlx3HQ3k3Xtv8oWFNbR96Bp4/82KfZvW6K8QOfiqVRgLjaHWVQuXzTV1Ai4aZT36KFUzGGuJRSmhmMSkLSHUctllJHSGBl0J7N1LVRrGzHbOnOwcuHYWpiBZKeGWLRRX/PM/Uw6ebJ1RM557jg6yGzcmd+Dp8m9A/d6IDHwu/T4T6sOBzEsIs8Xlovdrpgg4gAYAWxhjOwG8DuAxzvkTAP4DgBfA0/Hywl8WcT8BqLMeAZMIBYB/kgY2dQ48XQY+OqoKlqgDt5crN3ngfQ/gOxeZNwPSTuYR0+gBim7CsTCisRxagKYh5wilIl4+l0rAzziDTpmNp8fZ8txzwFe/Clx/PQ7tewVLBtWyv7QOvLZW7W3x1a/StPp0PbnjHHZMYNwaxT7bsP6Ks8+mCOPyyzEaGoXX4TXtJpkztbX0noXDiddpM+Srr6aWo5WV+tsYZ2OKEkKjuHi9NLj78MOpD7J79ujzb0GuDtyYgZeX69suhMMUoZx7LvDhD9Pr+da3MnuOgQEavLzwQjIQXV2JMZ5xEk8ytG67oyO1gGdTQpgtU1hKmFbAOedtnPNT4/9Wcc6/Fd++mHPeGi8tPI1z/sli76wYMPRErYkOHIA/HBfwTDNwMblF9MowceDLa5djToX54Mkc7xwwMLSPtOsEXEzjL0YOnnOE4omXQpoJeGcnnY2I/C6fGCUWo6z2W98C3nwTg2UR1O1VD7xpBzG14yRWa/p+3BrE559wgPB4gN27EbnwAgQiAVQ4KkjAQ8MZP3ZKxGQes8oDs7JBI8bZmGKdR+0iu4J3vYu6aIr1YI2Mj1OpoZmAz5lD+5PpGZZZhOJ00oHowQfVLH7HDpogdO65dP0XvkCxiOjelwoxa3bTJrViROvCR0fpO5uJgAMk1u3t9FmI+xibXAHZlRBmy0wS8JmEqLleF6pJzMCRxIGnyqKFOIgYJRBAqIwpVSjpcNgcaPQ0Jjrw+AGgGDm4VrSzXvXH7U7uwJub1R9qPgI+OEhZ7g9/iNDe3QjaAF97t7Iggc9JDtx0yMQo4FkipsaPhsx7voxPUl9sr73ADjxVP5RMBHz+fIqIPvMZctfGChQtYiJTshhFLC+oHcAUNDeT0Gbay+TECTI5brd++/veR45WuPAtW+hSzIr8u78jZysy/1Rs3kyPf+aZasWIVsDNJvGkoq5OvX+6CKXQ+bdg0SL63LOd9ZoDJSXgHSMdqAtYsIhXmUcocQcmBDQjBw6oAi4iFGtmAg5QjGIWoQAzzIEDyTsSitpkIeBmJW2ZIn4o9fWK064cDVM5IMiBh2Nh830vkIAnc/hC2BUHXmwBNy7ekIyGBuDJJymauO46Kqkz5t/a227cmFzAtT1QjGRbSpjs4HPFFXRWc//99PeWLSRa4vvj9QI33kiZf7oWxs89R87dbqf7LV1qLuCZZOAAibV4fUYBF6YhEKCIJdl7nC/iTFasq1pESk7A540ATdZK9Ph7EjJm/6Qf7jI3LIxeVkYzMQE18xURSoYOHKCBzLahNgwHhxMilGIMZOoceK4NrYykcuCbN9OAmFl9rhmaShIhkJVBUMMpkAMHkohsb29eAi7OwJI58LEQvfaCZ+DJBNy4eEMqNm2iKOInPyGhvfji5Ld917votmazMvfuJTdvtppQtpN5kgm4y0ULYDz0ENW2b9lCIqzlxhtpPMXY6ldLdzcdcC68UN22dq1ewMWCwkKM0yFKCbX3qa2ls0IRlYp4o9gCPgUxSkkJePtIO+YOxtBUVoUYjyWsiOMP+5X8G8igCsXowAMBhKw8Owfum4cjw7TKy1REKIFwQJmoVBAHHoups+0qKijD1Aq4mFlnVh1ghhDw2loli/bZvUoemrQfSjhMpXSFcOBJBkmn3IGbDQKmQsQox4+nXBcV115Ll2IJOMGhQzTZac0a86qdbB34iRP6/FvL+95Hcdldd9FnbhTwjRsp9vjDH5I/vohgjALe3k7v5fg4LUZx7rmZO3Dx/bFY1PfduNxaskHiQiEFPBHOueLAmx30gRhjlPHJcSX/BsgJp6wGMThwHgxgMgcHLqhx0Q+5mBFKMBJElbMqt8c36wk+MEDiKVbZbmrSC7gYLBPZajrMHPiiVekduBC/IkYoY5NxB273wufwJfYEz5VCCXimLFlCFUNf+Qrw05/SQfjgQWqHGwzSxCczhBhn4sDNZmFquewyOuCLJcSMAm6x0LJ3Tz2VvMTymWfoN6jtLKodyLzzTqrM+d730i41qCDEurlZ7fhoFPBUCxkXgupqel1SwFUGAgOYCE9g7gjQVE6j9saBzAQHnk5IDQ58MkgCkK0DF0xFhBKIBJRJMQVZlce4xFcyAc90lRETAfetXEunyqOjyR24dhJPjogxkGQRitGBm/YEzwW3mzLcqRJwgGY7XnQRtRm45BKKYEIhirxOPdX8Pi4XiYvRgZsdxMTEomT77nTSmcDQEB3AzAZdb7yRKlUeeCDxumiUMvLLL9fXqwsBf+IJEu53vzt1D24jQqy1kYuZA29oUH//hYaxKatEKRkBFyWE84aBpvgUd2MpocjABWnXxTQIeChEApCrA5+qKpS8HLhRwI0ioxXwcFh13pkKeH8/PY/DoQ5irj2bRGLrVlQ6KwGYuOQCCHhaB27IwFPdNisYM5/M09VF14kywULS2EgrCN11F53dCPE+5ZTU92tu1jvwJ5+kfR8a0t9OfAeSRSgAxSgAuW8zh3zaaSTsZjHKli30mRtXP6qqolWWfvxjGmz89rdTvx4jmQj4wYPFy78FUsD1iEk8c0eAxgoSG2OEYpaBAxk48HiEEoo75mwcuKmAF7MKJaw68JwWdUgm4CIfbWpSq1AOHCARX7KEcslMVl7XVJIoDvyseOuc115TI5Thbn2cU0ABz9SBa/cxb5IJuHbxhkLDGC2ke/Ag8NZblH2nQ9SCCx5+mMTbODXerAbcyKWXkkhff33y/bvxRuqgaIxtHnyQXPwVVyTeb+1aioU+/vHk5ZTJEN8fbdmhmQMvVnwiWLSIJqFFCz+ZT0vJCLjiwEcAu7cSteW1iRFKMgeeLMqwWun0VzjwyXiEkoUDr3RWKr1SEhx4sSKUuAMvSBWK+KGK2YCNjVQnHAio8cn73kcOWgz+pEIj4CPBEViYBZ76FqpkefVVNUL57v+jaeXa+wEFiVCSDWJqM/CCC7hZrXEmNeCFoKkptdBqMTpwUcNtjFWMB3Yz7HaqhrnppuS3ufFG+u6IkkOAxPmhhyg+ERPMtFxwAc1WFfl6Noil6uap0SYqKymT7++n33pPz9Q48HBY7YpYJEpGwNtH2uGyOFAzAcDtRpOnKTFCyTYDB2iwIe7AJyfpdtk4cLGwAwBFFNJGN3kQjAThsXtgZdbcIpRAQN/NTiw7JTq9aWvBd+2ig9x119G2ffuwq2dX6oE/MR0eJI4+h4/KOtevB157DV67B4wDI6N9wMsvq13o+vrUKCJHMnHgYnWlKXPgUyHg2dDcTJ9tNEpVJKJMzzh5KxMHnglLl9IknZ/+VC3je/11OogkWzz6ttuoEieX516wALjnHuDmm9VtFgt9Pv39xR/AFIiVgP7616I+TckIeMdIB+aV1YEBgNuNZm9zYoQy6YenTD2iZySkmkUdQuG4gGfhwAGazFPprITVQoMxxY5QXDYXNczKdVWe8XF1m1FktLXgu3fTKeyqVYDFgn17X8IpvzwFm4+k6EmtdeChESUywYYNQG8vLPf8L7whYKQ+HueIH1RfHw2w5RE3aAU8xhN7Uo+FxlDhoNjspBXwOXPooNnbq+9qaObAKytpclG+/OhHFMF99av094MPUpnjVVeZ356xxNmf2XDLLYktGMQZkvi+FduBn346Hbj+4z+KujpPSQn4XGu88YzHgyZvBg48XQYO6AU8kr0DB4DLFl2GSxddmvC8hY5QOOcIRUNw2pxw2pyFWRezszO5gO/aRbmq0wksWICedprld3T4aLIdTMjAhVBi/Xq6/MQn4IvaMHJxvOxMTBDKcxYmoAo4B1cm9WgZnRxVersXTcDFGUU4TCI50wRcO5lnyxYSUrPKlEIefM49F/jUp2hgcutWEvCLLkps6lVMhICLGNBsolOhuf12KgLIZBGOHCkZAW8facc8VNIf8Qile7xbcVqcc9M6cCCNkGoilFCE+jFn68A/s/4zuP+9asZXrAhFCLarzJWfgGsHD5M58IMHqWmSGBhbsQITnUcBIGEClcL4OM3M0zrweOaNNWuojI1z+BrmYsRTRgeGAgq4VrTNqku0DlycGRRMwJcto1hCVOuIgeCZJuDayTwvvQSsW0e9WMwilELu+x130PjKddfR9ypZfFIstAKerFFYoXnf++h5f/7zoj1FSQh4IBxAr78Xc2NxAYpHKJFYBP0TNHAUioYQ47HsM3CtA48vUZatAzdSZimDhVkKHqGIx3PanLRsW74LG0ciNKCjHagS7VzFivCrV9Pl8uXw99LisuI9T8AwEKlz4DYb1Sx///vwVTVhJDxG9cpiKa0COXDx2Znl4KOhUWXAWZzFFEzAxaIRL79Ml8WsAc8HsT+HD5MbPvdcOmgX04EDZJT+8z/J+Vss6mzSqUIboRQ7/xY4nVRJ88gjRRvMLAkBPzZKDW3mTcaPmh4PmjzkFEUlirETIZChExaLOoTDCDFy89k6cCOMsaKsiyleh8uWpwMXAt7TQ7GH9odqtVLpm6hO0DpwRoOfSR24Zho9EB/EdGqyyDvuAP7hH+Bz0ixInHEGVTHEYgUT8CYvfS/MKlHGJlUHDqCw0+kXL6b9f+UVBCNBvHk4LuQzTcAbGkhAH3mEYp5zz6V91DpwbXuFQnLttbRm5gc+kPdnnTVaB17s/FvLJ+Ndtn9ZnOUSSkLARQnh3KCTnJzdrvxQRQ5u7AUOZJGBj4wonQiB/B04kEEr2xzQRig5rfpjFPBkLrGpiSaGuN3qslzLl8Mfb6/R508j4JoywkpHZcLNlEUdzjiD9mX/fsqP841Qwn7lwJ7UgWvWNy2ogDNGLvyVV/Dbnb/FGQf/EUcqMfME3GqlKEOsbn/OOfR59/aq1Una9gqF5te/pn4tU01tLUVcw8NTK+Dz5lEL4F/9itocFJiSEHAxiWfeRJkyOi1+qKISJaUDT7cqz9gY4PcjFJ/Rm68DBzJopJUD4nXkPIhpXJUnlYADFJ+I1XFWrMCEEPB0DryuDjEew2hoVI1QNCiLOqxbRxuefppcXx4CzjnXO/BkGbg9Pwe+t28vXjj6gvmVGzcCBw/iaNcexMDxzGI29U4zE+bMoTOvlStp8LW5mf4WKwLN1PgnH7RdCqcqQhHcfju5/0cfLfhDl4SAd4x0wMIsmDMKpfBfceBjKRx4pnXgANDXV1AHnlNGnQbFgRcqQjH2QREIAdfO7KuqwkQVvbdJM3AxkaWuDmOhMXBwfYQSR1nUYcUKygkff1y5X66I96LRTROSzBz42ORYXg48Govi3f/3brz/gfeb3yCeg/e0U231syuc6gFwJiE+b9GASvwthHu2C/hUOnCAKm6eeQZ473sL/tAz8NuVyGhoFK0VrSjzBxQH7rQ5UeWsUiOUuAMXrVbFbYAM6sABoKenoA48bS/yHBCvo2CDmG+/TQIqZq8JxKxMMYAZx99AM01TRigOB+DxqJ0IkzjwcCyMICI0kCnaihZgFmayDFw0rsonA//9rt9jX/8+9Ph7zA9iZ5wBlJWhp5faCz/bEjatR592xKD1eefRpbEPfKEm8cwkhIBbrWosOFUwRiJehIN5SQj4nZffibbPttFMLk2Bf5O3SY1QwokRit1qBwPLzIH39BTWgRchQsm7jNDhoDGEsTG1S9yVVyauXm7mwAFM1NJ75Q/7zQ9OYhYmY0qEoZQRatC1lF23Ts0GC9AHpcHdAAaW4MC1y6kJKh2ZC3g4GsbXn/+68v3a07cn8UYuF7B2LXrGe8A40O+I4K2et3J4NUVG9NZO58Bno4AvXGjeK71EKQkBB0DTscfHdb0Tmr3NigMfClA3NW2EwhjLbGV6oOAOvBgRijYDz+kAwZjaD+X552ng6oYbEm93ySVUrysm38TxV6nvrWkObtLIKpkDB6AOZAoKIOAeuwdehzchA9c2shIIB55JT/DfvPkbHBk+gh9e+kMAwNu9b5vfcONG9GAcFx6jL9Ozbc9m/VqKzsc/TpNphBOtr6fvhlbAa2rogD9bEAI+1fl3kSkZAQeQ6MA9TTgxdgJ/2PUHfOqxT6HGVaPrDghk4ISL5MCLGaG4bC44rTk+vljU4b776GB45ZUJN9ntC+Gd7wliwq5vETrhVSc/mMYomQq41oFrBVybU2aJiNDKy8pR4ahIEHBtK1lBpbMS4Vg47YE2GAnimy9+E2e3nI1bz7gVXrsXb/eZCzg/+2z0uIHTj0WxAnV45sgzOb+molFXR322BTYblReKCKUYJYTTjddLZs0QC5Y6JS/g7SPt+MBDH8CahjXYfut2ncMCMijnK5YDL2KEknMVCkBf5IEBcmDvepfpjLSfvPoTPH7ocRwe1PcznnCogm6aAff360oIAZgPYmod+MqVlMNXVqoNtXJAOHC33Q2fw5cQoYi/dRFKhtPp79p2F46PHse/X/jvYIxhZd1K8wgFwNiZpyBkAxr8wEWeU/Bi+4uYjE7m+KqmEO1knpnYwyVfGKPeL//8z9O9JwWltATcEKGsrl8NBoZ/Pe9f8cKHX8C8ynkJd8l4Zfq4A7fAApsl//7NxYxQlDrwXB7f6wWefZbqYW+8MeHqUCSEB/bSCioiNxb4WQR18dnqeUUoWgdus1FP6QL1QVEcuGEQU7SSNUYo2n1Nxu92/Q5nzTkLFy6gtRtX1a1K6sB7vPSTahgHLm4+FxPhCbx6/NWsX8+Uo53MU2ICHo1F8d0t3034viawalVik6sSJyMBZ4wdZYztYoy9yRjbFt9WzRh7mjF2MH5ZVdxdRYIDv+mUm9D3xT5888JvJhXdtA5cG6FYAYc1dxeY8LwFjlCMDjwSiyASi6S5l4GKCho0rK42Xfn8rwf/qgiaED3BBMKYR1clRiihEGXr8Rgk5SCmcVm1b34T+Na3snsdBrQC7nOmcOCO7Bx4MBLEzu6duGDeBcq2VfWr0OvvNT0L6fFTLXWDH7hg2aWwMAueaZuBMYqR5mYS7miU+riUkIBv69qGLz/7ZTxx6Inp3pUpJxsHvolzfhrnPD77Al8G8CznfAmAZ+N/FxeDgFuYBTXlqftHp40y3G46vYo78EIJeFrnnwPGqfSA2oArY0Qp4XvfaxpZ3Lv7XjBq2pvowCMTaA7YYOUs0YGb9EEpLytHmTVxxD9hYeOLLzZd1eXeXffikt9ektHL0lYhpcrAs3XgO7t3IhwLY32LOqC7qm4VAPOBzJ7xuIBHnfAtXo2z5pxVGgIuZmOeOEEiXkICLg6k4jM+mcgnQrkWwD3x/98D4F15700qolFyjmYreKQgrRO2WMiV9vbGHXhhRt5zjjhSIA4IDptDmaSU7DlGgiPmX2gh4CbVJyPBEfx5/59xxRJa5soo4BPhCXgsDtRGHYnu02QavZn7BtQcOtnKOYKn257GM23PJF2gwbhvQNyBZ5mBp9qP1ztfBwCcNecsZdvKupUAzEsJFQf+8k6gogIXLbgIr3e+ntFrmFbEbMwdO9S/SwRFwCelgCeDA3iKMbadMXZrfFsD51x0wOkGYLpyK2PsVsbYNsbYtr6+JBNAMkGs5pFlo/eMnHBFBRCJkAOPO9t8EQeOTErUMiUQDsBhdcDCLIoDN76246PH8fknPo/mHzXjfQ+8L/FBVq4EVqwAzj8/4aqH9j6EUDSEvzvj7wAkOpqJ8ATKbS7UTdrSO/DQsGn+DQBWixVee2KpnxHRA6dztDPl7cS+Aekz8GwjlNe7XkeTpwlzvGrHxpaKFlQ4Kkxz8J7xHjAw1DYuBACc3ng6ojyavIf6TEHUfIv2viUo4Gkz8FlIpgJ+Lud8LYArANzGGNP9+jmplKlScc7v5pyv45yvq8tnoCpHAc+oqVR8IDNkBRxlhRFwl80FDo5wLFyQxwNIrIVwmy0a8dPXfoqFP1mIn73+M5SXlSdUkQAAvvhFWmnHOHkHFJ8sqlqEixZcBMAkQpn0w20rR90ES8zANdPoAUMrWRN8Tl9aAT82Ql0oRTfKVGjLCH0OHwKRAMJR9b0Xy6nZNRFZJj3BX+98HWfNOQtMs+q6qEQxFXB/D2rKa5QxGXHAMFtgYkYhBFu09y1BAZcRShI4553xy14AfwJwFoAexlgTAMQve4u1kwDUZcCyjFAyKueLD2SGylhBSgjF8wKFXZUnEAkoj2vmwH+57ZdYXb8ahz5zCO9f9f7kPUtMpvSeGDuBzUc24wNrPoDysnJYmMU0Qil3eFA7HkvuwMUgZnDEtIRQoHQkTALnXBHu46PHk95Ou29WZoXdaldybm1soV3MQSAGgwcChqXQ4gwFhnBg4ADWz1mfcN2qulXmGbi/Bw1u9WRUtHaY8e5Q68AZo7rwEkE68BQwxtyMMa/4P4BLAewG8CiAD8Vv9iEAjxRrJwHk58DTiahw4HZLwTLwYqzKE4wElezbTMAHA4NY17wO8yvno8ZVg+HgMKKxaEaP/cj+RxDjMdy4+kYwxuCxe3Q/iHA0jHAsDLezAnUj4UQH3tdHB4Zq6peSzoFXOisxGBhMen3/RL/y2oQTT8VEeALlZeVgjCkHDq2Aa5dT07KqblXSMr+tXVsB6PNv7f36JvoS3odefy8aPCUo4A0NJNzd3TQzs4Smm/cHZAaeigYAWxhjOwG8DuAxzvkTAL4D4BLG2EEAF8f/Lh7FzMAVB24pnAMvwsLGgUhAjVAMg5iccwwFh1DlpGrOmvIacNC2TNjVsws+hw/La5cDIOHR/iCUjLm8AnVDkxgKDulLGPv6aPp13N3rllMzYXH1Yuwf2J/0em1skokD94f9KC+jBXiF09ZGNGYOHAAuX3w5/nb8b0orBi1iAHNd87qE65INZPaMl6gDF7MxgZKKTwDpwFPCOW/jnJ8a/7eKc/6t+PYBzvlFnPMlnPOLOefJ7VQhEAKeSxWKiQvmnOO7W75Lg0vCgZcVzoEXJUIJJ49QJsITmIxOotpFDrjGReWVAxPm8YCRPf17sLJupZL1Gh24KNMrd1cpk3l0j21YUSedA19dvxrd491J908MYNqtdhwfyyxCEX1wxIFD58A1y6lpuWLxFYjxGJ5uezrhutc7X8fy2uWmUdCq+ngpoSEHn6oI5bkjz2HHiR0FfUwlRilRAZcOfCYjMvACOfBefy++/OyXcd/u+zQCXrgMvFgRinEQU7w24bSrXKoDB5A03zWyp2+P4iqBRAFXpqp7q1BH/9Xn4Jpp9MFIEJPRyZQOfHU99aRINqNRxCbrmtclRCihSAjPH31et01EKICmzlyTsRuXUxOsb1mPSmclHj/0uG4751wZwDRjjncOVaJocvCJ8ATGJ8enJEK5/fHb8fUXvp7x7SOxSPp9EMJdYl0IpQMvBfLIwCejkwlZsMhfhwJDaoRiK2AdeJEiFGMGLhy+eD3CgdeW02Bi0oFMDf0T/ej19+oE3Gv3mkcoFbWoFQKuzX9FK1mknkYvEAK+u3e36fUdIx1w2pw4vfH0hAjlnp33YNM9m3TbzSKUBAdukoHbLDZcuuhSPHHoCV3J57HRY+jx95gOYAJUiWKcUi8m8dS71f7qLpsLDKzg4jIUGErel92En732Myz/j+Wpy1pL0IFHY1Hluz9VVShvdr+J77/8/Sl5rnSUnoDnUIUCqCvOC4RjHQwM6ssIZ3AVitaBGyMUkeEqGXgWEcrevr0AgBW1K5RtCRGKWLKusk6JUHQHB02EIpxvKgGf450Dn8OXVMCPjR5Da0UrWitaMRLST0oSPba7x7uVbRPhCaVXtzJV35CBm0UoAMUo3ePd2NmzU9lmNoHHyKq6Vdjdu1sRRWUSjyZCMRsQLgQjoZGMz64AYP/AfnSOdaY2FEK4S0jAh4PDyqIZU+XA73nzHnzpmS/pylSni9IR8BwjlGTrYoqj9mBwUHXgBZyJWYwIRZuBGwcxjQ48mwhlbz8JeCYRSnlVQ2KEEo0Cg4MJjaxSlREyxrC6fnVKB97qa0WrrxWAfiBT7K/2AKKNUJRBzAwiFAC4bNFlAIDHD6oxymvHX4PdascpDackfQ1nNJ+BgcCAMklHmUaviVCAxPcyX8LRMCbCEymreIwIw5Ky9r4EHbj4DlQ4Kgqegfsn/aZnsN1+Mg4FWxA7D0pHwIUDLy/P6m7JogxdhKI4cD6jI5SUDtyQgXvtXtgstowc+J6+PXCXuRWxBFIMYtY0osYYofT20jTseBVDJhEKAEXAzU7rj40ew1zfXLRU0OoxOgHvSy3gTpsTZZYyJUIRy6klc+BN3iac1niakoMPBgbxyP5HcHrj6bqJP0Y2tGwAAKUM0cyBA/H3Mlw4ARdCNRgYzHjJNvF9Tyk6y5dTKeFUrxmZB+I7sKByQUEjlPHJcWz874244vdXJFwnDtTZHECLRWkJuMtlOoMwFcmcsIgcdBGKhc/oCMUsAxcCbnTgjDHUuGoycuB7+vZgRd0KWvUojtfu1f0glEHMqnqUMSsquVN14Mfig4xzaTGNVJ0ItayuX42h4JCyqpIgEouga6wLrRWtioCLssLh4LBye62A+yf9ShUKY0zX0EociJI5cIBilFeOvYIDAwdwwf9cgI6RDnzjgm+k3f/ysnJFwHv9NJdNm4EDhXfg4swixmNp+8kIxPc95e0vuABobweWLct3F6cMRcCrFiAUDRUk1ojxGG5+6Ga81fMWDg0eSrheHKgzLdEtJqUj4OPjWccnQGK1hkCJUAKaCMUSK7gDL1YVijEaGgoMwcqsOpdZW16buYBr8m9AFR3hjpUIxe4GqqtRF3WoAt5BJX9oJQefjQMHEgcyu8a6EOMxzPXNVXqQCAcu3Ddg4sBt6tmZtqWsqBSZXzk/6b5csfgKRHkU6+5eh8NDh/GXD/wFly2+LOX+2yw2rGteh9c6XwNAzqzSWZlgAjx2T0HdoTYGyTQHF9/3dO0LxGdYKojvwHzffACFycH/bfO/4ZH9j2Bl3UoMB4cTTJh04LlgaCWbKckycNNBTBYteBlhQatQwqoDZ4zBYXXoHHiVq0rXs6OmvCZtFcpoaBSdY526/Bsg0eHgygFIGcQscwM1NagL2dTHFgIuHHgGg5iA2pbVKOCiBry1ohUOmwP17npVwOP5NwPTxUPaCAWAzoG/1PESAODcuecm3ZezW89W9vfJm5/ExQsTe6WbsWHOBuzo3oFQJJRQAy4olgMHMhcR8X2fCbltIdE6cCB/Ab9/9/349pZv49a1t+Ifz/5HAPrB8nA0rBw0zSZ/TTWlJeBZVqAA6TNwf9iPSY8LMQZEWAEz8BwjlGRT3znnCEVDyoFBPIcQ2KHgkBKfCGpcNWkzcOFojQIuSu6Ec9R2+0NNDeoCmoZWx47RwbWK8vfh4DCszKoTVDPq3HVocDckCLio+xbrm7ZWtCoRyt6+vXBYHVhSs0SZQh3jMQQiAd3zaVvKvtTxElbUrkCdO3kzNZvFhidvfhLbbt2WUuiNbGjZgMnoJHZ070CPvychPgEKL+Da8shMxjiisagi3JlGLqVC/0Q/nDancuDMdyDzzlfvxJr6NfjZO3+GJi8N6naNdSnXi5gMkA48O3KMUJJm4Jr8asgeLeh6mKmeNxUdIx3w3uHF04cTZwWKA5A4MIjn0Dlwp35RJLMM/JfbfonzfnOeMg1eTAU3c+CA6mj8YT8YGL2umhrUaRtadXTQqXfc/Y+ERlDprNSdDSTDrBJFceDxQdWWihadA19asxQN7gbFfYmDpMjAASgtZaOxKLZ0bMF5c89Luy9nzTkLS2uyG8ATCz28dvw1mkbvmQIHnmWEonXds86BB/pRW16rGI583+e2oTZsaNkAu9WOJg8JuHaMRuTfgMzAsyPHCMVsVh6gP3oO8gBC8yhrLZQDtzAL7FZ7VhHKi+0vIhAJ4Ddv/ibhOu1qPAKtgJs68HJy4Noqj2ePPIstHVvw0N6HAJCAO6wOLKhcoLuvUcC1zaJQXY3a4TD6J/rpsTs6lPgEIJFIVUKoRUyG0VZTHBs9hipnlbIPLRUtiivf278XK+pWoLa8VhFw3dlBHJGB7+rdhdHQKM6bl17Ac6HZ24zWila82vnqtEQomThwrdCkzcBLjIGJAdSW1yrflXzGGsYnx9E30af8FoQDPzGmCrg2TpERSjbkGKGIU1rtkROgN19knoPBIYS2UiVBoRw4EF/YOIsIRUwe+fOBPyfcT7sepu7xNXXgooRQUFtei3AsrBMP4W6/9/L3wDnHnv49WFa7DFaLvronmYADIAc+GEAkFiFBOHYsQcDT5d+C1fWrMRGe0C14cGz0mK6kUUzm6fP34cjQEayoXYEal5rvKyWO2gzcThn4S+2Uf58/L3EBi0KxoWUDXmx/EcPB4SkRcG2EkslpvPY2s86BT8QduD1/B35k6AgAYGEVLcZRW14Lm8Wmd+DxAUwrs9IckmmmdAQ8xwilxlUDC7PosiuAvtSLqhYBIIcSspADLJQDB7JfVm1r11blx/7k4Sd112lXpBfoHHhgCNXOxAwc0FdrtA+3o8pZhe0ntmPzkc3Y27c3IT4B1KXHRKboD6tleqipQd0wRTB9g8fR7e/BJ1vexIvtLwJI34lQi1klSsdIh5J/A1BKCTcf2QwOjhW1qgPnnKsljmXq90M48Bc7XsRc31zd4xWa9XPWKzlpsgglHAtjMjpZkOcbCY3AbrWj2lWdUYSidYqzzYELAVcceB4Z+JFhEnAxIGphFjS4G0wjlEXVi6QDz4ocHbjVYkVtea1y5ATU1quLqknABwODyuLAhXTgWoFNRzgaxpvdb+Kjp30U1a5qPLDnAd31pg48vlhFjMcwHBxOcODG2ZjBSBA9/h78/Zl/jwZ3A77+wtdxdPgoVtYmCnhaBx6fzHP/a/+F0z4J3IVtuPx3l2Pzkc1ZOXDR1U8r4MdGaBq9QAi46Bi4sm4lastrEYlFMDY5ZhqhVDgqEIlF8Gzbsxnl3/kgJvQAiZN4gMI3tBoJjqDCUZFxnb9w4E6bc3Y6cFdhMvC2oTYAqgMHKEYxRiheuxfN3mY5iJkVOWbgAMUovROqAx+fHEckFlEc+GBgUOmVUlAHbsvcge/u3Y1gJIiNrRtx3fLr8Oj+R3XinywDD4QDGAmOgIObVqEAak4qcuSlNUvx2fWfxZaOLeDgpg48YRBz0q863JoapaHVv731Y1QHgOfW/BCLqhfhynuvxJGhIxkLeIWjAnN9cxUBnwhPYCAwoHPMIk556vBTsDALltYs1TXr0i6nJhBnAEPBoaLGJwCwtmmtsoRaMgcOFE7ARydH4XP4yIFnkYEvqFwwq6pQIrEIhoJDBcvAjwwdgcfuUX43AI1xGB14g6cB1a5qOYiZMZznHKEA5Iq0Dlz7hWZgRXPgrjLzDHxP3x6svWutrjxJ5N9nzjkT16+8HmOTY3jq8FPK9WYOXDh84QQSqlAMDrx9pB0AMM83D58681PKl35FnX4SD2BeRqh14AuHgGpbBT7sORdb7wYuOOUabL5lM5ZUL4E/7M84QgGAUxtOxbNHnkXPeI9ykNE6cDGZ59joMSysWgiHzaETcCVCMVShCIrtwF1lLpzacCqAxFmYQHEcuM/pQ015TVYZ+PzK+bMqQhGvq7a8lgbY8+z62DbchoVVC3XVU00evQMXC3ZUOatkhJIxk5PUMCmHCAWIO3CT+s2a8hpUueiDKIYDTxahPNv2LHZ078D/7vxfZdvWrq2ocdVgQeUCXLjgQlQ5q/DHPX9UrjfLwIXDFwckowMXIidcmhjAnOubi0pnJT591qdR5azC4urFCftoVkaoCHh1NaoDQP/SX+M3E5fCHQbQ0oI6dx2eveVZvHPJO3HRwosyfp/+36b/h9HQKG548AblNFbrwMVkHkDtmGgm4MYqFHE7scpQMRExypREKPExhkwjlKHAENxlbtS764saoYSj4Yx7sxQCMbZTW14LC7PAbXfnl4EPHUmoxmryNKFvok8Zv+jx96DR04hqV7WMUDImx17gggZ3g75+M6AKXpWzCoPBIjnwJBHKgYEDAIDf7/q9sm1r11asa14HxhjKrGV41/J34dH9jyr7lZEDN2TgVc4qMDDli94+3A4GpmTK39z0TRz89EHThk0OqwNWZtVl4NpBTABgg4NUgVJfDzhpv+rcdXjsA4/hqqVXZfw+ndZ4Gu666i48f/R5fO7JzwGArgoFUHNwIeDi7CKZgAsHft7c8zKqR8+Xf9z4j/jNtb/RnQUIipWBZxqhDAapQindQtKZEI6G8e77341tXdsSrjvtrtPwjedT94/J5fmSdazUCjhAA++5vseccxwZPqLLvwG1lFCcwXePdysOPBQNFbTXUS6UhoDn2EpWUO+ux/jkuPJD10YO4khalAw8SYRycPAgAMq93+p5CxPhCbzd+zbObD5Tuc31K6/HaGhUGbhLVQeuPSBpsVqsqHRWKi6tY7QDzd5mlFnLlOuFEBox9rE2RigAgIGBhBrwXLnl1FvwqXWfwoGBA2BgSmwiUAS8LtGBizJCbRWKyOCLHZ8I5lfOx4dP+7DpdQXPwEOjFKG4ajA2OZa2gdNQgOYIVDorMRoazcsld4514k/7/oTNRzbrtnPOsb9/Px7a91DOj23Gf279T5z6y1NN10VNEHCHN2cH3uvvxUR4wtSBAzSZJxwNYzAwiAZPg2KWptuFl4aA57iYg0AMLIkYRRs5KAI+hVUoBwYO4JKFl8DKrPj9W7/HjhM7EOVRnDlHFfBNCzaBgSlOJ2kdeDiQNAMH4pN5RAY+3I55lfMy3n/tD0I3iOl0UlvfwUF1FmYBuPOyO7F+znosql6kHGQEIhMXDtzn8MHKrBiYGDB14KvrV+N7F38PHzn9IwXZt3woWoQSP/hqRWQoMKTLbMX1Vc4q+Jw+cPCMB/qMS9kBahxndPIT4QlEeRS7e3frJrvky2MHH0OMx/C3Y39LuE4IuHgf8mkaZiwhFGgn8wj9EBEKMP2zMUtLwPNw4IAq4NrIodpVXbQM3CxCCUVCODp8FBtbN+LyxZfj3t33Ku1ItQ7caXNifuV8ZeX2VHXgxl7gWrT9UDpGOjDPl7mAJ3XgALnwgYGESTz54LA5sPlDm/HCh19IuG5ZzTI4bU7FgTPGlFpwMwG3MAu+eM4XM66GKSaFFHDOOUZDo0oZIaCfTn/747fjmvuu0d1nMDCoOHAgs8k8Wzu3Yu6P5+K146/ptovnMg6Gav82uvNcmQhPKHMLRMdHLYqAx9+HfCIUsxJCQO/AxYFJRCjA9M/GLA0BzzNCEQNLIscaCgyhzFIGd5mbMvBiVaGYzMQ8PHQYHBxLa5bipjU34fjocfx868/RUtGiHO0Fy2qXYX9/XMDjBwKzZlYDEwNw2Vy66wSipWyMx5RFEjJF21I2QcCrq4FDh+izKZCAAyTCzd7EFWFuPeNW7P7Ubl11SW15LfoDVEZos9gSXPtMoZAC7g/7EeMxpYwQ0E+n39m9E3v79uraJ4g2C2ZLzSXjuaPPAaDvqxbFgRsFXOPIn217NpuXlJSX2l9SGrgJk6Olf6If7jK3Ymo8dk/OEYqYhWlsOdzgaQADw4mxE+qCHfEyQkBGKJmRZ4Ri5sBF61VRzykiimJXoYgBzCXVS3DNsmvgLnPjyPARnfsWLKtZhgMDB8A5V5tZGTJwgEbGjfm3QLSU7RnvwWR0MisHLhxNMBIEB9dlzKipAXbG15Ccgh7SDptDmXil7EL8tWnXw5yJiH0rhIALoRRlhIAqIjEew+Ghw/CH/bpTe22EAmTmwIVgGtsRi7+Nj6FdxOOZI8+kXjw5Q546/BQcVgduOeUWbD+xPSHrF7MwBV5Hfg680dOY0EHTZrGh3l2PE+Mn1CXz3GoGLiOUTChQhKJdSUMIXrWrGjGudtYreB24IUI5OEADmEtqlsBtd+PdK94NAEkF3B/2o3OsU3Hy2v0TAt411pVcwOMRiqgBz9aBJ5vpiJoaYCzudgrowLNBG6Gka107nVgtVrhsLlNxifEYfrH1F2i9sxUvd7yc9rG0QmmMULrGupQDvSgZDYQDCEaCugglXSUK5zypgCsRiuExhKBfvexqdIx0JDj3XHiq7SmcN+88bFqwCcFIELt6d+muNwq4pyy/DNw4gClo8jaRgGscuIhQMnHggXAA27u2K7+jQpKxgDPGrIyxHYyxv8T/vogx9gZj7E3G2BbGWGIxcaHIM0JxlbngtXv1Djz+AQjhEwM/hc7AJ6OTuh7fBwYOoN5dr/yYPnIaDbK9Y/47Eu4vWpvu79+PYCQIh9WhW/ZMuPGusS7T/BsgAfeH/Yrzz2YQU0QoSpWH3eDABdMl4K5apQplJgs4YN7Q6tDgIVx4z4X4+7/+PY6PHsffjicO1BkRwlnhqFAnasVjDWEOABqwBvRrpYoIJZ0DPz56XJl9qPR8j5MuQnnPivcAyD9G6RztxO7e3bh04aVYP0dt2aul0A7cmH8LmjxN6BrrUqbRl5eVw+f0gYFllIHv7NmJdb9aV7BoSUs2DvyzAPZq/v4FgJs456cBuBfAvxZwv/TkGaEAdNQ0c+BC+MQXtpAOXDyHdsblgcEDup7TmxZsQuc/dGJj68aE+y+rpbUJDwwcoPUwNQOYQIYOPP4j33FiB4DsHbi2/DLBgQNAWZmymPFUU1tei4GJAX2jrRmKUcC7x7tx+l2nY0f3Dvzq6l/BYXXoZgsnQ3Qi9Dl9cJe5UWYpU1yxdv1G4cC1JaaKA0+TgQv3bbPYlEUzBMkcuHjMdc3r0FLRgmeOPJP2taRClM9euuhSzK+cj7ryuoSBzAQHblgGMFPC0TCOjR5L7sDjszHFNHqABskrnZUZRSjas+5Ck5GAM8ZaAFwJ4NeazRyAGFHyAegy3q9g5BmhAPrZmNrWq4oDjwt4qlXIs0W46mfa1C/zgYEDWFKt/yDNBu0AmkLuLnNj/8B+3XqYAvH32OSYaQkhoNbIvtH9BiqdlSkX9jUiFjY26zWC6vgBo6UFsExPEldbXosoj+LE2ImSc+C7e3djfHIcD1z/AD6+9uNo9DSi259Yfvfa8dd0g5TaCIUxpptOf2jwEOxWO5w2pxKZaRe7TtYb38irx1+F0+bEGU1nJI1QEjJwzTJ6Fy+8GM8deS6vevOnDj+FBncD1jSsAWMM61vWpxVwr90LDp51VNEx0oEYjyV34N4m9Ph70DXWpZtpm+lszIODB2FhlqSPnw+Z/vJ+DOBLALSfyMcB/JUxdhzABwF8x+yOjLFbGWPbGGPb+vr6zG6SnvFxEglH7u5Y2w9F23pVCHj3eDfKLGW6iCJf1tSvQYO7QXETY6ExdI93Z7zqC2MMS2uWYv/Aft2K9AKtI0+VgQPkwLNtqeqxe+AP+xXhSRjEBKYtPgHUg1P7SHvJCbgoSROfSYOnIcGBR2NRbLpnE77/yveVbdoIBdCvunRo6BAWVi3EXN9c1YGLCMVZBbvVDpfNpRPfrrEufPW5r+pa3b7a+SrOaDoDzd7mpBGKcULQSGgEVmaFu8yNixZchIHAAHZ278z2bQJA4wJPtz2NSxddqvwe189Zj339+5R9n4xOYmxyLMGBA9m3lE1WAy5o8jQhxmPY3bsbjZ5GZXuVqyojB35g4ADmV84vqDkUpFUrxthVAHo559sNV30ewDs55y0AfgPgR2b355zfzTlfxzlfV1eXfE3ClIhWsnlMiRYOPBqLYiQ0ohvEBCgDL2R8ApAAX7zwYjzT9gxiPKbMwMxm2S5RSpjKgQPmk3gANUIZmxzLqgIFUH8QwoWZRijTuIq5eG29/t4ZXYUCJAq4EGshCI2exoRFR/om+hCIBHQDgtoIBYBuOv3BgYNYXL1YJ+BaBy7up41Q/vj2H/HNF7+J3+78LQASxjdOvIH1c9ajrrwuqQPn4LrXMxwcRoWjAowxXLjgQgD6M890cM7RNdaFztFOPNP2DPon+nHpokuV60UOvrVzK+1H/DUbM3Ag+2of40IORkR572BgUOfARQlyOg4OHkw46y4UmdjNcwBcwxg7CuA+ABcyxh4DcCrnXJzT3A8gMcQtFFVVwKpVeT2EWENRfCFFhCKELxAJFHQAU3DJwkvQN9GHt3re0pUQZsqymmU4OnwUw8HhhAxc68jTOXAgu/wbUH8QQlhMBzFngAMHUHIOvMffA4fVoTjpBndDwgxGMXainRE5EhoBA1MOrmKmLecchwYPYUn1EszzzVMiFJGBi+97pbNS58CF+/zuy99FNBbFWz1vIRgJYkPLBqXKR+u0ByYGlOfWRjEjoRHloNLsbcaymmXYcmxLxu/P917+Hub8aA5a7mzBZb+7DAxkfgRilrKIUYzT6AHk3FK2bagNZZayhPYNAjGZB9C3CxaTAFPBOcfBgWkUcM75VzjnLZzz+QBuALAZwLUAfIwxYSUvgX6As7B89avAK6/k9RD17npwcMUFC8Fz2BzKj7/QDhwALll0CQDK9ISAm3X/S8aymmXg4NjVsyu1A09WhaLpdZKrAxduUSeS9fG2qfPnZ/WYhaTUBbzB06A02hIGQ1uxJARcuGlAbWQlooUaF2XgJ8ZPIBAJKA68e7wboUgIg4FBWJhFOVD4HHoHfnT4KKzMioODB/HQ3oeUAUwh4FEeVYRaxBbCqWoPBCPBEd2s19MaT8OuHn3ZXyrahtrgc/hw91V34+6r7saTNz+piysqnZVYXrscr3W+hrHQmBIracU112XVjgwfwVzf3IRlBQXaCXa6CMWZPkLp9fdibHKsKAOYAGDL5U6c8whj7BMAHmSMxQAMAfhoQfeswIha8H39+wDoI4dqVzUmwhNFceDN3masqluFp9ueRqOnEXN9cxOcdCpEJUqPv0dZfkygFfBkDtxpc8Jd5oY/7M8pAxfPDRhEctEi4A9/AK6+OqvHLCRaAS+1CEV0tRM0ehoR4zH0T/QrLk8I+InxEwhFQnDYHBidHNUNRIs6f1HpsLh6sfI5HRs9hsHAICqdlYrgGysnjg4fxaWLLsXhocP49pZvY2XdSjR7m9FSQe2BAXK7VS41LlhYtRBv9bylOxAYl9E7peEU3P/2/RgLjSlncqkYD4+jzl2HT5zxiaS3WT9nPR7Z/whOu+s0HBk6gi+f82Vd9VauGXjbUFvS/BswOHB3ogPnnCfteCkM43RGKAqc8+c551fF//8nzvkazvmpnPMLOOdtRdnDAiF+FELAtYKndePF4JKFl+Cl9pews3tn1h+kNi83OnDtgSBZBg6oLjybGnBA/UGI6p0Ekbzhhrwqg/LFa/eizELT50vOgY/36Nyc+H5qY5TO0U71/2P0f7GYg6DaVY1QNISdPTRguLh6sXKm1THSoSuZBeIZeFDvwBdVLcI/nfNPeLP7TTyw5wFsaNmg9JoBoExyE7nzwsqFyr4IjPu1pn4NACRtBWtkfHI87UF4Q8sGDAeHwTnHix95EXdcfIdOOI2LkBgZCY6Ydm48Onw0aQkhQLog3kNthFLlqkKUR1MeMMSBNZtxr2wojZmYBSDBgWsiByF+xXDgANWyhqIh7OrdlfUH6bF7lGwuWR04kNyBA2oOnnUGbtdn4DNNJLUiM9P2zYjH7kEgElAikh5/j87NKf16NAOZ2vkDIkYxOl1xcH6t8zWUWcp0Czh3jHQojawEPodPiT6GAkMYCY1gfuV83HzKzWipaMFkdBIb5tDiFNqWvYA6gClaGqRz4ADwVs9bGb0/45PjimFIxodO/RDuvupu7PzkTpw799yE61NFKJFYBMt/vhw/eOUHuu0T4Qn0TfQl9EAxIly4cRATUAeKOecJlUQHBg7AZrFlbZ4y5aQRcPHGT4cDP3/e+UoJUS5HYhGjJDhwzSBmsgwcoB95maVM5/gyQZuBl1nKZmSzKCFgpSDggNqMqs/fp3Nz4rPRCkDXeJcSlygCbnC64uD8eufrWFC1ADaLTemd3j7cjqHgkO7srNJZqQjv0eGjAKCUuH3h7C8AgBJL1JWrEQqgceAmGfhwcFgn4HN9c1HhqEiY/p6MTATcVebCJ874RNJIJlWEsrN7J7rHu7Gje4duu3hf040PiRzcOIgJqAPF//f2/6H1zlalsyFAEcrCqoXKmqmF5qQR8EpnJcosZcqouzEDB4rnwN12t/KjyEnAa0jAjXXgQtAZWMo1KOf55mFZ7bKsa9y1EcpMFUjhEkthJiZAQjUwMYAoj+oduEmE0jXWpfTIEUIjWskKxAHs0OAhZXDcYXOgydOU1IEHI0GlrTGg1j9/+qxPY/Mtm5XvqhKhxGvBhQMXAi4iFNHiVntgYYxhTf2agjrwdKTq+vjyMeozoxVXQH8QS0WTp0mZRi8wNrR64vATCMfCePzg48ptillCCJxEAs4YQ727HjEeg8fu0bnJYjtwALhs0WUAkNP6jELAk1Wh+Jy+pCPoAPD9S76PJ256IuvnVTLFybEZK5ClFKEAJC5CpLVnRF67F06bMyFCWVS1CPXu+qQRilacF1ep1U1zfXPRMdqBoUCiAxePI8yMEC+rxUoLicRzZbfdDZfNleDA53jnwG61K05+fHIcMR5L6L0uBDyTqe3+SX/eAl5mLYPD6jDNwJMJuOgZky7i+NyGz+Hn7/y5bpuxpazoXf5UGy1Gri3tLBYnjYADag5uHPArdgYOkLt59IZHc5pOKyIUowMvs5bByqwp82+AnMKcCvMa11Rof1AzVSBrXaUn4NqudgLGmG4yz2R0Er3+XjR7m3UTc0aChgxcU+evLU+d65uLo8NHTQcxxeMcHT4Kr92bcgBc9FwHyIE7rFR2q83StdP7tZzScApGQiOmy6EZKYQDB8wbWnHO8XLHy9R8Kjikq90+OnwUZZYyXaWJGWub1uKDp35Qt027qEPnaCfahtrgsXuw+chmTEYn0TXWhYnwRNFKCIGTTMDFD8YoeFPhwN12N65ellvJnRKhmJQfOm3OlD/AfLBb7TO+ykOJUEqgjBCIC7imr7QW7WQecTmnYg5aK1pxbPQYQpEQQtGQaYQC6JslzfPNw+HBw4jxmG58RLsqz9Hho1hQtSDlos+15bVqhDIxgJryGjDGdDM6tT3KtWQzkFkoATdb1KFjpAOdY53YtGATAHXyEkBtGFp9rSnPYJOhdeAvdbwEAPjc+s9hfHIcrx5/NaeZ19lyUgm44sANA37FzsDzZa5vLq5aehXOaT0n4TqnzZnWgeeD+FHNVIEsxQjFzIED8en0cXEXFShaB26cRg/QQVY8ttGBc1B0YczAATVCSZf91rnrdFUowvFrV7hP5sDFvIV0A5nhaBihaKgwDtxkWTURn3zwFHLQ2hjl6PDRtO9BMsrLylFmKcNQcAgvtr8Ir92Lz5/9eViZVTdxT0YoBUI4nulw4PlgtVjx5xv/rMzq1OIqc6WsQMkXkYPPVIEstSoUkYHbrfYEwWtwqy2PjQI+PjmuDLgZ71ftqoaVWXWVFNpMV/t9Nzrw+b75KfdbTKcHSMDFAVNbzSKiFKMD9zl9mOebl9aBi37zxXLgL3e8DI/dg2uXXQtAL+DtI+1Zz1AWMMaooVWABHxj60ZUu6qxoWUDnjz8JA4OHITD6kCrr3j9gopT2zJDSZqBu4qfgReLOy66oyhtKgWKA5+hg5gXzL8A717xbqyqz69XTrExOvBGT2NCdNHgaUCfvw+RWCRBwAF1UoxRKGtcNQllntqaf+33Xdy3bagN45PjKWcgAjTGoJ3II95nn9OHE/3UglmJUEwqodY0pK9EMe12mSNeh1c5UxG8fOxlbGjZgCpXFWrLaxUBD0VC6BrrylnAATo4Hhw8iLf73sYH1nwAABUsfO35r8Fpc2JR9aKCdjg1Ih04Zn6EkoqbT7nZdDGIQiGEZ6Y63JaKFjz4vgcL4t6KiTEDN+bfAEUoHBz9E/3oHO2EzWJDbXmtIsYiijD2dL9s0WXK0nwCrYCbOfA3u98EkL58rs5dh9HQKCajk+if6E8ZoRirUADglPpTsH9gv7JouBlCwAvmwDVVKKOhUezq3aXEjwurFioCfmyUmoTlGqEAdHAU+ff5884HQBP3ODi2dGwpanwCSAcOYOZHKNOJIuC2mSngpYLRgYvJNlqU2ZjjPega70KTpwkWZkkQcKPTvePiOxIeq8pZpUzf10ZsHrsHDCxjAdfOxhwMDOoFPM0gJkADmZFYBPv69+HUxlNNn6OQAm7MwF89/ipiPKbM3FxQuQDburYByLyEMBXVrmpEYhE4rA6lZn9d8zql0VUxBzCBk82BJ6lC8dq9aHA3mP6oTnbE9OSZGqGUCqKiJ5UD107m6RrrUlZqqnfXw261K939zITSCGNMEX6tYRGdCfcP7AeQuYAfHjyMKI8qYw4+pw/jk+OIxCIYCY3AZrEllLkCFKEAqQcyxYpPxcjAt3RsgYVZlH7iC6sWon2kHZFYJONJPKkQB8cNLRsUA2i1WJVWuMV24CeVgC+vXY4bV9+IixZepNvOGMP+2/fj78/8+2nas5nLTI9QSgmP3YPR0Ch6/b2mbQ2U6fTx5btE7b6FWdBS0aIMcKaadatlrm8uXDZXQvlppbNSmXhjFntoEdPpRQsK4cDF/UZDo8o0erNyxKU1S2G32lPm4IV24NoI5eVjL+PUhlOVwfiFVQsRiUVwfPQ42kfaYWGWpH3AM0EcHEV8IhCLURTbgZ9UEYrT5sS977nX9LpMXM3JyEwvIywlPHYP2kfaE6bRC8Q24cAvnH+hct1c31wlu810XdO1jWtxYuxEwnaf0weMZOY8hQMXjl1x4A51QpB2MQcjNosNK+tWTp2AO7wIx8KYjE6Cc47Xjr+Gj5z2EeV6MeDfNtSGo8NH0VLRklePH3E2f97c83TbP3jKB2FhFpw37zyzuxWMk8qBS7JHRCjSgeePx+7B4UFaHs1YAy6uLy8rx5GhIxgODusWuxZxiMvmylhwvrHpG/jbx/6WsF2451QtVAVCwI0OXJnRGRpJWMzByJr6NSnbyhZ6EBOglrL37b4P/rAf1yy7RrleK+D5lBAK1jatxaKqRTi79WzddofNgY+e/tGiVqAAUsAlaZARSuHw2D2KizZz4IwxNLgblI55OgGvIAHP5kzRZrGZzt4V7jkTBy4cd1oHniLWWVO/Bp1jnUmXHyt0hAJQ/54fv/ZjrKxbqVuaraWiBTaLTXHg+eTfAHDNsmtw6DOHpq0KSgq4JCUzvQ68lPDYPQhFqZwuWWvfBk+DsjiDmQPPND5JRTYO3GaxocpZpSz8a8zAh4PDCS1ujaSbkanUgRfgOya+r48deAxvdr+Jz63/nC6bt1lsmOebhwMDB9A52pm3A59upIBLUiIdeOHQujSzCAUgYQ9GggDMBTzTAcxUZOPAAShrYzIwRbh1EUo6B96QenWe8clxlFnKlJ75+SAGK7/78ndR46rBzafcnHCbhVUL8VLHS4jyaN4OfLqRAi5JifhByEHM/BECbjaNXqCNVkwFvACD7UKEMxUvsTZmlatKafqkjVCMizkYmeOdg0pnZdJFjgvVyApQ3+Njo8fwd2f8nWmEtKBygbJMYLFWypkqpIBLUiIdeOEQ72WDuyFpB0Ah4C6bSzcwKPppFMKBL6haAI/dk3YavUAMZGpb14oDyVBwCGOhsZQHFsYYVtevThqh+MP59wIXiAzcZrElLQvWtp6QDlwyq1k/Zz2uXXZt0ll0kswRIpVqaTtxXbO3WSfyHrsHteW1Bek8ecupt+DwZw5nLJqi57q2da3daofL5sLx0ePg4GnryUUlitniDsVw4NevvD5pD3ytgLdWFK/R1FRwUtWBS7KnwdOAh294eLp3Y1agOPAk+bf2Om18InjofQ8VZLawzWJT2kpkgohQtA4cIBcuFppId2awpn6NsriDsTtfIQV8fuV8fH7D53HbmbclvY0Q8GZvc8m3z5ACLpFMEdoIJRniOjMBL/akkGQoEUq5QcAdPrSPUD+RdNm8thKlmAJutVjxo8t+lPI2QsBLvQIFyCJCYYxZGWM7GGN/if/NGGPfYowdYIztZYx9pni7KZGUPpkIuDZCmSmI6fT5OHAh4GaVKIUU8EyoclWhyllV8vk3kJ0D/yyAvQBEIeqHAbQCWM45jzHGMj8nk0hOQjKJUJq9zahwVGBV3czpb242iAlQNctEeAJAegde5apCS0WL6UDmVAs4ANz7nntnhQPPSMAZYy0ArgTwLQD/EN/8KQAf4JzHAIBz3luUPZRIZgmZDGK6ylxo/1y7Uk0xE0gVoQjSDWIC5MLNSgnHJ8envEz18sWXT+nzFYtMI5QfA/gSgJhm2yIA72eMbWOMPc4YK27fRImkxBFRhHaxBTMqnZU5LbJbLJbWLMWymmU4a85Zuu1aAc+kvHFN/Rrs7d+LSCyi2z4dDny2kFbAGWNXAejlnG83XOUAEOScrwPwKwD/neT+t8ZFfltfX1/eOyyRlCrnzj0XL374RaU3dalQ5arCvtv3YW3TWt12bWySyQSj1fWrMRmdxMGBg8o2zrkU8DzIxIGfA+AaxthRAPcBuJAx9jsAxwE8FL/NnwCcYnZnzvndnPN1nPN1dXV1BdhliaQ0YYzhvHnnJZ3EU2qI2MRutcNpc6a9/Zr6xMUdgpEgOLgU8BxJK+Cc869wzls45/MB3ABgM+f8ZgAPA9gUv9k7ABwo1k5KJJKZh4hNMp0duqJuBSzMoqtEKWQnwpORfOrAvwPg94yxzwMYB/DxwuySRCIpBURskml/FqfNiSXVS3QOXAp4fmQl4Jzz5wE8H///MKgyRSKRnIQI551JBYpgee1yXQYuBTw/ZC8UiUSSE0pr2SwabDV7m3FiXF3mTQp4fkgBl0gkOZFthAIATZ4mDAYGEYrQwhaFXMzhZEQKuEQiyYlsBzEBdRJTj78HgHTg+SIFXCKR5ITiwLMQ8CZvEwDgxBjFKFLA80MKuEQiyQmfwwefw5fVqjZNnriAx3Nwf9gPQAp4rsh2shKJJCesFiv23LYnoclVKqQDLyxSwCUSSc5k2/a23l0PBqY4cCHgcsm+3JARikQimTJsFhvq3HXoHu8GoHYitDApRbkg3zWJRDKlNHmadA5cxie5IwVcIpFMKU3eJl0GLgU8d6SASySSKcXowOUkntyRAi6RSKaUJk8TesZ7EI1FpQPPEyngEolkSmnyNiHKoxgIDMAf9ksBzwMp4BKJZEoR0+lPjJ2QDjxPpIBLJJIpRTsbUwp4fkgBl0gkU4p2Nub45Dg8ZVLAc0UKuEQimVKkAy8cUsAlEsmU4ipzwefw4fjocQQjQSngeSAFXCKRTDmNnkYcGjwEQDayygcp4BKJZMpp8jYpAi4n8uSOFHCJRDLlNHma0D7SDkA68HyQAi6RSKacJk8TYjwGQAp4PkgBl0gkU44oJQSkgOeDFHCJRDLliNmYgBTwfMhYwBljVsbYDsbYXwzbf8oYGy/8rkkkktmKqAUHpIDnQzYO/LMA9mo3MMbWAagq6B5JJJJZj4xQCkNGAs4YawFwJYBfa7ZZAXwfwJeKs2sSiWS2Ih14YcjUgf8YJNQxzbbbATzKOT+R6o6MsVsZY9sYY9v6+vpy20uJRDKrqHRWwmF1AADcZbIOPFfSCjhj7CoAvZzz7ZptzQCuB/CzdPfnnN/NOV/HOV9XV1eX185KJJLZAWMMjZ5G2Cw22K326d6dksWWwW3OAXANY+ydAJwAKgC8DSAE4BBjDADKGWOHOOeLi7anEolkVtHkbcJIaARxDZHkQFoHzjn/Cue8hXM+H8ANADZzzqs4542c8/nx7RNSvCUSSTY0eZpkfJInmThwiUQiKTifXf9ZHB46PN27UdIwzvmUPdm6dev4tm3bpuz5JBKJZDbAGNvOOV9n3C5nYkokEkmJIgVcIpFIShQp4BKJRFKiSAGXSCSSEkUKuEQikZQoUsAlEomkRJECLpFIJCWKFHCJRCIpUaZ0Ig9jrA9Ae453rwXQX8DdKRVOxtd9Mr5m4OR83Sfjawayf93zOOcJ3QCnVMDzgTG2zWwm0mznZHzdJ+NrBk7O130yvmagcK9bRigSiURSokgBl0gkkhKllAT87unegWniZHzdJ+NrBk7O130yvmagQK+7ZDJwiUQikegpJQcukUgkEg1SwCUSiaREKQkBZ4xdzhjbzxg7xBj78nTvTzFgjLUyxp5jjO1hjL3NGPtsfHs1Y+xpxtjB+GXVdO9roWGMWRljOxhjf4n/vYAx9lr8876fMTbrVr1ljFUyxh5gjO1jjO1ljJ092z9rxtjn49/t3YyxPzDGnLPxs2aM/TdjrJcxtluzzfSzZcRP46//LcbY2myea8YLOGPMCuDnAK4AsBLAjYyxldO7V0UhAuALnPOVADYAuC3+Or8M4FnO+RIAz8b/nm18FsBezd/fBXBnfJ3VIQAfm5a9Ki4/AfAE53w5gFNBr3/WftaMsTkAPgNgHed8NQAraI3d2fhZ/w+Ayw3bkn22VwBYEv93K4BfZPNEM17AAZwF4BDnvI1zPgngPgDXTvM+FRzO+QnO+Rvx/4+BftBzQK/1nvjN7gHwrmnZwSLBGGsBcCWAX8f/ZgAuBPBA/Caz8TX7AJwP4L8AgHM+yTkfxiz/rEFr8LoYYzYA5QBOYBZ+1pzzFwEMGjYn+2yvBfC/nHgVQCVjrCnT5yoFAZ8D4Jjm7+PxbbMWxth8AKcDeA1AA+f8RPyqbgAN07VfReLHAL4EIBb/uwbAMOc8Ev97Nn7eCwD0AfhNPDr6NWPMjVn8WXPOOwH8AEAHSLhHAGzH7P+sBck+27z0rRQE/KSCMeYB8CCAz3HOR7XXcar5nDV1n4yxqwD0cs63T/e+TDE2AGsB/IJzfjoAPwxxySz8rKtAbnMBgGYAbiTGDCcFhfxsS0HAOwG0av5uiW+bdTDGykDi/XvO+UPxzT3ilCp+2Ttd+1cEzgFwDWPsKCgauxCUDVfGT7OB2fl5HwdwnHP+WvzvB0CCPps/64sBHOGc93HOwwAeAn3+s/2zFiT7bPPSt1IQ8K0AlsRHq+2ggY9Hp3mfCk48+/0vAHs55z/SXPUogA/F//8hAI9M9b4VC875VzjnLZzz+aDPdTPn/CYAzwF4b/xms+o1AwDnvBvAMcbYsvimiwDswSz+rEHRyQbGWHn8uy5e86z+rDUk+2wfBXBLvBplA4ARTdSSHs75jP8H4J0ADgA4DOBfpnt/ivQazwWdVr0F4M34v3eCMuFnARwE8AyA6une1yK9/gsA/CX+/4UAXgdwCMAfATime/+K8HpPA7At/nk/DKBqtn/WAL4BYB+A3QB+C8AxGz9rAH8A5fxh0NnWx5J9tgAYqMruMIBdoCqdjJ9LTqWXSCSSEqUUIhSJRCKRmCAFXCKRSEoUKeASiURSokgBl0gkkhJFCrhEIpGUKFLAJRKJpESRAi6RSCQlyv8Hcn4vpR3gfigAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(results[1]['mml-pgg-off-sim']['f'])))\n",
    "\n",
    "mml_mml_off_r_avg = results[1]['mml-mml-off-sim']['r'] + results[3]['mml-mml-off-sim']['r'] + results[4]['mml-mml-off-sim']['r']\n",
    "mml_mml_on_r_avg = results[1]['mml-mml-on-sim']['r'] + results[3]['mml-mml-on-sim']['r'] + results[4]['mml-mml-on-sim']['r']\n",
    "mml_pgg_off_r_avg = results[1]['mml-pgg-off-sim']['r'] + results[3]['mml-pgg-off-sim']['r'] + results[4]['mml-pgg-off-sim']['r']\n",
    "mml_pgg_on_r_avg = results[1]['mml-pgg-on-sim']['r'] + results[3]['mml-pgg-on-sim']['r'] + results[4]['mml-pgg-on-sim']['r']\n",
    "\n",
    "mml_mml_off_p_avg = results[1]['mml-mml-off-sim']['p'] + results[3]['mml-mml-off-sim']['p'] + results[4]['mml-mml-off-sim']['p']\n",
    "mml_mml_on_p_avg = results[1]['mml-mml-on-sim']['p'] + results[3]['mml-mml-on-sim']['p'] + results[4]['mml-mml-on-sim']['p']\n",
    "mml_pgg_off_p_avg = results[1]['mml-pgg-off-sim']['p'] + results[3]['mml-pgg-off-sim']['p'] + results[4]['mml-pgg-off-sim']['p']\n",
    "mml_pgg_on_p_avg = results[1]['mml-pgg-on-sim']['p'] + results[3]['mml-pgg-on-sim']['p'] + results[4]['mml-pgg-on-sim']['p']\n",
    "\n",
    "mml_mml_off_f_avg = results[1]['mml-mml-off-sim']['f'] + results[3]['mml-mml-off-sim']['f'] + results[4]['mml-mml-off-sim']['f']\n",
    "mml_mml_on_f_avg = results[1]['mml-mml-on-sim']['f'] + results[3]['mml-mml-on-sim']['f'] + results[4]['mml-mml-on-sim']['f']\n",
    "mml_pgg_off_f_avg = results[1]['mml-pgg-off-sim']['f'] + results[3]['mml-pgg-off-sim']['f'] + results[4]['mml-pgg-off-sim']['f']\n",
    "mml_pgg_on_f_avg = results[1]['mml-pgg-on-sim']['f'] + results[3]['mml-pgg-on-sim']['f'] + results[4]['mml-pgg-on-sim']['f']\n",
    "\n",
    "plt.plot(x, mml_pgg_off_f_avg/3.0, 'r')\n",
    "plt.plot(x, mml_mml_off_f_avg/3.0, 'g')\n",
    "#plt.plot(x, mml_mml_on_f_avg/3.0, 'y')\n",
    "#plt.plot(x, mml_pgg_on_f_avg/3.0, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gold_fold.1.dev.predictions.step.800.csv 56.83\n",
      "#\n",
      "2 gold_fold.2.dev.predictions.step.2000.csv 65.76\n",
      "#\n",
      "3 gold_fold.3.dev.predictions.step.4200.csv 63.59\n",
      "#\n",
      "4 gold_fold.4.dev.predictions.step.1400.csv 64.44\n",
      "#\n",
      "5 gold_fold.5.dev.predictions.step.900.csv 67.0\n",
      "#\n",
      "6 gold_fold.6.dev.predictions.step.400.csv 69.45\n",
      "#\n",
      "7 gold_fold.7.dev.predictions.step.6100.csv 59.3\n",
      "#\n",
      "8 gold_fold.8.dev.predictions.step.7300.csv 64.1\n",
      "#\n",
      "9 gold_fold.9.dev.predictions.step.1800.csv 67.48\n",
      "#\n",
      "10 gold_fold.10.dev.predictions.step.4100.csv 61.41\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the dev predictions on the RE-QA dataset using the model having access to gold templates!\n",
    "for fold_i in range(1, 11, 1):\n",
    "    fold_gold_file = \"./zero-shot-extraction/relation_splits/dev.{}\".format(fold_i-1)\n",
    "    fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_{}/gold/dev_predictions/\".format(fold_i)\n",
    "    fold_files = [\"gold_fold.{}.dev.predictions.step.{}.csv\".format(fold_i, 100 * i) for i in range(1, 506, 1)]\n",
    "    preprocess_the_prediction_files(fold_path, fold_files)\n",
    "    max_file,  max_f1, f1s, scores = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "    print(fold_i, max_file, max_f1)\n",
    "    print(\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 concat_fold.1.dev.predictions.step.1700.csv 53.96\n",
      "#\n",
      "2 concat_fold.2.dev.predictions.step.4600.csv 64.46\n",
      "#\n",
      "3 concat_fold.3.dev.predictions.step.18600.csv 61.4\n",
      "#\n",
      "4 concat_fold.4.dev.predictions.step.1400.csv 67.12\n",
      "#\n",
      "5 concat_fold.5.dev.predictions.step.7900.csv 69.91\n",
      "#\n",
      "6 concat_fold.6.dev.predictions.step.2600.csv 64.16\n",
      "#\n",
      "7 concat_fold.7.dev.predictions.step.24700.csv 63.0\n",
      "#\n",
      "8 concat_fold.8.dev.predictions.step.13800.csv 61.08\n",
      "#\n",
      "9 concat_fold.9.dev.predictions.step.17700.csv 61.6\n",
      "#\n",
      "10 concat_fold.10.dev.predictions.step.35500.csv 57.72\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the dev predictions on the RE-QA dataset using the model having access to psuedo questions.\n",
    "for fold_i in range(1, 11, 1):\n",
    "    fold_gold_file = \"./zero-shot-extraction/relation_splits/dev.{}\".format(fold_i-1)\n",
    "    fold_path = \"/home/saeednjf/scratch/feb-15-2022-arr/fold_{}/concat/dev_predictions/\".format(fold_i)\n",
    "    fold_files = [\"concat_fold.{}.dev.predictions.step.{}.csv\".format(fold_i, 100 * i) for i in range(1, 506, 1)]\n",
    "    preprocess_the_prediction_files(fold_path, fold_files)\n",
    "    max_file,  max_f1, f1s, scores = unk_eval_the_prediction_files(fold_files, fold_gold_file)\n",
    "    print(fold_i, max_file, max_f1)\n",
    "    print(\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_macro_PRF(predicted_idx, gold_idx, i=-1, empty_label=None):\n",
    "    '''\n",
    "    This evaluation function follows work from Sorokin and Gurevych(https://www.aclweb.org/anthology/D17-1188.pdf)\n",
    "    code borrowed from the following link:\n",
    "    https://github.com/UKPLab/emnlp2017-relation-extraction/blob/master/relation_extraction/evaluation/metrics.py\n",
    "    '''\n",
    "    if i == -1:\n",
    "        i = len(predicted_idx)\n",
    "\n",
    "    complete_rel_set = set(gold_idx) - {empty_label}\n",
    "    avg_prec = 0.0\n",
    "    avg_rec = 0.0\n",
    "\n",
    "    for r in complete_rel_set:\n",
    "        r_indices = (predicted_idx[:i] == r)\n",
    "        tp = len((predicted_idx[:i][r_indices] == gold_idx[:i][r_indices]).nonzero()[0])\n",
    "        tp_fp = len(r_indices.nonzero()[0])\n",
    "        tp_fn = len((gold_idx == r).nonzero()[0])\n",
    "        prec = (tp / tp_fp) if tp_fp > 0 else 0\n",
    "        rec = tp / tp_fn\n",
    "        avg_prec += prec\n",
    "        avg_rec += rec\n",
    "    f1 = 0\n",
    "    avg_prec = avg_prec / len(set(predicted_idx[:i]))\n",
    "    avg_rec = avg_rec / len(complete_rel_set)\n",
    "    if (avg_rec+avg_prec) > 0:\n",
    "        f1 = 2.0 * avg_prec * avg_rec / (avg_prec + avg_rec)\n",
    "\n",
    "    return avg_prec, avg_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/fewrl/concat_run_1/relation.concat.run.1.dev.predictions.step.900.csv 0.2350029463759576\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_file = \"~/QA-ZRE/rel_fewrl_data/val_ids_12321.csv\"\n",
    "gold_file = \"~/QA-ZRE/rel_fewrl_data/val_data_12321.csv\"\n",
    "\n",
    "prediction_files = [\"~/fewrl/concat_run_1/relation.concat.run.0.dev.predictions.step.{}.csv\".format(100 * i) for i in range(1, 27, 1)]\n",
    "prediction_files += [\"~/fewrl/concat_run_1/relation.concat.run.1.dev.predictions.step.{}.csv\".format(100 * i) for i in range(1, 27, 1)]\n",
    "prediction_files += [\"~/fewrl/concat_run_1/relation.concat.run.2.dev.predictions.step.{}.csv\".format(100 * i) for i in range(1, 27, 1)]\n",
    "prediction_files += [\"~/fewrl/concat_run_1/relation.concat.run.3.dev.predictions.step.{}.csv\".format(100 * i) for i in range(1, 27, 1)]\n",
    "\n",
    "df = pd.read_csv(gold_file, sep=',')\n",
    "ids = {i:val for i, val in enumerate(pd.read_csv(id_file, sep=',')[\"relation_ids\"].tolist())}\n",
    "actual_ids = df[\"actual_ids\"].tolist()\n",
    "num_examples = len(actual_ids) // 5\n",
    "actual_ids = np.argmax(np.reshape(np.array(actual_ids), (num_examples, 5)), axis=1)\n",
    "\n",
    "max_f1 = 0.0\n",
    "max_file = \"None\"\n",
    "for prediction_file in prediction_files:\n",
    "    pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, actual_ids)\n",
    "    if max_f1 <= f1:\n",
    "        max_f1 = f1\n",
    "        max_file = prediction_file\n",
    "\n",
    "print(max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408']\n",
      "[-0.6911495, -12.227538000000001, -4.965505, -15.330715, -8.0793495, -15.859772, -25.396414, -17.503723, -24.049929000000002, -25.550713000000002, -5.446661499999999, -10.7046995, -3.6017826, -9.2648115, -10.869199, -9.927994, -13.194257, -13.050821000000001, -8.164425, -10.922594]\n",
      "[0 0 2 3 0 2 0 0 0 0 0 0 0 0 0 0 2 2 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 3 0 0 0 0 0 0 2 0 0 0 2 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0.21042654028436017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_file = \"~/QA-ZRE/unk_fewrl_data/val_ids_12321.csv\"\n",
    "gold_file = \"~/QA-ZRE/unk_fewrl_data/val_data_12321.csv\"\n",
    "prediction_file = \"~/fewrl/run_1/relation.unk.mml-pgg-off-sim.run.0.dev.predictions.step.5200.csv\"\n",
    "df = pd.read_csv(gold_file, sep=',')\n",
    "\n",
    "ids = {i:val for i, val in enumerate(pd.read_csv(id_file, sep=',')[\"relation_ids\"].tolist())}\n",
    "\n",
    "actual_ids = df[\"actual_ids\"].tolist()\n",
    "\n",
    "print(actual_ids[0:100])\n",
    "\n",
    "num_examples = len(actual_ids) // 5\n",
    "\n",
    "actual_ids = np.argmax(np.reshape(np.array(actual_ids), (num_examples, 5)), axis=1)\n",
    "\n",
    "pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "print(pred_log_ps[:20])\n",
    "pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "print(pred_ids[0:100])\n",
    "avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, actual_ids)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408', 'P1408']\n",
      "[-0.7031368, -19.062004, -1.5099378, -17.406715, -13.607196, -16.561901000000002, -22.089489999999998, -21.497389000000002, -24.634203, -23.68671, -6.5539393, -18.939682, -7.034047599999999, -16.166794, -18.426668, -19.916698, -17.367314999999998, -17.627111, -19.524204, -21.17197]\n",
      "[0 0 0 1 0 2 0 2 0 2 0 0 0 0 0 0 2 2 0 2 0 0 0 0 2 0 0 2 0 0 3 0 0 0 2 0 0\n",
      " 0 0 0 0 2 0 0 0 0 2 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 2 0 2 0 0 0 3 0\n",
      " 0 0 0 2 0 2 0 0 2 0 0 0 0 0 0 0 2 2 0 0 0 0 2 0 0 0]\n",
      "0.20528511821974968\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_file = \"~/QA-ZRE/unk_fewrl_data/val_ids_12321.csv\"\n",
    "gold_file = \"~/QA-ZRE/unk_fewrl_data/val_data_12321.csv\"\n",
    "prediction_file = \"~/fewrl/run_1/relation.unk.mml-mml-off-sim.run.0.dev.predictions.step.5200.csv\"\n",
    "df = pd.read_csv(gold_file, sep=',')\n",
    "\n",
    "ids = {i:val for i, val in enumerate(pd.read_csv(id_file, sep=',')[\"relation_ids\"].tolist())}\n",
    "\n",
    "actual_ids = df[\"actual_ids\"].tolist()\n",
    "\n",
    "print(actual_ids[0:100])\n",
    "\n",
    "num_examples = len(actual_ids) // 5\n",
    "\n",
    "actual_ids = np.argmax(np.reshape(np.array(actual_ids), (num_examples, 5)), axis=1)\n",
    "\n",
    "pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "print(pred_log_ps[:20])\n",
    "pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "print(pred_ids[0:100])\n",
    "avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, actual_ids)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.0\n",
      "717.0\n",
      "recall: 0.2866666666666667\n",
      "precision: 0.1199442119944212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nids = {i:val for i, val in enumerate(pd.read_csv(id_file, sep=\\',\\')[\"relation_ids\"].tolist())}\\n\\nprint(actual_ids[0:100])\\n\\nnum_examples = len(actual_ids) // 5\\n\\nactual_ids = np.argmax(np.reshape(np.array(actual_ids), (num_examples, 5)), axis=1)\\n\\npred_log_ps = pd.read_csv(prediction_file, sep=\\',\\')[\"relation_log_p\"].tolist()\\nprint(pred_log_ps[:20])\\npred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\\nprint(pred_ids[0:100])\\navg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, actual_ids)\\nprint(f1)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_file = \"~/Desktop/codes/repos/QA-ZRE/nce_fewrel_data/data.csv\"\n",
    "prediction_file = \"~/Desktop/codes/repos/fewrl/run_1/fold_1_gold_entity_relation.gold_fold.1.dev.predictions.step.52500.csv\"\n",
    "df = pd.read_csv(gold_file, sep=',')\n",
    "answers = df[\"answers\"].tolist()\n",
    "answers = [ans.replace(\" </s>\", \"\") for ans in answers]\n",
    "\n",
    "pred_df = pd.read_csv(prediction_file, sep=',')\n",
    "predictions = pred_df[\"predictions_str\"].tolist()\n",
    "\n",
    "tpc = 0.0\n",
    "num_non_null_entity = 0.0\n",
    "num_gen_non_null_entity = 0.0\n",
    "for i in range(len(answers)):\n",
    "    if answers[i] == predictions[i] and answers[i] != \"no_answer\":\n",
    "        tpc += 1\n",
    "    if answers[i] != \"no_answer\":\n",
    "        num_non_null_entity += 1\n",
    "    if predictions[i] != \"no_answer\":\n",
    "        num_gen_non_null_entity += 1\n",
    "\n",
    "print(num_non_null_entity)\n",
    "print(num_gen_non_null_entity)\n",
    "print(\"recall:\", tpc / num_non_null_entity)\n",
    "print(\"precision:\", tpc / num_gen_non_null_entity)\n",
    "\n",
    "'''\n",
    "ids = {i:val for i, val in enumerate(pd.read_csv(id_file, sep=',')[\"relation_ids\"].tolist())}\n",
    "\n",
    "print(actual_ids[0:100])\n",
    "\n",
    "num_examples = len(actual_ids) // 5\n",
    "\n",
    "actual_ids = np.argmax(np.reshape(np.array(actual_ids), (num_examples, 5)), axis=1)\n",
    "\n",
    "pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "print(pred_log_ps[:20])\n",
    "pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "print(pred_ids[0:100])\n",
    "avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, actual_ids)\n",
    "print(f1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8097916859604715\n",
      "~/fold_1/gold/relation.gold.dev.predictions.fold.1.step.2500.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.8331326492522585\n",
      "~/fold_2/gold/relation.gold.dev.predictions.fold.2.step.6600.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Gold Templates on the dev data over the fold 1.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for fold_i in range(1, 3, 1):\n",
    "    gold_file = \"~/QA-ZRE/zero-shot-extraction/relation_splits/dev.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 506, 1):\n",
    "        prediction_file = \"~/fold_{}/gold/relation.gold.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 >= max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1\n",
    "0.8097916859604715\n",
    "~/fold_1/gold/relation.gold.dev.predictions.fold.1.step.2500.csv\n",
    "\n",
    "\n",
    "2\n",
    "0.8331326492522585\n",
    "~/fold_2/gold/relation.gold.dev.predictions.fold.2.step.6600.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.7016410071156501 0.7013333333333333 0.701487136487896\n",
      "~/fold_1/gold/relation.gold.test.predictions.fold.1.step.2500.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.6102377060671086 0.5776666666666667 0.5935056552184317\n",
      "~/fold_2/gold/relation.gold.test.predictions.fold.2.step.6600.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Gold Templates on the dev data over the fold 1.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fold_checkpoint = {\n",
    "    1: 2500,\n",
    "    2: 6600\n",
    "}\n",
    "for fold_i in range(1, 3, 1):\n",
    "    gold_file = \"~/QA-ZRE/zero-shot-extraction/relation_splits/test.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    prediction_file = \"~/fold_{}/gold/relation.gold.test.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(fold_checkpoint[fold_i]))\n",
    "    pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 24)), axis=1)\n",
    "\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "    print(fold_i)\n",
    "    print(avg_prec, avg_rec, f1)\n",
    "    print(prediction_file)\n",
    "    print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.6645079529607614\n",
      "~/fold_1/concat/relation.concat.dev.predictions.fold.1.step.3600.csv\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Concat Templates on the dev data over the fold 1.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for fold_i in range(1, 2, 1):\n",
    "    gold_file = \"~/QA-ZRE/zero-shot-extraction/relation_splits/dev.{}.concat.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 188, 1):\n",
    "        prediction_file = \"~/fold_{}/concat/relation.concat.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 >= max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.6447182716311557\n",
      "~/fold_1/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.0.dev.predictions.step.9300.csv\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the MML-PGG-oFF-Sim Templates on the dev data over the fold 1.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for fold_i in range(1, 2, 1):\n",
    "    gold_file = \"~/QA-ZRE/zero-shot-extraction/relation_splits/dev.{}.qq.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(93, 94, 1):\n",
    "        prediction_file = \"~/fold_{}/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.0.dev.predictions.step.{}.csv\".format(str(fold_i), str(100 * checkpoint_i))\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 >= max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.7016410071156501 0.7013333333333333 0.701487136487896\n",
      "~/fold_1/gold/relation.gold.test.predictions.fold.1.step.2500.csv\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Gold Templates on the dev data over the fold 1.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fold_checkpoint = {\n",
    "    1: 2500,\n",
    "}\n",
    "for fold_i in range(1, 2, 1):\n",
    "    gold_file = \"~/QA-ZRE/zero-shot-extraction/relation_splits/test.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    prediction_file = \"~/fold_{}/gold/relation.gold.test.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(fold_checkpoint[fold_i]))\n",
    "    pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 24)), axis=1)\n",
    "\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "    print(fold_i)\n",
    "    print(avg_prec, avg_rec, f1)\n",
    "    print(prediction_file)\n",
    "    print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.689066127748157 0.6813333333333333 0.6851779135044868\n",
      "~/fold_1/concat/relation.concat.test.predictions.fold.1.step.3600.csv\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Concat Templates on the dev data over the fold 1.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fold_checkpoint = {\n",
    "    1: 3600,\n",
    "}\n",
    "for fold_i in range(1, 2, 1):\n",
    "    gold_file = \"~/QA-ZRE/zero-shot-extraction/relation_splits/test.{}.concat.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    prediction_file = \"~/fold_{}/concat/relation.concat.test.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(fold_checkpoint[fold_i]))\n",
    "    pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 24)), axis=1)\n",
    "\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "    print(fold_i)\n",
    "    print(avg_prec, avg_rec, f1)\n",
    "    print(prediction_file)\n",
    "    print(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.609839655658675 0.5775 0.5932294090649438\n",
      "~/fold_1/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.0.test.predictions.step.9300.csv\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Concat Templates on the dev data over the fold 1.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fold_checkpoint = {\n",
    "    1: 9300,\n",
    "}\n",
    "for fold_i in range(1, 2, 1):\n",
    "    gold_file = \"~/QA-ZRE/zero-shot-extraction/relation_splits/test.{}.qq.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    prediction_file = \"~/fold_{}/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.0.test.predictions.step.{}.csv\".format(str(fold_i), str(fold_checkpoint[fold_i]))\n",
    "    pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 24)), axis=1)\n",
    "\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "    print(fold_i)\n",
    "    print(avg_prec, avg_rec, f1)\n",
    "    print(prediction_file)\n",
    "    print(\"\\r\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
