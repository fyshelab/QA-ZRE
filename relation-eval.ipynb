{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_macro_PRF(predicted_idx, gold_idx, i=-1, empty_label=None):\n",
    "    '''\n",
    "    This evaluation function follows work from Sorokin and Gurevych(https://www.aclweb.org/anthology/D17-1188.pdf)\n",
    "    code borrowed from the following link:\n",
    "    https://github.com/UKPLab/emnlp2017-relation-extraction/blob/master/relation_extraction/evaluation/metrics.py\n",
    "    '''\n",
    "    if i == -1:\n",
    "        i = len(predicted_idx)\n",
    "\n",
    "    complete_rel_set = set(gold_idx) - {empty_label}\n",
    "    avg_prec = 0.0\n",
    "    avg_rec = 0.0\n",
    "\n",
    "    for r in complete_rel_set:\n",
    "        r_indices = (predicted_idx[:i] == r)\n",
    "        tp = len((predicted_idx[:i][r_indices] == gold_idx[:i][r_indices]).nonzero()[0])\n",
    "        tp_fp = len(r_indices.nonzero()[0])\n",
    "        tp_fn = len((gold_idx == r).nonzero()[0])\n",
    "        prec = (tp / tp_fp) if tp_fp > 0 else 0\n",
    "        rec = tp / tp_fn\n",
    "        avg_prec += prec\n",
    "        avg_rec += rec\n",
    "    f1 = 0\n",
    "    avg_prec = avg_prec / len(set(predicted_idx[:i]))\n",
    "    avg_rec = avg_rec / len(complete_rel_set)\n",
    "    if (avg_rec+avg_prec) > 0:\n",
    "        f1 = 2.0 * avg_prec * avg_rec / (avg_prec + avg_rec)\n",
    "\n",
    "    return avg_prec, avg_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.100.csv 0.522874895000289 0.4833333333333334 0.5023271700636752\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.200.csv 0.5541007180264474 0.48333333333333334 0.5163033673226487\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.300.csv 0.5348535919442112 0.4566666666666667 0.49267739083828904\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.400.csv 0.5294456032134146 0.47333333333333333 0.49981953759556286\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.500.csv 0.6019570158523647 0.5166666666666667 0.5560603261262776\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.600.csv 0.5664639894419307 0.48666666666666675 0.5235421453726604\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.700.csv 0.6018064633260711 0.4833333333333334 0.5361025829784979\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.800.csv 0.5454121021649936 0.5 0.5217197132455935\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.900.csv 0.5927444488299751 0.49666666666666665 0.5404688925931228\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1000.csv 0.4690127030569856 0.4766666666666666 0.47280871074902747\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1100.csv 0.5843497189085424 0.48666666666666664 0.5310535556672936\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1200.csv 0.5844763966192539 0.47000000000000003 0.5210242871092702\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1300.csv 0.6122178871726613 0.48 0.5381061586595722\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1400.csv 0.6804711246200608 0.3766666666666667 0.48491462964649057\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1500.csv 0.6484106942440275 0.42 0.5097899020473305\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1600.csv 0.6139973411471639 0.46666666666666673 0.5302889528355699\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1700.csv 0.6649978785141387 0.43 0.522282450718716\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1800.csv 0.5758547863813939 0.4633333333333333 0.5135022478187875\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.1900.csv 0.6661311136410175 0.45 0.5371394049944381\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2000.csv 0.6961445689386867 0.3666666666666667 0.4803355479498021\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2100.csv 0.6251944522868436 0.45333333333333337 0.5255710401076573\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2200.csv 0.6305571240353849 0.34 0.4417863036863652\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2300.csv 0.6231223258658056 0.3333333333333333 0.43432738351757255\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2400.csv 0.6503178639542275 0.37000000000000005 0.4716522530156515\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2500.csv 0.6444882559801915 0.49333333333333335 0.5588706394799907\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2600.csv 0.5399210124500823 0.3466666666666667 0.42223148834152546\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2700.csv 0.5660878535878536 0.34 0.42483710482983206\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2800.csv 0.5630940988835725 0.31 0.39986336152567453\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2900.csv 0.529515831697995 0.22666666666666668 0.3174460894764904\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3000.csv 0.5443474544246414 0.41 0.46771740266998585\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3100.csv 0.5428579968572794 0.39666666666666667 0.45838854571215315\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3200.csv 0.6444969362086818 0.34333333333333343 0.4480066834441864\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3300.csv 0.511027134553078 0.35333333333333333 0.4177954165741631\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3400.csv 0.5052085769980507 0.3133333333333333 0.38678211942819757\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3500.csv 0.5874297082228116 0.36000000000000004 0.44641769858979063\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3600.csv 0.540029243555187 0.37666666666666665 0.4437916931978574\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3700.csv 0.5666790656152358 0.38999999999999996 0.4620250270613266\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3800.csv 0.626558735875506 0.35666666666666663 0.4545704682116609\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.3900.csv 0.6096423247957776 0.37000000000000005 0.4605102382065025\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4000.csv 0.6447860962566845 0.3333333333333333 0.4394733245250353\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4100.csv 0.6640856113583387 0.36999999999999994 0.4752250171624128\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4200.csv 0.626070371070371 0.32000000000000006 0.42352561684360535\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4300.csv 0.6186786566627679 0.34 0.43883472695133896\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4400.csv 0.5374391809785434 0.3466666666666667 0.42147046058372367\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4500.csv 0.5653266740658527 0.39999999999999997 0.4685060005104861\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4600.csv 0.5872134038800705 0.30666666666666664 0.4029148498181507\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4700.csv 0.6884479934479935 0.3666666666666667 0.4784900456287833\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4800.csv 0.5043277875539913 0.3633333333333333 0.42237479986938925\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.4900.csv 0.6285888950425054 0.34 0.44130223959479314\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5000.csv 0.6220324779425778 0.4133333333333334 0.4966491161858218\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5100.csv 0.5888507674952689 0.35333333333333333 0.44165594459090624\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5200.csv 0.5695501633716735 0.39666666666666667 0.4676415433482615\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5300.csv 0.6250478911769235 0.37666666666666665 0.4700634603603364\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5400.csv 0.539146104468774 0.36999999999999994 0.43883828500812316\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5500.csv 0.5452889913117186 0.4000000000000001 0.4614791847348652\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5600.csv 0.5370953645285196 0.35333333333333333 0.4262524240794097\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5700.csv 0.5955444080444081 0.37999999999999995 0.46396017073283924\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5800.csv 0.5114768525224587 0.3566666666666667 0.42026863078292903\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.5900.csv 0.6198141945773525 0.33666666666666667 0.4363302754843215\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6000.csv 0.5140391080513125 0.3333333333333333 0.4044180834355425\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6100.csv 0.5641426024955436 0.28 0.37424939395731094\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6200.csv 0.5153165643361722 0.3233333333333333 0.3973506058528293\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6300.csv 0.4730083817866042 0.33 0.38876995441141066\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6400.csv 0.5476307581170803 0.3866666666666667 0.4532829786066958\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6500.csv 0.5050802139037434 0.32666666666666666 0.39673817534986394\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6600.csv 0.5718042986425339 0.3433333333333333 0.42904907198144165\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6700.csv 0.5006475006475006 0.3466666666666667 0.40966575780176967\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6800.csv 0.5618711481284581 0.3266666666666667 0.4131384663636792\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.6900.csv 0.5032798057798058 0.4000000000000001 0.4457354654090352\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7000.csv 0.552999247129682 0.3566666666666667 0.4336457927059938\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7100.csv 0.5398071625344353 0.35333333333333333 0.4271038318785149\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7200.csv 0.543218892820286 0.28 0.3695281809400474\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7300.csv 0.5049175824175824 0.26666666666666666 0.3490083909942201\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7400.csv 0.6065443781868464 0.33666666666666667 0.4329959346930373\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7500.csv 0.5173340435770226 0.33 0.4029585160056159\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7600.csv 0.5321428571428571 0.31666666666666665 0.39705469845722297\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7700.csv 0.5065937880120951 0.32 0.392236221744987\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7800.csv 0.5743648018648019 0.33 0.4191679822667844\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.7900.csv 0.609748102008164 0.28 0.38377034618438416\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8000.csv 0.5630571913466651 0.3233333333333333 0.4107786657605498\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8100.csv 0.666088051382169 0.34 0.45019904005183614\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8200.csv 0.5143515585588756 0.35333333333333333 0.4189021899285984\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8300.csv 0.49339575893404974 0.3233333333333333 0.39065902488128407\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8400.csv 0.4814468654062089 0.41 0.4428603037974647\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8500.csv 0.5365379903115752 0.38666666666666666 0.4494374127896076\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8600.csv 0.5159559923006237 0.38666666666666666 0.442051795858593\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8700.csv 0.5441503528184289 0.39999999999999997 0.4610709310813129\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8800.csv 0.508781512605042 0.36000000000000004 0.4216511099289066\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.8900.csv 0.5073704547485035 0.34 0.4071559343326181\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9000.csv 0.5630971479500891 0.2866666666666667 0.3799201134144785\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9100.csv 0.5575075004740077 0.3166666666666667 0.40391045275159493\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9200.csv 0.5784982408895452 0.3466666666666667 0.4335358057871949\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9300.csv 0.5648777692895339 0.31333333333333335 0.4030808397861825\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9400.csv 0.5594294779089451 0.36333333333333334 0.4405452289520499\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9500.csv 0.5427516927516929 0.38333333333333336 0.4493211955588052\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9600.csv 0.5722546403255937 0.31333333333333335 0.40494329033818527\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9700.csv 0.6483357573460711 0.34 0.4460714000464479\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9800.csv 0.6004345568299057 0.3866666666666667 0.47040368933693877\n",
      "~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.9900.csv 0.6187617937617937 0.36000000000000004 0.4551756048795231\n",
      "0.5588706394799907 ~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.2500.csv\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for the prompt model on the RE-QA dataset.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    1: \"~/codes/QA-ZRE/zero-shot-extraction/relation_splits/dev.0.prompt_data.csv\",\n",
    "}\n",
    "\n",
    "prediction_arrs = {\n",
    "    1: [\"~/codes/prompt_models/fold_1/dev.0.prompt_data.predicted.step.{}.csv\".format(step * 100) for step in range(1, 100, 1)]\n",
    "}\n",
    "\n",
    "max_f1 = 0.0\n",
    "max_file = None\n",
    "for fold_id in range(1, 2, 1):\n",
    "    prediction_files = prediction_arrs[fold_id]\n",
    "    df = pd.read_csv(gold_files[fold_id], sep=',')\n",
    "    answers = [ans.replace(\"</s>\", \"\").strip() for ans in df[\"answers\"].tolist()]\n",
    "    all_classes = set(answers)\n",
    "    ids = {val:i for i, val in enumerate(list(all_classes))}\n",
    "    actual_ids = [ids[ans] for ans in answers]\n",
    "    gold_indices = np.array(actual_ids)\n",
    "    for prediction_file in prediction_files:\n",
    "        prediction_ids = []\n",
    "        for pred_class in pd.read_csv(prediction_file, sep=',')[\"predictions_str\"].tolist():\n",
    "            if pred_class.strip() in ids:\n",
    "                prediction_ids.append(ids[pred_class.strip()])\n",
    "            else:\n",
    "                prediction_ids.append(-1)\n",
    "        pred_ids = np.array(prediction_ids)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 > max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "        print(prediction_file, avg_prec, avg_rec, f1)\n",
    "\n",
    "print(max_f1, max_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.6645079529607614\n",
      "~/may-20/fold_1/concat/relation.concat.dev.predictions.fold.1.step.3600.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.7355692801363015\n",
      "~/may-20/fold_2/concat/relation.concat.dev.predictions.fold.2.step.4300.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.816466070295921\n",
      "~/may-20/fold_3/concat/relation.concat.dev.predictions.fold.3.step.5200.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.820538067780762\n",
      "~/may-20/fold_4/concat/relation.concat.dev.predictions.fold.4.step.1600.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.7970665456384882\n",
      "~/may-20/fold_5/concat/relation.concat.dev.predictions.fold.5.step.2900.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.9100498471715361\n",
      "~/may-20/fold_6/concat/relation.concat.dev.predictions.fold.6.step.1400.csv\n",
      "\n",
      "\n",
      "7\n",
      "0.7789862082105365\n",
      "~/may-20/fold_7/concat/relation.concat.dev.predictions.fold.7.step.2500.csv\n",
      "\n",
      "\n",
      "8\n",
      "0.7585498509710629\n",
      "~/may-20/fold_8/concat/relation.concat.dev.predictions.fold.8.step.400.csv\n",
      "\n",
      "\n",
      "9\n",
      "0.7690369496615103\n",
      "~/may-20/fold_9/concat/relation.concat.dev.predictions.fold.9.step.2600.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.7394406760740089\n",
      "~/may-20/fold_10/concat/relation.concat.dev.predictions.fold.10.step.800.csv\n",
      "\n",
      "\n",
      "0.7790211448900889\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Concat Templates on the dev data over all the folds.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.concat.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        prediction_file = \"~/may-20/fold_{}/concat/relation.concat.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 >= max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 1\n",
      "159 1\n",
      "162 1\n",
      "163 1\n",
      "164 1\n",
      "165 1\n",
      "167 1\n",
      "168 1\n",
      "169 1\n",
      "171 1\n",
      "1\n",
      "0.7958029874558785\n",
      "~/may-20/fold_1/gold/relation.gold.dev.predictions.fold.1.step.600.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.8055480874453981\n",
      "~/may-20/fold_2/gold/relation.gold.dev.predictions.fold.2.step.1900.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.8088784230714176\n",
      "~/may-20/fold_3/gold/relation.gold.dev.predictions.fold.3.step.200.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.7950547270773886\n",
      "~/may-20/fold_4/gold/relation.gold.dev.predictions.fold.4.step.9500.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.8218222460881007\n",
      "~/may-20/fold_5/gold/relation.gold.dev.predictions.fold.5.step.15300.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.9343882793208368\n",
      "~/may-20/fold_6/gold/relation.gold.dev.predictions.fold.6.step.1100.csv\n",
      "\n",
      "\n",
      "7\n",
      "0.7977715930389874\n",
      "~/may-20/fold_7/gold/relation.gold.dev.predictions.fold.7.step.2600.csv\n",
      "\n",
      "\n",
      "8\n",
      "0.8869445616734918\n",
      "~/may-20/fold_8/gold/relation.gold.dev.predictions.fold.8.step.1000.csv\n",
      "\n",
      "\n",
      "9\n",
      "0.8353253359450881\n",
      "~/may-20/fold_9/gold/relation.gold.dev.predictions.fold.9.step.1900.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.8742971188094225\n",
      "~/may-20/fold_10/gold/relation.gold.dev.predictions.fold.10.step.4000.csv\n",
      "\n",
      "\n",
      "0.8355833359926009\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Gold Templates on the dev data over all the folds.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        try:\n",
    "            prediction_file = \"~/may-20/fold_{}/gold/relation.gold.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if f1 >= max_f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(checkpoint_i, fold_i)\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.7021862131500355\n",
      "~/may-20/fold_1/relation.mml-pgg-off-sim.run.fold_1.dev.predictions.step.4700.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.7318462713898469\n",
      "~/may-20/fold_2/relation.mml-pgg-off-sim.run.fold_2.dev.predictions.step.400.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.7766533200558716\n",
      "~/may-20/fold_3/relation.mml-pgg-off-sim.run.fold_3.dev.predictions.step.3600.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.8437707696480834\n",
      "~/may-20/fold_4/relation.mml-pgg-off-sim.run.fold_4.dev.predictions.step.800.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.8300206299665337\n",
      "~/may-20/fold_5/relation.mml-pgg-off-sim.run.fold_5.dev.predictions.step.7900.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.8906375171815566\n",
      "~/may-20/fold_6/relation.mml-pgg-off-sim.run.fold_6.dev.predictions.step.700.csv\n",
      "\n",
      "\n",
      "197\n",
      "198\n",
      "199\n",
      "7\n",
      "0.7827607798234402\n",
      "~/may-20/fold_7/relation.mml-pgg-off-sim.run.fold_7.dev.predictions.step.2100.csv\n",
      "\n",
      "\n",
      "198\n",
      "199\n",
      "8\n",
      "0.795102231532206\n",
      "~/may-20/fold_8/relation.mml-pgg-off-sim.run.fold_8.dev.predictions.step.6800.csv\n",
      "\n",
      "\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "9\n",
      "0.7819016572177454\n",
      "~/may-20/fold_9/relation.mml-pgg-off-sim.run.fold_9.dev.predictions.step.4300.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.7755543602531488\n",
      "~/may-20/fold_10/relation.mml-pgg-off-sim.run.fold_10.dev.predictions.step.1600.csv\n",
      "\n",
      "\n",
      "0.7910433750218469\n"
     ]
    }
   ],
   "source": [
    "# MML-OFF-PGG performance for Relation Extraction on all the dev folds.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.qq.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        try:\n",
    "            prediction_file = \"~/may-20/fold_{}/relation.mml-pgg-off-sim.run.fold_{}.dev.predictions.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "            pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 12, 8)), axis=2))\n",
    "            pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if f1 >= max_f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(checkpoint_i)\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 concat alone 0.6851779135044868 0.689066127748157 0.6813333333333333\n",
      "1 gold alone 0.7433432938934399 0.7562889888849941 0.7308333333333333\n",
      "\n",
      "\n",
      "2 concat alone 0.5901669782971629 0.5989194167218461 0.5816666666666667\n",
      "2 gold alone 0.6642954078337273 0.6842181964463796 0.6455000000000001\n",
      "\n",
      "\n",
      "3 concat alone 0.6373039703281808 0.6626408187363189 0.6138333333333333\n",
      "3 gold alone 0.681873757976071 0.6871616100666138 0.6766666666666667\n",
      "\n",
      "\n",
      "4 concat alone 0.5858742474657468 0.6150594189021233 0.5593333333333333\n",
      "4 gold alone 0.6824352310400019 0.7000704484368208 0.6656666666666667\n",
      "\n",
      "\n",
      "5 concat alone 0.622864337200164 0.6281502269876816 0.6176666666666667\n",
      "5 gold alone 0.5005601199498438 0.5060723602043087 0.4951666666666666\n",
      "\n",
      "\n",
      "6 concat alone 0.5752377444829445 0.5954721054962936 0.5563333333333333\n",
      "6 gold alone 0.6651754396604047 0.6719876078130175 0.6585\n",
      "\n",
      "\n",
      "7 concat alone 0.6683183924580341 0.6834597978850874 0.6538333333333333\n",
      "7 gold alone 0.6543720994745615 0.6683140048618551 0.641\n",
      "\n",
      "\n",
      "8 concat alone 0.5976466905286616 0.6104892396256113 0.5853333333333334\n",
      "8 gold alone 0.76734257561607 0.7774442974442916 0.7575\n",
      "\n",
      "\n",
      "9 concat alone 0.6010214403439702 0.6135438179429739 0.589\n",
      "9 gold alone 0.6226748483257762 0.6471308376432654 0.6\n",
      "\n",
      "\n",
      "10 concat alone 0.6176894076003205 0.6142508628482145 0.6211666666666668\n",
      "10 gold alone 0.6597456987087056 0.6692580091015435 0.6505\n",
      "\n",
      "\n",
      "gold alone p: 0.6767946360903091\n",
      "gold alone r: 0.6521333333333332\n",
      "gold alone f: 0.6641818472478602\n",
      "concat alone p: 0.6311051832894308\n",
      "concat alone r: 0.6059500000000001\n",
      "concat alone f: 0.6181301122209673\n"
     ]
    }
   ],
   "source": [
    "# Test set performance over the 10 folds of the RE-QA dataset for the concat and gold models.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    1: \"relation.gold.test.predictions.fold.1.step.600.csv\",\n",
    "    2: \"relation.gold.test.predictions.fold.2.step.1900.csv\",\n",
    "    3: \"relation.gold.test.predictions.fold.3.step.200.csv\",\n",
    "    4: \"relation.gold.test.predictions.fold.4.step.9500.csv\",\n",
    "    5: \"relation.gold.test.predictions.fold.5.step.15300.csv\",\n",
    "    6: \"relation.gold.test.predictions.fold.6.step.1100.csv\",\n",
    "    7: \"relation.gold.test.predictions.fold.7.step.2600.csv\",\n",
    "    8: \"relation.gold.test.predictions.fold.8.step.1000.csv\",\n",
    "    9: \"relation.gold.test.predictions.fold.9.step.1900.csv\",\n",
    "    10: \"relation.gold.test.predictions.fold.10.step.4000.csv\"\n",
    "}\n",
    "\n",
    "concat_files = {\n",
    "    1: \"relation.concat.test.predictions.fold.1.step.3600.csv\",\n",
    "    2: \"relation.concat.test.predictions.fold.2.step.4300.csv\",\n",
    "    3: \"relation.concat.test.predictions.fold.3.step.5200.csv\",\n",
    "    4: \"relation.concat.test.predictions.fold.4.step.1600.csv\",\n",
    "    5: \"relation.concat.test.predictions.fold.5.step.2900.csv\",\n",
    "    6: \"relation.concat.test.predictions.fold.6.step.1400.csv\",\n",
    "    7: \"relation.concat.test.predictions.fold.7.step.2500.csv\",\n",
    "    8: \"relation.concat.test.predictions.fold.8.step.400.csv\",\n",
    "    9: \"relation.concat.test.predictions.fold.9.step.2600.csv\",\n",
    "    10: \"relation.concat.test.predictions.fold.10.step.800.csv\"\n",
    "}\n",
    "\n",
    "gold_alone_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "concat_alone_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/test.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "    \n",
    "    concat_prediction_file = \"~/may-20/fold_{}/concat/{}\".format(fold_i, concat_files[fold_i])\n",
    "    concat_pred_log_ps = pd.read_csv(concat_prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    concat_pred_log_ps = np.reshape(np.array(concat_pred_log_ps), (num_examples, 24))\n",
    "    concat_pred_ids = np.argmax(concat_pred_log_ps, axis=1)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(concat_pred_ids, gold_indices)\n",
    "    concat_alone_p_r_f[\"f\"].append(f1)\n",
    "    concat_alone_p_r_f[\"r\"].append(avg_rec)\n",
    "    concat_alone_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(fold_i, \"concat alone\", f1, avg_prec, avg_rec)\n",
    "    \n",
    "    gold_prediction_file = \"~/may-20/fold_{}/gold/{}\".format(fold_i, gold_files[fold_i])\n",
    "    gold_pred_log_ps = pd.read_csv(gold_prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    gold_pred_log_ps = np.reshape(np.array(gold_pred_log_ps), (num_examples, 24))\n",
    "    gold_pred_ids = np.argmax(gold_pred_log_ps, axis=1)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(gold_pred_ids, gold_indices)\n",
    "    print(fold_i, \"gold alone\", f1, avg_prec, avg_rec)\n",
    "    gold_alone_p_r_f[\"f\"].append(f1)\n",
    "    gold_alone_p_r_f[\"r\"].append(avg_rec)\n",
    "    gold_alone_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"gold alone p:\", np.mean(np.array(gold_alone_p_r_f[\"p\"])))\n",
    "print(\"gold alone r:\", np.mean(np.array(gold_alone_p_r_f[\"r\"])))\n",
    "print(\"gold alone f:\", np.mean(np.array(gold_alone_p_r_f[\"f\"])))\n",
    "\n",
    "print(\"concat alone p:\", np.mean(np.array(concat_alone_p_r_f[\"p\"])))\n",
    "print(\"concat alone r:\", np.mean(np.array(concat_alone_p_r_f[\"r\"])))\n",
    "print(\"concat alone f:\", np.mean(np.array(concat_alone_p_r_f[\"f\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 mml 0.7324313594407584 0.7347101443139104 0.7301666666666667\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 692139 into shape (6000,24,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6217db65b1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmml_pred_log_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmml_prediction_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer_log_p\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mpred_log_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmml_pred_log_ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mpred_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_log_ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mavg_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_macro_PRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 692139 into shape (6000,24,8)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mml_files = {\n",
    "    1: \"relation.mml-pgg-off-sim.run.fold_1.test.predictions.step.4700.csv\",\n",
    "    2: \"relation.mml-pgg-off-sim.run.fold_2.test.predictions.step.400.csv\",\n",
    "    3: \"relation.mml-pgg-off-sim.run.fold_3.test.predictions.step.3600.csv\",\n",
    "    4: \"relation.mml-pgg-off-sim.run.fold_4.test.predictions.step.800.csv\",\n",
    "    5: \"relation.mml-pgg-off-sim.run.fold_5.test.predictions.step.7900.csv\",\n",
    "    6: \"relation.mml-pgg-off-sim.run.fold_6.test.predictions.step.700.csv\",\n",
    "    7: \"relation.mml-pgg-off-sim.run.fold_7.test.predictions.step.2100.csv\",\n",
    "    8: \"relation.mml-pgg-off-sim.run.fold_8.test.predictions.step.6800.csv\",\n",
    "    9: \"relation.mml-pgg-off-sim.run.fold_9.test.predictions.step.4300.csv\",\n",
    "    10: \"relation.mml-pgg-off-sim.run.fold_10.test.predictions.step.1600.csv\"\n",
    "}\n",
    "\n",
    "mml_mml_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/test.{}.qq.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "    \n",
    "    mml_prediction_file = \"~/may-20/fold_{}/{}\".format(fold_i, mml_files[fold_i])\n",
    "    mml_pred_log_ps = pd.read_csv(mml_prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "\n",
    "    pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(mml_pred_log_ps)), (num_examples, 24, 8)), axis=2))\n",
    "    pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "    mml_mml_p_r_f[\"f\"].append(f1)\n",
    "    mml_mml_p_r_f[\"r\"].append(avg_rec)\n",
    "    mml_mml_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(fold_i, \"mml\", f1, avg_prec, avg_rec)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"mml p:\", np.mean(np.array(mml_mml_p_r_f[\"p\"])))\n",
    "print(\"mml r:\", np.mean(np.array(mml_mml_p_r_f[\"r\"])))\n",
    "print(\"mml f:\", np.mean(np.array(mml_mml_p_r_f[\"f\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ~/may-29/fewrl/concat_run_1/relation.concat.run.0.dev.predictions.step.600.csv 0.5478163622378379\n",
      "2 ~/may-29/fewrl/concat_run_2/relation.concat.run.0.dev.predictions.step.200.csv 0.4564517056171136\n",
      "3 ~/may-29/fewrl/concat_run_3/relation.concat.run.0.dev.predictions.step.800.csv 0.6302340196983017\n",
      "4 ~/may-29/fewrl/concat_run_4/relation.concat.run.1.dev.predictions.step.1000.csv 0.7054889125319359\n",
      "5 ~/may-29/fewrl/concat_run_5/relation.concat.run.0.dev.predictions.step.800.csv 0.6725607501052342\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for concat model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/val_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/val_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/val_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/val_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/val_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {   \n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/val_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/val_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/val_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/val_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/val_data_1300.csv\",\n",
    "}\n",
    "\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [\"~/may-29/fewrl/concat_run_{}/relation.concat.run.0.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/concat_run_{}/relation.concat.run.1.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/concat_run_{}/relation.concat.run.2.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/concat_run_{}/relation.concat.run.3.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if max_f1 <= f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "    print(run_id, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.36408830731147435 0.37638095238095237 0.37013259379216645\n",
      "2 0.4049919630602685 0.40514285714285714 0.4050673960489486\n",
      "3 0.34249083430854455 0.3451428571428572 0.34381173164737605\n",
      "4 0.2948596112396407 0.3235238095238095 0.30852736829582333\n",
      "5 0.3796415763339939 0.40228571428571425 0.39063576509021747\n",
      "mean_p 0.3572144584507844\n",
      "mean_r 0.3704952380952381\n",
      "mean_f 0.3636349709749064\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for concat model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/test_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/test_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/test_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/test_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/test_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/test_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/test_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/test_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/test_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/test_data_1300.csv\",\n",
    "}\n",
    "test_files = {\n",
    "    1: \"~/june-12/fewrl/concat_run_1/relation.concat.run.0.test.predictions.step.2000.csv\",\n",
    "    2: \"~/june-12/fewrl/concat_run_2/relation.concat.run.0.test.predictions.step.400.csv\",\n",
    "    3: \"~/june-12/fewrl/concat_run_3/relation.concat.run.1.test.predictions.step.800.csv\",\n",
    "    4: \"~/june-12/fewrl/concat_run_4/relation.concat.run.0.test.predictions.step.2400.csv\",\n",
    "    5: \"~/june-12/fewrl/concat_run_5/relation.concat.run.0.test.predictions.step.200.csv\",\n",
    "}\n",
    "\n",
    "mean_f1 = 0.0\n",
    "mean_p = 0.0\n",
    "mean_r = 0.0\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [test_files[run_id]]\n",
    "\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 15)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            print(run_id, avg_prec, avg_rec, f1)\n",
    "            mean_f1 += f1\n",
    "            mean_p += avg_prec\n",
    "            mean_r += avg_rec\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "mean_f1 /= 5\n",
    "mean_p /= 5\n",
    "mean_r /= 5\n",
    "print(\"mean_p\", mean_p)\n",
    "print(\"mean_r\", mean_r)\n",
    "print(\"mean_f\", mean_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ~/june-16/fewrl/run_1/relation.mml-pgg-off-sim.run.0.dev.predictions.step.1000.csv 0.6866699556484906\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.3.dev.predictions.step.1000.csv\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.3.dev.predictions.step.1200.csv\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.3.dev.predictions.step.1400.csv\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.3.dev.predictions.step.1600.csv\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.3.dev.predictions.step.1800.csv\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.3.dev.predictions.step.2000.csv\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.3.dev.predictions.step.2200.csv\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.3.dev.predictions.step.2400.csv\n",
      "2 ~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.2.dev.predictions.step.2200.csv 0.5213218904876981\n",
      "3 ~/june-16/fewrl/run_3/relation.mml-pgg-off-sim.run.2.dev.predictions.step.1200.csv 0.6660949360255928\n",
      "4 ~/june-16/fewrl/run_4/relation.mml-pgg-off-sim.run.1.dev.predictions.step.1400.csv 0.7018449812380131\n",
      "5 ~/june-16/fewrl/run_5/relation.mml-pgg-off-sim.run.0.dev.predictions.step.2400.csv 0.6628225426897361\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for off-mml-pgg model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/small_fewrl_data/val_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/small_fewrl_data/val_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/small_fewrl_data/val_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/small_fewrl_data/val_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/small_fewrl_data/val_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {   \n",
    "    1: \"~/codes/QA-ZRE/small_fewrl_data/val_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/small_fewrl_data/val_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/small_fewrl_data/val_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/small_fewrl_data/val_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/small_fewrl_data/val_data_1300.csv\",\n",
    "}\n",
    "\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [\"~/june-16/fewrl/run_{}/relation.mml-pgg-off-sim.run.0.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/june-16/fewrl/run_{}/relation.mml-pgg-off-sim.run.1.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/june-16/fewrl/run_{}/relation.mml-pgg-off-sim.run.2.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/june-16/fewrl/run_{}/relation.mml-pgg-off-sim.run.3.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            mml_pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "            pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(mml_pred_log_ps)), (num_examples, 5, 8)), axis=2))\n",
    "            pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if max_f1 <= f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "    print(run_id, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/june-16/fewrl/run_1/relation.mml-pgg-off-sim.run.0.test.predictions.step.1000.csv 0.39090262621490907 0.3941904761904762 0.39253966669598334\n",
      "~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.2.test.predictions.step.2200.csv 0.38823952774766773 0.396 0.39208136684878714\n",
      "~/june-16/fewrl/run_3/relation.mml-pgg-off-sim.run.2.test.predictions.step.1200.csv 0.33109424738588195 0.338 0.33451148639718353\n",
      "~/june-16/fewrl/run_4/relation.mml-pgg-off-sim.run.1.test.predictions.step.1400.csv 0.29031332227659645 0.31657142857142856 0.3028743201670405\n",
      "~/june-16/fewrl/run_5/relation.mml-pgg-off-sim.run.0.test.predictions.step.2400.csv 0.3921389098579965 0.42447619047619045 0.4076672854222021\n",
      "mean_p 0.3585377266966104\n",
      "mean_r 0.37384761904761904\n",
      "mean_f 0.3659348251062393\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for off-mml-pgg model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/small_fewrl_data/test_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/small_fewrl_data/test_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/small_fewrl_data/test_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/small_fewrl_data/test_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/small_fewrl_data/test_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {   \n",
    "    1: \"~/codes/QA-ZRE/small_fewrl_data/test_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/small_fewrl_data/test_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/small_fewrl_data/test_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/small_fewrl_data/test_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/small_fewrl_data/test_data_1300.csv\",\n",
    "}\n",
    "\n",
    "test_files = {\n",
    "    1: \"~/june-16/fewrl/run_1/relation.mml-pgg-off-sim.run.0.test.predictions.step.1000.csv\",\n",
    "    2: \"~/june-16/fewrl/run_2/relation.mml-pgg-off-sim.run.2.test.predictions.step.2200.csv\",\n",
    "    3: \"~/june-16/fewrl/run_3/relation.mml-pgg-off-sim.run.2.test.predictions.step.1200.csv\",\n",
    "    4: \"~/june-16/fewrl/run_4/relation.mml-pgg-off-sim.run.1.test.predictions.step.1400.csv\",\n",
    "    5: \"~/june-16/fewrl/run_5/relation.mml-pgg-off-sim.run.0.test.predictions.step.2400.csv\",\n",
    "}\n",
    "\n",
    "mean_f1 = 0.0\n",
    "mean_p = 0.0\n",
    "mean_r = 0.0\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [test_files[run_id]]\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            mml_pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "            pred_log_ps = np.log(np.sum(np.reshape(np.exp(np.array(mml_pred_log_ps)), (num_examples, 15, 8)), axis=2))\n",
    "            pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            mean_f1 += f1\n",
    "            mean_p += avg_prec\n",
    "            mean_r += avg_rec\n",
    "            print(prediction_file, avg_prec, avg_rec, f1)\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "mean_f1 /= 5\n",
    "mean_p /= 5\n",
    "mean_r /= 5\n",
    "print(\"mean_p\", mean_p)\n",
    "print(\"mean_r\", mean_r)\n",
    "print(\"mean_f\", mean_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ~/june-19/wikizsl/concat_run_1/relation.concat.run.1.dev.predictions.step.4000.csv 0.2950228237597085\n",
      "~/june-19/wikizsl/concat_run_2/relation.concat.run.3.dev.predictions.step.1200.csv\n",
      "2 ~/june-19/wikizsl/concat_run_2/relation.concat.run.0.dev.predictions.step.2400.csv 0.37060460613882945\n",
      "3 ~/june-19/wikizsl/concat_run_3/relation.concat.run.0.dev.predictions.step.1400.csv 0.3002193280315908\n",
      "4 ~/june-19/wikizsl/concat_run_4/relation.concat.run.1.dev.predictions.step.1400.csv 0.25564976384906496\n",
      "~/june-19/wikizsl/concat_run_5/relation.concat.run.3.dev.predictions.step.3600.csv\n",
      "5 ~/june-19/wikizsl/concat_run_5/relation.concat.run.0.dev.predictions.step.2200.csv 0.40583545137171356\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for off-mml-pgg model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/wikizsl_dataset/val_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/wikizsl_dataset/val_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/wikizsl_dataset/val_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/wikizsl_dataset/val_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/wikizsl_dataset/val_ids_1300.csv\"\n",
    "}\n",
    "\n",
    "gold_files = {\n",
    "    1: \"~/codes/QA-ZRE/wikizsl_dataset/small.val_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/wikizsl_dataset/small.val_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/wikizsl_dataset/small.val_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/wikizsl_dataset/small.val_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/wikizsl_dataset/small.val_data_1300.csv\",\n",
    "}\n",
    "\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [\"~/june-19/wikizsl/concat_run_{}/relation.concat.run.0.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 23, 1)]\n",
    "    prediction_files += [\"~/june-19/wikizsl/concat_run_{}/relation.concat.run.1.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 23, 1)]\n",
    "    prediction_files += [\"~/june-19/wikizsl/concat_run_{}/relation.concat.run.2.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 23, 1)]\n",
    "    prediction_files += [\"~/june-19/wikizsl/concat_run_{}/relation.concat.run.3.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 23, 1)]\n",
    "\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if max_f1 <= f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "    print(run_id, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  2 12 12  0  0  0 12 10  6  6 10 14  8  5  0 11  2 11 14  1  8  0  2\n",
      "  2  4 13  8  3  6  8 12  7  3  9 10  5  6  2  7 11 11  7 14 12  8 10  9\n",
      "  9  2  3 11  0  9  0  5 13  9 11  1  8 11 11 10 12  3  8  9 14 14  8  0\n",
      "  5 14 12  3 11 12  9 12  6  4  9 10 12  6 13  3 11  0  0  1  6  1  7  9\n",
      "  0 12  9  0]\n",
      "[ 4 10  8  8 11 10 14  8 13  2  4 10  6 13  5 10 13  0 14  5  4 14 10  2\n",
      " 12  3  0 14  2  4 14  4  2  2 12 12  4  4  0  8 13  0  2 10  6 11 12  7\n",
      " 10 11  6  0 10 12  7 12  3 11  7 11  0 13  5 12  8  5 11  1 12 10 14  0\n",
      "  4 10 11  6 13 10 12  8  8  3  7 12  6  4  0  6 13  2 12  9 11  4  2 11\n",
      " 10 13 12  7]\n",
      "Samosh\n",
      "~/june-19/wikizsl/concat_run_1/relation.concat.run.1.test.predictions.step.4000.csv\n",
      "[ 9  5  5 10 14 14 13  9 13 14  5 11 10  3 13  3  9  9  2  9  5  7  8 13\n",
      "  2  8 13  4 13 10 11  8 11  8  4  3 10  9 12 12  7 13  6  2  2  7 11  7\n",
      "  0  0  5  9  8 10 13  9 14 12 10  4  4  4  9  9 13 12  3 13 10  5  6  5\n",
      "  2  8 10 14 10  7 13  6  8 10 14 12  0  2 14 11  9 10  9  9  6  5  6  2\n",
      "  0 14  8  5]\n",
      "[ 2  6  4 10 10 14 11  7 11 13  6  6  4 14 10 11  2  2 10  2  6  9  5 11\n",
      " 10 14 10 10 14  6  6  5  3  5  5 14  6  2  4  3  9  0 14  6  7  9 12  7\n",
      "  9 14  6  2  5  6  5  2 13  6 10  2  3  2  2  0 11  6 11 11  3  6 14  6\n",
      " 10 14  1 10  9  9 11 14  6  1 10  4 11  0 11  8  4  1 10  2  9  4 14  2\n",
      "  9 10  5  6]\n",
      "Samosh\n",
      "~/june-19/wikizsl/concat_run_2/relation.concat.run.0.test.predictions.step.2400.csv\n",
      "[ 1 11  7  5  1 11 14 13  2  2 13  5 12  7  5 12 11  0  0 13  7 13  1  2\n",
      " 14 14 13  8 11 13  2  2  3  6  5  1 12 10 12  5 11 10 11  1 13  1 12  2\n",
      "  7  0  1 13 14  0 11  0  6 14  7 12 10 10  7 10 14  8  0  4  9 13  5 10\n",
      "  1  4 11 12  7 13  5  0 14  0  9 10 13  7  0 12  1 13  5  0 10  7  6 11\n",
      " 12  0 13 10]\n",
      "[ 7 11  7  8  6 12 13  7  3 14  0  8  7  5  8  7 12 14  9  7  9  7  7 10\n",
      " 13 12  1 14 12  4 13  6 11  0  3  7  1  1  7  8 12 14 13  0  4  0  7 14\n",
      "  7  6  4  9 10  9 13  1  5  1  7  9 11 11  7 11 13 14 13  6 10 12 11 11\n",
      "  0  9 11  7  7  7 13  9 10  5 10 11  7  7  1  7  0  0  8  0 11  9  1 12\n",
      "  5 10  0 14]\n",
      "Samosh\n",
      "~/june-19/wikizsl/concat_run_3/relation.concat.run.0.test.predictions.step.1400.csv\n",
      "[10  0  0  8  2 10 14  5  8  1  6  6  2 10  6  0  2  4  9  6  1  0 13 12\n",
      "  4  0  2 11 12 13  1  4  1  8  0  6 13  4  0 10 10 14  6  2  3 11  0 11\n",
      "  1  1  2  4  0  6  0  8 11  4  9 13  3  1 12  8  2  6 11 10  7  3  0  4\n",
      "  5  2  1 10  9  4  7  2  9  8  2 14 11  4  7 13  7  7  0  6  4 11  8  9\n",
      " 14  0  5  8]\n",
      "[ 0  4  7  4 12  4  4  5  2  0 10 10  6  2 10 12  6  4  8 10  0  4 13  8\n",
      " 11  1  6  4  2 13  7  0  5 14 10  6  3  4  0  2  6  4 10  6  4  4  2  4\n",
      "  7 11  6  7 12 10  0  0  8  4  0  3  4  0  2 11  3 10  4  2 12  4  7  5\n",
      " 14  6  5  6  9  4  4  6  1 13  6  4  1  3 14  2  3  5  0  6 12 12  2  4\n",
      "  4  0  4  2]\n",
      "Samosh\n",
      "~/june-19/wikizsl/concat_run_4/relation.concat.run.1.test.predictions.step.1400.csv\n",
      "[10  7  9  4 10  8 12  7 10  9  9  9 13  0  0  4  7  7  8 10 11  6  3 10\n",
      "  1  2 10  4 13 10 10 10  2 12  9  4  7  9 13  2  2 14 10 11  3 10  7 13\n",
      "  4  6  6  4  1  2  9  7 10  0  5  9  8  2  9  4 10  4  2 11  7  2  2  8\n",
      "  7 12  0  3  3  8  1 13  3  0  8  3 11  2  7  2 12 13  2 11  9  9 11 13\n",
      "  4 10  1  9]\n",
      "[10  3  5 14 10  8 10  3 10 10  5  2  8  7 10  1 11 12  8 10  0 14  3 10\n",
      "  9  0 12 14 14 12 10 13 14  5  5  9  3 12  2 10 12  0 10  8 14  6  3  0\n",
      "  8  6 13 14  0 12 14  3  3  7  4  5  8 14  5 14 10  1 12  5  3  0 11  8\n",
      " 12  7  7 13  3  0 10 13  5  8  8 12 14 10 10 12  1  2 14 14  2  5  3 13\n",
      "  8 13  8  5]\n",
      "Samosh\n",
      "~/june-19/wikizsl/concat_run_5/relation.concat.run.0.test.predictions.step.2200.csv\n",
      "mean_p 0.0\n",
      "mean_r 0.0\n",
      "mean_f 0.0\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for concat model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/wikizsl_dataset/test_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/wikizsl_dataset/test_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/wikizsl_dataset/test_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/wikizsl_dataset/test_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/wikizsl_dataset/test_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {\n",
    "    1: \"~/codes/QA-ZRE/wikizsl_dataset/test_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/wikizsl_dataset/test_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/wikizsl_dataset/test_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/wikizsl_dataset/test_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/wikizsl_dataset/test_data_1300.csv\",\n",
    "}\n",
    "test_files = {\n",
    "    1: \"~/june-19/wikizsl/concat_run_1/relation.concat.run.1.test.predictions.step.4000.csv\",\n",
    "    2: \"~/june-19/wikizsl/concat_run_2/relation.concat.run.0.test.predictions.step.2400.csv\",\n",
    "    3: \"~/june-19/wikizsl/concat_run_3/relation.concat.run.0.test.predictions.step.1400.csv\",\n",
    "    4: \"~/june-19/wikizsl/concat_run_4/relation.concat.run.1.test.predictions.step.1400.csv\",\n",
    "    5: \"~/june-19/wikizsl/concat_run_5/relation.concat.run.0.test.predictions.step.2200.csv\",\n",
    "}\n",
    "\n",
    "mean_f1 = 0.0\n",
    "mean_p = 0.0\n",
    "mean_r = 0.0\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [test_files[run_id]]\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "\n",
    "\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 15)), axis=1)\n",
    "            print(\"Samosh\")\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            print(run_id, avg_prec, avg_rec, f1)\n",
    "            mean_f1 += f1\n",
    "            mean_p += avg_prec\n",
    "            mean_r += avg_rec\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "mean_f1 /= 5\n",
    "mean_p /= 5\n",
    "mean_r /= 5\n",
    "print(\"mean_p\", mean_p)\n",
    "print(\"mean_r\", mean_r)\n",
    "print(\"mean_f\", mean_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction_f1s(prediction_files, gold_file, id_file):\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_file, sep=',')[\"relation_ids\"].tolist())}\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if max_f1 < f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "    print(run_id, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ~/august_29/fewrel/concat_run_12321/relation.concat.run.12321.epoch.0.dev.predictions.step.9900.csv 0.6225757946913466\n",
      "1 ~/august_29/fewrel/concat_run_12321_lr_0.00005/relation.concat.run.12321.epoch.0.dev.predictions.step.3700.csv 0.598789217937264\n",
      "1 ~/august_29/fewrel/concat_run_12321_adam/relation.concat.run.12321.epoch.0.dev.predictions.step.700.csv 0.5939651344395138\n"
     ]
    }
   ],
   "source": [
    "# Investigate Ada-factor with different learning rates using the concat model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/val_ids_12321.csv\",\n",
    "}\n",
    "gold_files = {   \n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/val_data_12321.csv\",\n",
    "}\n",
    "\n",
    "for run_id in range(1, 2, 1):\n",
    "    prediction_files = [\"~/august_29/fewrel/concat_run_12321/relation.concat.run.12321.epoch.0.dev.predictions.step.{}.csv\".format(100 * i) for i in range(1, 105, 1)]\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    compute_prediction_f1s(prediction_files, gold_files[run_id], id_files[run_id])\n",
    "\n",
    "for run_id in range(1, 2, 1):\n",
    "    prediction_files = [\"~/august_29/fewrel/concat_run_12321_lr_0.00005/relation.concat.run.12321.epoch.0.dev.predictions.step.{}.csv\".format(100 * i) for i in range(1, 105, 1)]\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    compute_prediction_f1s(prediction_files, gold_files[run_id], id_files[run_id])\n",
    "\n",
    "for run_id in range(1, 2, 1):\n",
    "    prediction_files = [\"~/august_29/fewrel/concat_run_12321_adam/relation.concat.run.12321.epoch.0.dev.predictions.step.{}.csv\".format(100 * i) for i in range(1, 105, 1)]\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    compute_prediction_f1s(prediction_files, gold_files[run_id], id_files[run_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
