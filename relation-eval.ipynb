{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_macro_PRF(predicted_idx, gold_idx, i=-1, empty_label=None):\n",
    "    '''\n",
    "    This evaluation function follows work from Sorokin and Gurevych(https://www.aclweb.org/anthology/D17-1188.pdf)\n",
    "    code borrowed from the following link:\n",
    "    https://github.com/UKPLab/emnlp2017-relation-extraction/blob/master/relation_extraction/evaluation/metrics.py\n",
    "    '''\n",
    "    if i == -1:\n",
    "        i = len(predicted_idx)\n",
    "\n",
    "    complete_rel_set = set(gold_idx) - {empty_label}\n",
    "    avg_prec = 0.0\n",
    "    avg_rec = 0.0\n",
    "\n",
    "    for r in complete_rel_set:\n",
    "        r_indices = (predicted_idx[:i] == r)\n",
    "        tp = len((predicted_idx[:i][r_indices] == gold_idx[:i][r_indices]).nonzero()[0])\n",
    "        tp_fp = len(r_indices.nonzero()[0])\n",
    "        tp_fn = len((gold_idx == r).nonzero()[0])\n",
    "        prec = (tp / tp_fp) if tp_fp > 0 else 0\n",
    "        rec = tp / tp_fn\n",
    "        #print(id_to_labels[r], prec, rec, 2.0 * prec * rec / (prec + rec))\n",
    "        avg_prec += prec\n",
    "        avg_rec += rec\n",
    "    f1 = 0\n",
    "    avg_prec = avg_prec / len(set(predicted_idx[:i]))\n",
    "    avg_rec = avg_rec / len(complete_rel_set)\n",
    "    if (avg_rec+avg_prec) > 0:\n",
    "        f1 = 2.0 * avg_prec * avg_rec / (avg_prec + avg_rec)\n",
    "\n",
    "    return avg_prec, avg_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelationPrompt p: 0.4776472720786848, r: 0.3602666666666667, f1: 0.4071264051681733\n",
      "RelationPrompt with added data p: 0.5564498521345045, r: 0.5548761904761905, f1: 0.5552867829940056\n"
     ]
    }
   ],
   "source": [
    "#RelationPrompt Results.\n",
    "\n",
    "results_no_added_data = {\n",
    "    \"12321\": {\n",
    "        \"precision\": 0.563572016705731,\n",
    "        \"recall\": 0.3225714285714286,\n",
    "        \"score\": 0.41029978047129695,\n",
    "\n",
    "    },\n",
    "    \"111\": {\n",
    "        \"precision\": 0.3782919141331947,\n",
    "        \"recall\": 0.2439047619047619,\n",
    "        \"score\": 0.2965853171530759,\n",
    "    },\n",
    "    \"943\": {\n",
    "        \"precision\": 0.5670379080898744,\n",
    "        \"recall\": 0.424,\n",
    "        \"score\": 0.48519652188380946,\n",
    "    },\n",
    "    \"300\": {\n",
    "        \"precision\": 0.4160565573101449,\n",
    "        \"recall\": 0.3947619047619048,\n",
    "        \"score\": 0.4051295986347155,\n",
    "    },\n",
    "    \"1300\": {\n",
    "        \"precision\": 0.46327796415447897,\n",
    "        \"recall\": 0.4160952380952381,\n",
    "        \"score\": 0.43842080769796876,\n",
    "    }\n",
    "}\n",
    "\n",
    "results_with_added_data = {\n",
    "    \"12321\": {\n",
    "        \"precision\": 0.6335737530573299,\n",
    "        \"recall\": 0.6580952380952382,\n",
    "        \"score\": 0.6456017334551125,\n",
    "    },\n",
    "    \"943\": {\n",
    "        \"precision\": 0.6568560306481417,\n",
    "        \"recall\": 0.6818095238095239,\n",
    "        \"score\": 0.6691002035217998,\n",
    "    },\n",
    "    \"111\": {\n",
    "        \"precision\": 0.5521802938349817,\n",
    "        \"recall\": 0.534952380952381,\n",
    "        \"score\": 0.5434298310641532,\n",
    "    },\n",
    "    \"300\": {\n",
    "        \"precision\": 0.42557058135412607,\n",
    "        \"recall\": 0.3803809523809524,\n",
    "        \"score\": 0.4017088776805001,\n",
    "    },\n",
    "    \"1300\": {\n",
    "        \"precision\": 0.5140686017779429,\n",
    "        \"recall\": 0.5191428571428571,\n",
    "        \"score\": 0.5165932692484626,\n",
    "    }\n",
    "}\n",
    "\n",
    "no_added_avg_f1 = 0.0\n",
    "no_added_avg_p = 0.0\n",
    "no_added_avg_r = 0.0\n",
    "for seed, scores in results_no_added_data.items():\n",
    "    no_added_avg_r += scores[\"recall\"]\n",
    "    no_added_avg_p += scores[\"precision\"]\n",
    "    no_added_avg_f1 += scores[\"score\"]\n",
    "\n",
    "no_added_avg_f1 = no_added_avg_f1 / len(results_no_added_data.keys())\n",
    "no_added_avg_p = no_added_avg_p / len(results_no_added_data.keys())\n",
    "no_added_avg_r = no_added_avg_r / len(results_no_added_data.keys())\n",
    "print(\"RelationPrompt p: {}, r: {}, f1: {}\".format(no_added_avg_p, no_added_avg_r, no_added_avg_f1))\n",
    "\n",
    "with_added_avg_f1 = 0.0\n",
    "with_added_avg_p = 0.0\n",
    "with_added_avg_r = 0.0\n",
    "for seed, scores in results_with_added_data.items():\n",
    "    with_added_avg_r += scores[\"recall\"]\n",
    "    with_added_avg_p += scores[\"precision\"]\n",
    "    with_added_avg_f1 += scores[\"score\"]\n",
    "\n",
    "with_added_avg_f1 = with_added_avg_f1 / len(results_with_added_data.keys())\n",
    "with_added_avg_p = with_added_avg_p / len(results_with_added_data.keys())\n",
    "with_added_avg_r = with_added_avg_r / len(results_with_added_data.keys())\n",
    "print(\"RelationPrompt with added data p: {}, r: {}, f1: {}\".format(with_added_avg_p, with_added_avg_r, with_added_avg_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RelationPrompt Results on the test data without sentences having multiple triplets.\n",
    "\n",
    "results_no_added_data = {\n",
    "    \"12321\": {\n",
    "       \"precision\": 0.5288569302012683,\n",
    "        \"recall\": 0.4371477910978992,\n",
    "        \"score\": 0.4786490867940637,\n",
    "    },\n",
    "    \"111\": {\n",
    "       \"precision\": 0.5514520480423039,\n",
    "        \"recall\": 0.45100775119994635,\n",
    "        \"score\": 0.4961977493165534,\n",
    "    },\n",
    "    \"943\": {\n",
    "       \"precision\": 0.583743934277585,\n",
    "        \"recall\": 0.48417201001017734,\n",
    "        \"score\": 0.5293159550659702,\n",
    "    },\n",
    "    \"300\": {\n",
    "        \"precision\": 0.5138102385350568,\n",
    "        \"recall\": 0.4780500550525526,\n",
    "        \"score\": 0.4952855042312534,\n",
    "    },\n",
    "    \"1300\": {\n",
    "        \"precision\": 0.5446269710553917,\n",
    "        \"recall\": 0.4770284827169461,\n",
    "        \"score\": 0.5085913782185381,\n",
    "    }\n",
    "}\n",
    "\n",
    "results_with_added_data = {\n",
    "    \"12321\": {\n",
    "        \"precision\": 0.6134127769859357,\n",
    "        \"recall\": 0.5869961902111368,\n",
    "        \"score\": 0.5999138176355603,   \n",
    "    },\n",
    "    \"943\": {\n",
    "       \"precision\": 0.6887865911137259,\n",
    "        \"recall\": 0.6922624338057392,\n",
    "        \"score\": 0.6905201384360007,\n",
    "    },\n",
    "    \"111\": {\n",
    "        \"precision\": 0.6750761729608312,\n",
    "        \"recall\": 0.7013992255134261,\n",
    "        \"score\": 0.6879860045477596,\n",
    "    },\n",
    "    \"300\": {\n",
    "        \"precision\": 0.5140957915191029,\n",
    "        \"recall\": 0.5013268888307134,\n",
    "        \"score\": 0.5076310559351425,\n",
    "    },\n",
    "    \"1300\": {\n",
    "        \"precision\": 0.5696408693992706,\n",
    "        \"recall\": 0.6290561164980496,\n",
    "        \"score\": 0.5978759892094577,\n",
    "    }\n",
    "}\n",
    "\n",
    "no_added_avg_f1 = 0.0\n",
    "no_added_avg_p = 0.0\n",
    "no_added_avg_r = 0.0\n",
    "for seed, scores in results_no_added_data.items():\n",
    "    no_added_avg_r += scores[\"recall\"]\n",
    "    no_added_avg_p += scores[\"precision\"]\n",
    "    no_added_avg_f1 += scores[\"score\"]\n",
    "\n",
    "no_added_avg_f1 = no_added_avg_f1 / len(results_no_added_data.keys())\n",
    "no_added_avg_p = no_added_avg_p / len(results_no_added_data.keys())\n",
    "no_added_avg_r = no_added_avg_r / len(results_no_added_data.keys())\n",
    "print(\"RelationPrompt p: {}, r: {}, f1: {}\".format(no_added_avg_p, no_added_avg_r, no_added_avg_f1))\n",
    "\n",
    "with_added_avg_f1 = 0.0\n",
    "with_added_avg_p = 0.0\n",
    "with_added_avg_r = 0.0\n",
    "for seed, scores in results_with_added_data.items():\n",
    "    with_added_avg_r += scores[\"recall\"]\n",
    "    with_added_avg_p += scores[\"precision\"]\n",
    "    with_added_avg_f1 += scores[\"score\"]\n",
    "\n",
    "with_added_avg_f1 = with_added_avg_f1 / len(results_with_added_data.keys())\n",
    "with_added_avg_p = with_added_avg_p / len(results_with_added_data.keys())\n",
    "with_added_avg_r = with_added_avg_r / len(results_with_added_data.keys())\n",
    "print(\"RelationPrompt with added data p: {}, r: {}, f1: {}\".format(with_added_avg_p, with_added_avg_r, with_added_avg_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelationPrompt p: 0.46809274436460635, r: 0.20921904761904758, f1: 0.2850566304723004\n",
      "RelationPrompt with added data p: 0.49878761344938083, r: 0.48481904761904754, f1: 0.4904729285339803\n"
     ]
    }
   ],
   "source": [
    "# RelationPrompt Results on the test data with negs data.\n",
    "\n",
    "results_no_added_data = {\n",
    "    \"12321\": {\n",
    "       \"precision\": 0.459251382294596,\n",
    "        \"recall\": 0.11276190476190477,\n",
    "        \"score\": 0.18106593606788426,\n",
    "    },\n",
    "    \"111\": {\n",
    "       \"precision\": 0.3305721717039897,\n",
    "        \"recall\": 0.17371428571428568,\n",
    "        \"score\": 0.22774797078061565,\n",
    "    },\n",
    "    \"943\": {\n",
    "       \"precision\": 0.48672764408023866,\n",
    "        \"recall\": 0.25685714285714284,\n",
    "        \"score\": 0.3362615110052447,\n",
    "    },\n",
    "    \"300\": {\n",
    "       \"precision\": 0.5159171136238571,                                                                                               \n",
    "        \"recall\": 0.27723809523809523,                                                                                                 \n",
    "        \"score\": 0.3606655451132733,         \n",
    "    },\n",
    "    \"1300\": {\n",
    "        \"precision\": 0.5479954101203502,\n",
    "        \"recall\": 0.22552380952380954,\n",
    "        \"score\": 0.3195421893944839,\n",
    "    }\n",
    "}\n",
    "\n",
    "results_with_added_data = {\n",
    "    \"12321\": {\n",
    "        \"precision\": 0.5501224678769095,\n",
    "        \"recall\": 0.5651428571428572,\n",
    "        \"score\": 0.5575315152363876, \n",
    "    },\n",
    "    \"943\": {\n",
    "       \"precision\": 0.543395939080254,\n",
    "        \"recall\": 0.4959047619047619,\n",
    "        \"score\": 0.518565288244702,\n",
    "    },\n",
    "    \"111\": {\n",
    "       \"precision\": 0.4962629947119975,\n",
    "        \"recall\": 0.523142857142857,\n",
    "        \"score\": 0.5093485395939629,\n",
    "    },\n",
    "    \"300\": {\n",
    "        \"precision\": 0.40499570471570406,\n",
    "         \"recall\": 0.3205714285714285,\n",
    "        \"score\": 0.35787192023932907,\n",
    "    },\n",
    "    \"1300\": {\n",
    "        \"precision\": 0.49916096086203887,\n",
    "        \"recall\": 0.5193333333333333,\n",
    "        \"score\": 0.5090473793555202,\n",
    "    }\n",
    "}\n",
    "\n",
    "no_added_avg_f1 = 0.0\n",
    "no_added_avg_p = 0.0\n",
    "no_added_avg_r = 0.0\n",
    "for seed, scores in results_no_added_data.items():\n",
    "    no_added_avg_r += scores[\"recall\"]\n",
    "    no_added_avg_p += scores[\"precision\"]\n",
    "    no_added_avg_f1 += scores[\"score\"]\n",
    "\n",
    "no_added_avg_f1 = no_added_avg_f1 / len(results_no_added_data.keys())\n",
    "no_added_avg_p = no_added_avg_p / len(results_no_added_data.keys())\n",
    "no_added_avg_r = no_added_avg_r / len(results_no_added_data.keys())\n",
    "print(\"RelationPrompt p: {}, r: {}, f1: {}\".format(no_added_avg_p, no_added_avg_r, no_added_avg_f1))\n",
    "\n",
    "with_added_avg_f1 = 0.0\n",
    "with_added_avg_p = 0.0\n",
    "with_added_avg_r = 0.0\n",
    "for seed, scores in results_with_added_data.items():\n",
    "    with_added_avg_r += scores[\"recall\"]\n",
    "    with_added_avg_p += scores[\"precision\"]\n",
    "    with_added_avg_f1 += scores[\"score\"]\n",
    "\n",
    "with_added_avg_f1 = with_added_avg_f1 / len(results_with_added_data.keys())\n",
    "with_added_avg_p = with_added_avg_p / len(results_with_added_data.keys())\n",
    "with_added_avg_r = with_added_avg_r / len(results_with_added_data.keys())\n",
    "print(\"RelationPrompt with added data p: {}, r: {}, f1: {}\".format(with_added_avg_p, with_added_avg_r, with_added_avg_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-1/fewrel/concat_run_12321/relation.concat.run.12321.epoch.0.dev.predictions.step.9900.csv 0.6225757946913466\n",
      "943 ~/sep-1/fewrel/concat_run_943/relation.concat.run.943.epoch.0.dev.predictions.step.1300.csv 0.5099570516870796\n",
      "111 ~/sep-1/fewrel/concat_run_111/relation.concat.run.111.epoch.0.dev.predictions.step.5000.csv 0.5992184520328142\n",
      "300 ~/sep-1/fewrel/concat_run_300/relation.concat.run.300.epoch.0.dev.predictions.step.5500.csv 0.7290633687525613\n",
      "1300 ~/sep-1/fewrel/concat_run_1300/relation.concat.run.1300.epoch.0.dev.predictions.step.1300.csv 0.6430064368535299\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for the model on the fewrel dataset using the concat model without the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data/val_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data/val_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data/val_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data/val_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data/val_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data/val_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data/val_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data/val_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data/val_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data/val_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "for seed in seeds:\n",
    "    predictions = [\"~/sep-1/fewrel/concat_run_{}/relation.concat.run.{}.epoch.0.dev.predictions.step.{}.csv\".format(seed, seed, step * 100) for step in range(1, 106, 1)]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    prediction_files = predictions\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-28/wikizsl/concat_run_12321/relation.concat.run.epoch.0.dev.predictions.step.1700.csv 0.4742412814446165\n",
      "943 ~/sep-28/wikizsl/concat_run_943/relation.concat.run.epoch.0.dev.predictions.step.4000.csv 0.6433634224082675\n",
      "111 ~/sep-28/wikizsl/concat_run_111/relation.concat.run.epoch.0.dev.predictions.step.2000.csv 0.462240973169985\n",
      "300 ~/sep-28/wikizsl/concat_run_300/relation.concat.run.epoch.0.dev.predictions.step.4700.csv 0.6777896183831733\n",
      "1300 ~/sep-28/wikizsl/concat_run_1300/relation.concat.run.epoch.0.dev.predictions.step.4400.csv 0.48692508873389795\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for the model on the wikizsl dataset using the concat model without the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/wikizsl_data/val_data_12321.csv.sampled.csv\",\n",
    "    943: \"~/codes/QA-ZRE/wikizsl_data/val_data_943.csv.sampled.csv\",\n",
    "    111: \"~/codes/QA-ZRE/wikizsl_data/val_data_111.csv.sampled.csv\",\n",
    "    300: \"~/codes/QA-ZRE/wikizsl_data/val_data_300.csv.sampled.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/wikizsl_data/val_data_1300.csv.sampled.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/wikizsl_data/val_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/wikizsl_data/val_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/wikizsl_data/val_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/wikizsl_data/val_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/wikizsl_data/val_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "for seed in seeds:\n",
    "    predictions = [\"~/sep-28/wikizsl/concat_run_{}/relation.concat.run.epoch.0.dev.predictions.step.{}.csv\".format(seed, step * 100) for step in range(1, 48, 1)]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    prediction_files = predictions\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    gold_entity_relations = df[\"entity_relations\"].tolist()\n",
    "    gold_relations = [row.split(\"<SEP>\")[1].strip() for row in gold_entity_relations][:5]\n",
    "\n",
    "    label_to_id = {}\n",
    "    with open(\"./relation_descriptions.json\", \"r\") as fd:\n",
    "        re_desc_data = json.load(fd)\n",
    "        for row in re_desc_data:\n",
    "            re_label = row[\"relation_label\"]\n",
    "            re_id = row[\"relation_id\"]\n",
    "            label_to_id[re_label] = re_id\n",
    "\n",
    "    ids = {label_to_id[rel_label]: i for i, rel_label in enumerate(gold_relations)}\n",
    "\n",
    "    # ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-28/wikizsl/concat_run_12321_with_unks/relation.concat.run.epoch.0.dev.predictions.step.8100.csv 0.7789526506917566\n",
      "943 ~/sep-28/wikizsl/concat_run_943_with_unks/relation.concat.run.epoch.0.dev.predictions.step.3900.csv 0.7846069028486728\n",
      "111 ~/sep-28/wikizsl/concat_run_111_with_unks/relation.concat.run.epoch.0.dev.predictions.step.7700.csv 0.5954701697186493\n",
      "300 ~/sep-28/wikizsl/concat_run_300_with_unks/relation.concat.run.epoch.0.dev.predictions.step.8200.csv 0.8075851218740074\n",
      "1300 ~/sep-28/wikizsl/concat_run_1300_with_unks/relation.concat.run.epoch.0.dev.predictions.step.4200.csv 0.710696564194337\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for the model on the wikizsl dataset using the concat model with the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_12321.csv.sampled.csv\",\n",
    "    943: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_943.csv.sampled.csv\",\n",
    "    111: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_111.csv.sampled.csv\",\n",
    "    300: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_300.csv.sampled.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_1300.csv.sampled.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/wikizsl_data_unks/val_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/wikizsl_data_unks/val_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/wikizsl_data_unks/val_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/wikizsl_data_unks/val_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/wikizsl_data_unks/val_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "for seed in seeds:\n",
    "    predictions = [\"~/sep-28/wikizsl/concat_run_{}_with_unks/relation.concat.run.epoch.0.dev.predictions.step.{}.csv\".format(seed, step * 100) for step in range(1, 94, 1)]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    prediction_files = predictions\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "\n",
    "    gold_entity_relations = df[\"entity_relations\"].tolist()\n",
    "    gold_relations = [row.split(\"<SEP>\")[1].strip() for row in gold_entity_relations][:5]\n",
    "\n",
    "    label_to_id = {}\n",
    "    with open(\"./relation_descriptions.json\", \"r\") as fd:\n",
    "        re_desc_data = json.load(fd)\n",
    "        for row in re_desc_data:\n",
    "            re_label = row[\"relation_label\"]\n",
    "            re_id = row[\"relation_id\"]\n",
    "            label_to_id[re_label] = re_id\n",
    "\n",
    "    ids = {label_to_id[rel_label]: i for i, rel_label in enumerate(gold_relations)}\n",
    "\n",
    "    #ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-1/fewrel/concat_run_12321_with_unks/relation.concat.run.epoch.0.dev.predictions.step.8600.csv 0.8560795626010362\n",
      "943 ~/sep-1/fewrel/concat_run_943_with_unks/relation.concat.run.epoch.0.dev.predictions.step.3400.csv 0.7936263560920236\n",
      "111 ~/sep-1/fewrel/concat_run_111_with_unks/relation.concat.run.epoch.0.dev.predictions.step.4600.csv 0.8865212316090652\n",
      "300 ~/sep-1/fewrel/concat_run_300_with_unks/relation.concat.run.epoch.0.dev.predictions.step.6100.csv 0.8899964022223363\n",
      "1300 ~/sep-1/fewrel/concat_run_1300_with_unks/relation.concat.run.epoch.0.dev.predictions.step.13700.csv 0.8507511193598049\n",
      "0.8553949343768531\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for the model on the fewrel dataset using the concat model with the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "avg_f1_dev = 0.0\n",
    "for seed in seeds:\n",
    "    predictions = [\"~/sep-1/fewrel/concat_run_{}_with_unks/relation.concat.run.epoch.0.dev.predictions.step.{}.csv\".format(seed, step * 100) for step in range(1, 210, 1)]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    prediction_files = predictions\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    avg_f1_dev += max_f1\n",
    "    print(seed, max_file, max_f1)\n",
    "\n",
    "print(avg_f1_dev/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-1/fewrel/concat_run_12321/relation.concat.run.12321.epoch.0.test.predictions.step.9900.csv 0.34701733359825704\n",
      "943 ~/sep-1/fewrel/concat_run_943/relation.concat.run.943.epoch.0.test.predictions.step.1300.csv 0.3671554049998069\n",
      "111 ~/sep-1/fewrel/concat_run_111/relation.concat.run.111.epoch.0.test.predictions.step.5000.csv 0.256033773197929\n",
      "300 ~/sep-1/fewrel/concat_run_300/relation.concat.run.300.epoch.0.test.predictions.step.5500.csv 0.3014579520878535\n",
      "1300 ~/sep-1/fewrel/concat_run_1300/relation.concat.run.1300.epoch.0.test.predictions.step.1300.csv 0.3067879888834918\n",
      "0.31569049055346765\n",
      "0.3082683125936674\n",
      "0.32371428571428573\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for the model on the fewrel dataset using the concat model without the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data/test_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data/test_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data/test_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data/test_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data/test_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data/test_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data/test_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data/test_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data/test_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data/test_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "prediction_files = {\n",
    "    12321: \"~/sep-1/fewrel/concat_run_12321/relation.concat.run.12321.epoch.0.test.predictions.step.9900.csv\",\n",
    "    943: \"~/sep-1/fewrel/concat_run_943/relation.concat.run.943.epoch.0.test.predictions.step.1300.csv\",\n",
    "    111: \"~/sep-1/fewrel/concat_run_111/relation.concat.run.111.epoch.0.test.predictions.step.5000.csv\",\n",
    "    300: \"~/sep-1/fewrel/concat_run_300/relation.concat.run.300.epoch.0.test.predictions.step.5500.csv\",\n",
    "    1300: \"~/sep-1/fewrel/concat_run_1300/relation.concat.run.1300.epoch.0.test.predictions.step.1300.csv\",\n",
    "}\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "avg_f1 = 0.0\n",
    "avg_p = 0.0\n",
    "avg_r = 0.0\n",
    "for seed in seeds:\n",
    "    predictions = [prediction_files[seed]]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in predictions:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 15)), axis=1)\n",
    "        prec, rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        avg_f1 += f1\n",
    "        avg_p += prec\n",
    "        avg_r += rec\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)\n",
    "\n",
    "print(avg_f1/5.0)\n",
    "print(avg_p/5.0)\n",
    "print(avg_r/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-1/fewrel/concat_run_12321_with_unks/relation.concat.run.12321.epoch.0.test.predictions.step.8600.csv 0.6744073305090348\n",
      "943 ~/sep-1/fewrel/concat_run_943_with_unks/relation.concat.run.943.epoch.0.test.predictions.step.3400.csv 0.649950240610028\n",
      "111 ~/sep-1/fewrel/concat_run_111_with_unks/relation.concat.run.111.epoch.0.test.predictions.step.4600.csv 0.5539922978879085\n",
      "300 ~/sep-1/fewrel/concat_run_300_with_unks/relation.concat.run.300.epoch.0.test.predictions.step.6100.csv 0.4930803340711556\n",
      "1300 ~/sep-1/fewrel/concat_run_1300_with_unks/relation.concat.run.1300.epoch.0.test.predictions.step.13700.csv 0.6530094576640766\n",
      "f1:  0.6048879321484406\n",
      "p:  0.6280573304427337\n",
      "r:  0.5836190476190477\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for the model on the fewrel dataset using the concat model with the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "prediction_files = {\n",
    "    12321: \"~/sep-1/fewrel/concat_run_12321_with_unks/relation.concat.run.12321.epoch.0.test.predictions.step.8600.csv\",\n",
    "    943: \"~/sep-1/fewrel/concat_run_943_with_unks/relation.concat.run.943.epoch.0.test.predictions.step.3400.csv\",\n",
    "    111: \"~/sep-1/fewrel/concat_run_111_with_unks/relation.concat.run.111.epoch.0.test.predictions.step.4600.csv\",\n",
    "    300: \"~/sep-1/fewrel/concat_run_300_with_unks/relation.concat.run.300.epoch.0.test.predictions.step.6100.csv\",\n",
    "    1300: \"~/sep-1/fewrel/concat_run_1300_with_unks/relation.concat.run.1300.epoch.0.test.predictions.step.13700.csv\",\n",
    "}\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "avg_f1 = 0.0\n",
    "avg_p = 0.0\n",
    "avg_r = 0.0\n",
    "for seed in seeds:\n",
    "    predictions = [prediction_files[seed]]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in predictions:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 15)), axis=1)\n",
    "        prec, rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        avg_f1 += f1\n",
    "        avg_p += prec\n",
    "        avg_r += rec\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)\n",
    "\n",
    "print(\"f1: \", avg_f1/5.0)\n",
    "print(\"p: \", avg_p/5.0)\n",
    "print(\"r: \", avg_r/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-28/wikizsl/concat_run_12321/relation.concat.run.12321.epoch.0.test.predictions.step.1700.csv 0.287491358493333\n",
      "943 ~/sep-28/wikizsl/concat_run_943/relation.concat.run.943.epoch.0.test.predictions.step.4000.csv 0.33523016814229356\n",
      "111 ~/sep-28/wikizsl/concat_run_111/relation.concat.run.111.epoch.0.test.predictions.step.2000.csv 0.25736755828754043\n",
      "300 ~/sep-28/wikizsl/concat_run_300/relation.concat.run.300.epoch.0.test.predictions.step.4700.csv 0.46728152259303596\n",
      "1300 ~/sep-28/wikizsl/concat_run_1300/relation.concat.run.1300.epoch.0.test.predictions.step.4400.csv 0.34425972150396533\n",
      "f1:  0.3383260658040336\n",
      "p:  0.3310861160390882\n",
      "r:  0.3464293234111697\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for the model on the wikizsl dataset using the concat model without the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/wikizsl_data/test_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/wikizsl_data/test_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/wikizsl_data/test_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/wikizsl_data/test_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/wikizsl_data/test_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/wikizsl_data/test_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/wikizsl_data/test_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/wikizsl_data/test_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/wikizsl_data/test_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/wikizsl_data/test_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "prediction_files = {\n",
    "    12321: \"~/sep-28/wikizsl/concat_run_12321/relation.concat.run.12321.epoch.0.test.predictions.step.1700.csv\",\n",
    "    943: \"~/sep-28/wikizsl/concat_run_943/relation.concat.run.943.epoch.0.test.predictions.step.4000.csv\",\n",
    "    111: \"~/sep-28/wikizsl/concat_run_111/relation.concat.run.111.epoch.0.test.predictions.step.2000.csv\",\n",
    "    300: \"~/sep-28/wikizsl/concat_run_300/relation.concat.run.300.epoch.0.test.predictions.step.4700.csv\",\n",
    "    1300: \"~/sep-28/wikizsl/concat_run_1300/relation.concat.run.1300.epoch.0.test.predictions.step.4400.csv\",\n",
    "}\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "avg_f1 = 0.0\n",
    "avg_p = 0.0\n",
    "avg_r = 0.0\n",
    "for seed in seeds:\n",
    "    predictions = [prediction_files[seed]]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "\n",
    "    gold_entity_relations = df[\"entity_relations\"].tolist()\n",
    "    gold_relations = [row.split(\"<SEP>\")[1].strip() for row in gold_entity_relations][:15]\n",
    "\n",
    "    label_to_id = {}\n",
    "    with open(\"./relation_descriptions.json\", \"r\") as fd:\n",
    "        re_desc_data = json.load(fd)\n",
    "        for row in re_desc_data:\n",
    "            re_label = row[\"relation_label\"]\n",
    "            re_id = row[\"relation_id\"]\n",
    "            label_to_id[re_label] = re_id\n",
    "\n",
    "    ids = {label_to_id[rel_label]: i for i, rel_label in enumerate(gold_relations)}\n",
    "\n",
    "\n",
    "    #ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in predictions:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 15)), axis=1)\n",
    "        prec, rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        avg_f1 += f1\n",
    "        avg_p += prec\n",
    "        avg_r += rec\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)\n",
    "\n",
    "print(\"f1: \", avg_f1/5.0)\n",
    "print(\"p: \", avg_p/5.0)\n",
    "print(\"r: \", avg_r/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-1/fewrel/run_12321/relation.offmml-pgg.run.epoch.0.dev.predictions.step.1800.csv 0.6498331456500441\n",
      "943 ~/sep-1/fewrel/run_943/relation.offmml-pgg.run.epoch.0.dev.predictions.step.1900.csv 0.5659540894916784\n",
      "111 ~/sep-1/fewrel/run_111/relation.offmml-pgg.run.epoch.0.dev.predictions.step.8800.csv 0.6217527243186586\n",
      "300 ~/sep-1/fewrel/run_300/relation.offmml-pgg.run.epoch.0.dev.predictions.step.1900.csv 0.7017740927559872\n",
      "1300 ~/sep-1/fewrel/run_1300/relation.offmml-pgg.run.epoch.0.dev.predictions.step.7900.csv 0.6402843822685743\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for the model on the fewrel dataset using the offmml-g model without the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data/val_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data/val_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data/val_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data/val_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data/val_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data/val_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data/val_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data/val_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data/val_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data/val_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "for seed in seeds:\n",
    "    predictions = [\"~/sep-1/fewrel/run_{}/relation.offmml-pgg.run.epoch.0.dev.predictions.step.{}.csv\".format(seed, step * 100) for step in range(1, 106, 1)]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    prediction_files = predictions\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "        pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 5, 8)), axis=2))\n",
    "        pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-28/wikizsl/run_12321/relation.offmml-pgg.run.epoch.0.dev.predictions.step.800.csv 0.4203692048623931\n",
      "943 ~/sep-28/wikizsl/run_943/relation.offmml-pgg.run.epoch.0.dev.predictions.step.3000.csv 0.6375243450837228\n",
      "111 ~/sep-28/wikizsl/run_111/relation.offmml-pgg.run.epoch.0.dev.predictions.step.500.csv 0.5169302461492905\n",
      "300 ~/sep-28/wikizsl/run_300/relation.offmml-pgg.run.epoch.0.dev.predictions.step.1500.csv 0.6790189264600169\n",
      "1300 ~/sep-28/wikizsl/run_1300/relation.offmml-pgg.run.epoch.0.dev.predictions.step.2400.csv 0.4979349584311499\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for the model on the wikizsl dataset using the offmml-g model without the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/wikizsl_data/val_data_12321.csv.sampled.csv\",\n",
    "    943: \"~/codes/QA-ZRE/wikizsl_data/val_data_943.csv.sampled.csv\",\n",
    "    111: \"~/codes/QA-ZRE/wikizsl_data/val_data_111.csv.sampled.csv\",\n",
    "    300: \"~/codes/QA-ZRE/wikizsl_data/val_data_300.csv.sampled.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/wikizsl_data/val_data_1300.csv.sampled.csv\",\n",
    "}\n",
    "\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "for seed in seeds:\n",
    "    predictions = [\"~/sep-28/wikizsl/run_{}/relation.offmml-pgg.run.epoch.0.dev.predictions.step.{}.csv\".format(seed, step * 100) for step in range(1, 46, 1)]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    prediction_files = predictions\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    gold_entity_relations = df[\"entity_relations\"].tolist()\n",
    "    gold_relations = [row.split(\"<SEP>\")[1].strip() for row in gold_entity_relations][:5]\n",
    "\n",
    "    label_to_id = {}\n",
    "    with open(\"./relation_descriptions.json\", \"r\") as fd:\n",
    "        re_desc_data = json.load(fd)\n",
    "        for row in re_desc_data:\n",
    "            re_label = row[\"relation_label\"]\n",
    "            re_id = row[\"relation_id\"]\n",
    "            label_to_id[re_label] = re_id\n",
    "\n",
    "    ids = {label_to_id[rel_label]: i for i, rel_label in enumerate(gold_relations)}\n",
    "\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "        pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 5, 8)), axis=2))\n",
    "        pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-28/wikizsl/run_12321_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.8900.csv 0.8487020087551942\n",
      "943 ~/sep-28/wikizsl/run_943_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.3700.csv 0.7728171239157858\n",
      "111 ~/sep-28/wikizsl/run_111_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.6900.csv 0.7598997604137664\n",
      "300 ~/sep-28/wikizsl/run_300_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.600.csv 0.7626723708239196\n",
      "1300 ~/sep-28/wikizsl/run_1300_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.4800.csv 0.7242507938718629\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for the model on the wikizsl dataset using the offmml-g model with the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_12321.csv.sampled.csv\",\n",
    "    943: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_943.csv.sampled.csv\",\n",
    "    111: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_111.csv.sampled.csv\",\n",
    "    300: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_300.csv.sampled.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/wikizsl_data_unks/val_data_1300.csv.sampled.csv\",\n",
    "}\n",
    "\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "for seed in seeds:\n",
    "    predictions = [\"~/sep-28/wikizsl/run_{}_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.{}.csv\".format(seed, step * 100) for step in range(1, 94, 1)]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    prediction_files = predictions\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    gold_entity_relations = df[\"entity_relations\"].tolist()\n",
    "    gold_relations = [row.split(\"<SEP>\")[1].strip() for row in gold_entity_relations][:5]\n",
    "\n",
    "    label_to_id = {}\n",
    "    with open(\"./relation_descriptions.json\", \"r\") as fd:\n",
    "        re_desc_data = json.load(fd)\n",
    "        for row in re_desc_data:\n",
    "            re_label = row[\"relation_label\"]\n",
    "            re_id = row[\"relation_id\"]\n",
    "            label_to_id[re_label] = re_id\n",
    "\n",
    "    ids = {label_to_id[rel_label]: i for i, rel_label in enumerate(gold_relations)}\n",
    "\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "        pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 5, 8)), axis=2))\n",
    "        pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-1/fewrel/run_12321/relation.offmml-pgg.run.epoch.0.test.predictions.step.1800.csv 0.32358858387038925\n",
      "943 ~/sep-1/fewrel/run_943/relation.offmml-pgg.run.epoch.0.test.predictions.step.1900.csv 0.3172183349253462\n",
      "111 ~/sep-1/fewrel/run_111/relation.offmml-pgg.run.epoch.0.test.predictions.step.8800.csv 0.284561011851722\n",
      "300 ~/sep-1/fewrel/run_300/relation.offmml-pgg.run.epoch.0.test.predictions.step.1900.csv 0.2525921583604101\n",
      "1300 ~/sep-1/fewrel/run_1300/relation.offmml-pgg.run.epoch.0.test.predictions.step.7900.csv 0.3175353309188262\n",
      "f: 0.2990990839853388\n",
      "p: 0.2939819684227859\n",
      "r: 0.3044952380952381\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for the model on the fewrel dataset using the offmml-g model without the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data/test_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data/test_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data/test_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data/test_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data/test_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data/test_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data/test_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data/test_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data/test_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data/test_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "prediction_files = {\n",
    "    12321: \"~/sep-1/fewrel/run_12321/relation.offmml-pgg.run.epoch.0.test.predictions.step.1800.csv\",\n",
    "    943: \"~/sep-1/fewrel/run_943/relation.offmml-pgg.run.epoch.0.test.predictions.step.1900.csv\",\n",
    "    111: \"~/sep-1/fewrel/run_111/relation.offmml-pgg.run.epoch.0.test.predictions.step.8800.csv\",\n",
    "    300: \"~/sep-1/fewrel/run_300/relation.offmml-pgg.run.epoch.0.test.predictions.step.1900.csv\",\n",
    "    1300: \"~/sep-1/fewrel/run_1300/relation.offmml-pgg.run.epoch.0.test.predictions.step.7900.csv\",\n",
    "}\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "avg_f1 = 0.0\n",
    "avg_p = 0.0\n",
    "avg_r = 0.0\n",
    "for seed in seeds:\n",
    "    predictions = [prediction_files[seed]]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in predictions:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "        pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 15, 8)), axis=2))\n",
    "        pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "        prec, rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        avg_f1 += f1\n",
    "        avg_p += prec\n",
    "        avg_r += rec\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)\n",
    "\n",
    "print(\"f:\", avg_f1/5.0)\n",
    "print(\"p:\", avg_p/5.0)\n",
    "print(\"r:\", avg_r/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-1/fewrel/run_12321_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.7700.csv 0.8984147957805454\n",
      "943 ~/sep-1/fewrel/run_943_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.5900.csv 0.8066627814635562\n",
      "111 ~/sep-1/fewrel/run_111_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.11000.csv 0.9040280878278296\n",
      "300 ~/sep-1/fewrel/run_300_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.10700.csv 0.912398403495852\n",
      "1300 ~/sep-1/fewrel/run_1300_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.15200.csv 0.8778187449916541\n",
      "0.8798645627118875\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for the model on the fewrel dataset using the offmml-g model with the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data_unks/val_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data_unks/val_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "avg_f1_dev = 0.0\n",
    "for seed in seeds:\n",
    "    predictions = [\"~/sep-1/fewrel/run_{}_with_unks/relation.offmml-pgg.run.epoch.0.dev.predictions.step.{}.csv\".format(seed, step * 100) for step in range(1, 202, 1)]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    prediction_files = predictions\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "        pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 5, 8)), axis=2))\n",
    "        pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    avg_f1_dev += max_f1\n",
    "    print(seed, max_file, max_f1)\n",
    "\n",
    "print(avg_f1_dev / 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12321 ~/sep-1/fewrel/run_12321_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.7700.csv 0.6539281780314811\n",
      "943 ~/sep-1/fewrel/run_943_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.5900.csv 0.6459036663934058\n",
      "111 ~/sep-1/fewrel/run_111_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.11000.csv 0.6397429356638897\n",
      "300 ~/sep-1/fewrel/run_300_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.10700.csv 0.5094849804267173\n",
      "1300 ~/sep-1/fewrel/run_1300_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.15200.csv 0.6165207370401674\n",
      "f: 0.6131160995111322\n",
      "p: 0.637325315840368\n",
      "r: 0.5915238095238096\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for the model on the fewrel dataset using the offmml-g model with the negative examples.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data_unks/test_data_1300.csv\",\n",
    "}\n",
    "id_files = {\n",
    "    12321: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_12321.csv\",\n",
    "    943: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_943.csv\",\n",
    "    111: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_111.csv\",\n",
    "    300: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_300.csv\",\n",
    "    1300: \"~/codes/QA-ZRE/fewrl_data_unks/test_ids_1300.csv\",\n",
    "}\n",
    "\n",
    "prediction_files = {\n",
    "    12321: \"~/sep-1/fewrel/run_12321_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.7700.csv\",\n",
    "    943: \"~/sep-1/fewrel/run_943_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.5900.csv\",\n",
    "    111: \"~/sep-1/fewrel/run_111_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.11000.csv\",\n",
    "    300: \"~/sep-1/fewrel/run_300_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.10700.csv\",\n",
    "    1300: \"~/sep-1/fewrel/run_1300_with_unks/relation.offmml-pgg.run.epoch.0.test.predictions.step.15200.csv\",\n",
    "}\n",
    "seeds = [12321, 943, 111, 300, 1300]\n",
    "\n",
    "avg_f1 = 0.0\n",
    "avg_p = 0.0\n",
    "avg_r = 0.0\n",
    "for seed in seeds:\n",
    "    predictions = [prediction_files[seed]]\n",
    "    max_f1 = 0.0\n",
    "    max_file = None\n",
    "    df = pd.read_csv(gold_files[seed], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[seed], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in predictions:\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "        pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 15, 8)), axis=2))\n",
    "        pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "        prec, rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        avg_f1 += f1\n",
    "        avg_p += prec\n",
    "        avg_r += rec\n",
    "        if max_f1 <= f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(seed, max_file, max_f1)\n",
    "\n",
    "print(\"f:\", avg_f1/5.0)\n",
    "print(\"p:\", avg_p/5.0)\n",
    "print(\"r:\", avg_r/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval of the RE-QA for relation extraction using the concat model.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.concat.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        prediction_file = \"~/reqa-predictions/fold_{}/concat/relation.concat.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 >= max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction for the RelationPrompt on the RE-QA dataset.\n",
    "from re import I\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    1: \"~/codes/RelationPrompt/train_reqa_models/fold_1/extractor/pred_in_single.jsonl\",\n",
    "}\n",
    "\n",
    "prediction_arrs = {\n",
    "    1: [\"~/codes/RelationPrompt/train_reqa_models/fold_1/extractor/pred_out_single.jsonl\"]\n",
    "}\n",
    "\n",
    "for fold_id in range(1, 2, 1):\n",
    "    prediction_files = prediction_arrs[fold_id]\n",
    "    df = pd.read_csv(gold_files[fold_id], sep=',')\n",
    "    answers = [ans.replace(\"</s>\", \"\").strip() for ans in df[\"answers\"].tolist()]\n",
    "    all_classes = set(answers)\n",
    "    ids = {val:i for i, val in enumerate(list(all_classes))}\n",
    "    actual_ids = [ids[ans] for ans in answers]\n",
    "    gold_indices = np.array(actual_ids)\n",
    "    for prediction_file in prediction_files:\n",
    "        prediction_ids = []\n",
    "        for pred_class in pd.read_csv(prediction_file, sep=',')[\"predictions_str\"].tolist():\n",
    "            if pred_class.strip() in ids:\n",
    "                prediction_ids.append(ids[pred_class.strip()])\n",
    "            else:\n",
    "                prediction_ids.append(-1)\n",
    "        pred_ids = np.array(prediction_ids)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 > max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "        print(prediction_file, avg_prec, avg_rec, f1)\n",
    "\n",
    "print(max_f1, max_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.6645079529607614\n",
      "~/reqa-predictions/fold_1/concat/relation.concat.dev.predictions.fold.1.step.3600.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.7355692801363015\n",
      "~/reqa-predictions/fold_2/concat/relation.concat.dev.predictions.fold.2.step.4300.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.816466070295921\n",
      "~/reqa-predictions/fold_3/concat/relation.concat.dev.predictions.fold.3.step.5200.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.820538067780762\n",
      "~/reqa-predictions/fold_4/concat/relation.concat.dev.predictions.fold.4.step.1600.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.7970665456384882\n",
      "~/reqa-predictions/fold_5/concat/relation.concat.dev.predictions.fold.5.step.2900.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.9100498471715361\n",
      "~/reqa-predictions/fold_6/concat/relation.concat.dev.predictions.fold.6.step.1400.csv\n",
      "\n",
      "\n",
      "7\n",
      "0.7789862082105365\n",
      "~/reqa-predictions/fold_7/concat/relation.concat.dev.predictions.fold.7.step.2500.csv\n",
      "\n",
      "\n",
      "8\n",
      "0.7585498509710629\n",
      "~/reqa-predictions/fold_8/concat/relation.concat.dev.predictions.fold.8.step.400.csv\n",
      "\n",
      "\n",
      "9\n",
      "0.7690369496615103\n",
      "~/reqa-predictions/fold_9/concat/relation.concat.dev.predictions.fold.9.step.2600.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.7394406760740089\n",
      "~/reqa-predictions/fold_10/concat/relation.concat.dev.predictions.fold.10.step.800.csv\n",
      "\n",
      "\n",
      "0.7790211448900889\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA for relation extraction using the concat model.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.concat.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        prediction_file = \"~/reqa-predictions/fold_{}/concat/relation.concat.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 >= max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 1\n",
      "159 1\n",
      "162 1\n",
      "163 1\n",
      "164 1\n",
      "165 1\n",
      "167 1\n",
      "168 1\n",
      "169 1\n",
      "171 1\n",
      "1\n",
      "0.7958029874558785\n",
      "~/reqa-predictions/fold_1/gold/relation.gold.dev.predictions.fold.1.step.600.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.8055480874453981\n",
      "~/reqa-predictions/fold_2/gold/relation.gold.dev.predictions.fold.2.step.1900.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.8088784230714176\n",
      "~/reqa-predictions/fold_3/gold/relation.gold.dev.predictions.fold.3.step.200.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.7950547270773886\n",
      "~/reqa-predictions/fold_4/gold/relation.gold.dev.predictions.fold.4.step.9500.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.8218222460881007\n",
      "~/reqa-predictions/fold_5/gold/relation.gold.dev.predictions.fold.5.step.15300.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.9343882793208368\n",
      "~/reqa-predictions/fold_6/gold/relation.gold.dev.predictions.fold.6.step.1100.csv\n",
      "\n",
      "\n",
      "7\n",
      "0.7977715930389874\n",
      "~/reqa-predictions/fold_7/gold/relation.gold.dev.predictions.fold.7.step.2600.csv\n",
      "\n",
      "\n",
      "8\n",
      "0.8869445616734918\n",
      "~/reqa-predictions/fold_8/gold/relation.gold.dev.predictions.fold.8.step.1000.csv\n",
      "\n",
      "\n",
      "9\n",
      "0.8353253359450881\n",
      "~/reqa-predictions/fold_9/gold/relation.gold.dev.predictions.fold.9.step.1900.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.8742971188094225\n",
      "~/reqa-predictions/fold_10/gold/relation.gold.dev.predictions.fold.10.step.4000.csv\n",
      "\n",
      "\n",
      "0.8355833359926009\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Gold Templates on the dev data over all the folds.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        try:\n",
    "            prediction_file = \"~/reqa-predictions/fold_{}/gold/relation.gold.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if f1 >= max_f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(checkpoint_i, fold_i)\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.7021862131500355\n",
      "~/reqa-predictions/fold_1/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_1.dev.predictions.step.4700.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.7318462713898469\n",
      "~/reqa-predictions/fold_2/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_2.dev.predictions.step.400.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.7766533200558716\n",
      "~/reqa-predictions/fold_3/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_3.dev.predictions.step.3600.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.8437707696480834\n",
      "~/reqa-predictions/fold_4/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_4.dev.predictions.step.800.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.8300206299665337\n",
      "~/reqa-predictions/fold_5/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_5.dev.predictions.step.7900.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.8906375171815566\n",
      "~/reqa-predictions/fold_6/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_6.dev.predictions.step.700.csv\n",
      "\n",
      "\n",
      "197\n",
      "198\n",
      "199\n",
      "7\n",
      "0.7827607798234402\n",
      "~/reqa-predictions/fold_7/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_7.dev.predictions.step.2100.csv\n",
      "\n",
      "\n",
      "198\n",
      "199\n",
      "8\n",
      "0.795102231532206\n",
      "~/reqa-predictions/fold_8/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_8.dev.predictions.step.6800.csv\n",
      "\n",
      "\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "9\n",
      "0.7819016572177454\n",
      "~/reqa-predictions/fold_9/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_9.dev.predictions.step.4300.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.7755543602531488\n",
      "~/reqa-predictions/fold_10/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_10.dev.predictions.step.1600.csv\n",
      "\n",
      "\n",
      "0.7910433750218469\n"
     ]
    }
   ],
   "source": [
    "# MML-OFF-PGG performance for Relation Extraction on all the dev folds.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.qq.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        try:\n",
    "            prediction_file = \"~/reqa-predictions/fold_{}/mml-pgg-off-sim/relation.mml-pgg-off-sim.run.fold_{}.dev.predictions.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "            pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 12, 8)), axis=2))\n",
    "            pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if f1 >= max_f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(checkpoint_i)\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 concat alone 0.6868200485458184 0.6926748847477643 0.6810633587961235\n",
      "1 gold alone 0.7404285767936459 0.7531358825049224 0.728142964768295\n",
      "\n",
      "\n",
      "2 concat alone 0.5913023110477719 0.5975156340730365 0.585216877806697\n",
      "2 gold alone 0.6586987557834644 0.6757540315314027 0.6424831986356715\n",
      "\n",
      "\n",
      "3 concat alone 0.6324106523285894 0.6578301488771372 0.60888256050775\n",
      "3 gold alone 0.676931710052006 0.6806536959107133 0.6732502083282599\n",
      "\n",
      "\n",
      "4 concat alone 0.5794697498339418 0.6063706954690022 0.5548542716952589\n",
      "4 gold alone 0.6728400404740734 0.6895175863911674 0.656950210374016\n",
      "\n",
      "\n",
      "5 concat alone 0.6191377271586156 0.6268067958412001 0.6116540543838874\n",
      "5 gold alone 0.49349253129168735 0.4986497121305824 0.48844093262952004\n",
      "\n",
      "\n",
      "6 concat alone 0.5782347137534999 0.6001076131310151 0.5579002025330327\n",
      "6 gold alone 0.6607776835391415 0.6691998506324075 0.6525648747509227\n",
      "\n",
      "\n",
      "7 concat alone 0.6735910798575685 0.6934384410876097 0.6548482345074617\n",
      "7 gold alone 0.6474800154241827 0.6618318212248525 0.633737435642919\n",
      "\n",
      "\n",
      "8 concat alone 0.6046606629785962 0.6215315803731405 0.58868143336638\n",
      "8 gold alone 0.7714364531887481 0.780457536718944 0.7626215309046493\n",
      "\n",
      "\n",
      "9 concat alone 0.6017628265979826 0.6153436850776661 0.5887684922695174\n",
      "9 gold alone 0.6243678988994422 0.6462041634257861 0.6039591600991271\n",
      "\n",
      "\n",
      "10 concat alone 0.6167540970127698 0.6150992932792283 0.6184178286132765\n",
      "10 gold alone 0.6636083208337981 0.6717276147811493 0.6556829615307239\n",
      "\n",
      "\n",
      "gold alone p: 0.6727131895251928\n",
      "gold alone r: 0.6497833477664104\n",
      "gold alone f: 0.661006198628019\n",
      "concat alone p: 0.6326718771956801\n",
      "concat alone r: 0.6050287314479386\n",
      "concat alone f: 0.6184143869115154\n"
     ]
    }
   ],
   "source": [
    "# Test set performance over the 10 folds of the RE-QA dataset for the concat and gold models.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "gold_files = {\n",
    "    1: \"relation.gold.test.predictions.fold.1.step.600.csv\",\n",
    "    2: \"relation.gold.test.predictions.fold.2.step.1900.csv\",\n",
    "    3: \"relation.gold.test.predictions.fold.3.step.200.csv\",\n",
    "    4: \"relation.gold.test.predictions.fold.4.step.9500.csv\",\n",
    "    5: \"relation.gold.test.predictions.fold.5.step.15300.csv\",\n",
    "    6: \"relation.gold.test.predictions.fold.6.step.1100.csv\",\n",
    "    7: \"relation.gold.test.predictions.fold.7.step.2600.csv\",\n",
    "    8: \"relation.gold.test.predictions.fold.8.step.1000.csv\",\n",
    "    9: \"relation.gold.test.predictions.fold.9.step.1900.csv\",\n",
    "    10: \"relation.gold.test.predictions.fold.10.step.4000.csv\"\n",
    "}\n",
    "\n",
    "concat_files = {\n",
    "    1: \"relation.concat.test.predictions.fold.1.step.3600.csv\",\n",
    "    2: \"relation.concat.test.predictions.fold.2.step.4300.csv\",\n",
    "    3: \"relation.concat.test.predictions.fold.3.step.5200.csv\",\n",
    "    4: \"relation.concat.test.predictions.fold.4.step.1600.csv\",\n",
    "    5: \"relation.concat.test.predictions.fold.5.step.2900.csv\",\n",
    "    6: \"relation.concat.test.predictions.fold.6.step.1400.csv\",\n",
    "    7: \"relation.concat.test.predictions.fold.7.step.2500.csv\",\n",
    "    8: \"relation.concat.test.predictions.fold.8.step.400.csv\",\n",
    "    9: \"relation.concat.test.predictions.fold.9.step.2600.csv\",\n",
    "    10: \"relation.concat.test.predictions.fold.10.step.800.csv\"\n",
    "}\n",
    "\n",
    "gold_alone_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "concat_alone_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/test.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    fewrel_file = \"./zero-shot-extraction/relation_splits/test.{}.fewrel_format.json\".format(str(fold_i-1))\n",
    "\n",
    "    example_indices_to_consider = set()\n",
    "    with open(fewrel_file, 'r') as fin:\n",
    "        short_examples = json.load(fin)\n",
    "        for key, val in short_examples.items():\n",
    "            for row in val:\n",
    "                example_indices_to_consider.add(row[\"example_index\"])\n",
    "\n",
    "\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    gold_indices_to_consider = []\n",
    "    for i, index in enumerate(gold_indices):\n",
    "        if i in example_indices_to_consider:\n",
    "            gold_indices_to_consider.append(index)\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices_to_consider = np.array(gold_indices_to_consider)\n",
    "    \n",
    "    concat_prediction_file = \"~/may-20/fold_{}/concat/{}\".format(fold_i, concat_files[fold_i])\n",
    "    concat_pred_log_ps = pd.read_csv(concat_prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    concat_pred_log_ps = np.reshape(np.array(concat_pred_log_ps), (num_examples, 24))\n",
    "    concat_pred_ids = np.argmax(concat_pred_log_ps, axis=1)\n",
    "    concat_pred_ids_to_consider = []\n",
    "    for i, index in enumerate(concat_pred_ids):\n",
    "        if i in example_indices_to_consider:\n",
    "            concat_pred_ids_to_consider.append(index)\n",
    "    \n",
    "    concat_pred_ids_to_consider = np.array(concat_pred_ids_to_consider)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(concat_pred_ids_to_consider, gold_indices_to_consider)\n",
    "    concat_alone_p_r_f[\"f\"].append(f1)\n",
    "    concat_alone_p_r_f[\"r\"].append(avg_rec)\n",
    "    concat_alone_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(fold_i, \"concat alone\", f1, avg_prec, avg_rec)\n",
    "    \n",
    "    gold_prediction_file = \"~/may-20/fold_{}/gold/{}\".format(fold_i, gold_files[fold_i])\n",
    "    gold_pred_log_ps = pd.read_csv(gold_prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    gold_pred_log_ps = np.reshape(np.array(gold_pred_log_ps), (num_examples, 24))\n",
    "    gold_pred_ids = np.argmax(gold_pred_log_ps, axis=1)\n",
    "\n",
    "    gold_pred_ids_to_consider = []\n",
    "    for i, index in enumerate(gold_pred_ids):\n",
    "        if i in example_indices_to_consider:\n",
    "            gold_pred_ids_to_consider.append(index)\n",
    "    \n",
    "    gold_pred_ids_to_consider = np.array(gold_pred_ids_to_consider)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(gold_pred_ids_to_consider, gold_indices_to_consider)\n",
    "    print(fold_i, \"gold alone\", f1, avg_prec, avg_rec)\n",
    "    gold_alone_p_r_f[\"f\"].append(f1)\n",
    "    gold_alone_p_r_f[\"r\"].append(avg_rec)\n",
    "    gold_alone_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"gold alone p:\", np.mean(np.array(gold_alone_p_r_f[\"p\"])))\n",
    "print(\"gold alone r:\", np.mean(np.array(gold_alone_p_r_f[\"r\"])))\n",
    "print(\"gold alone f:\", np.mean(np.array(gold_alone_p_r_f[\"f\"])))\n",
    "\n",
    "print(\"concat alone p:\", np.mean(np.array(concat_alone_p_r_f[\"p\"])))\n",
    "print(\"concat alone r:\", np.mean(np.array(concat_alone_p_r_f[\"r\"])))\n",
    "print(\"concat alone f:\", np.mean(np.array(concat_alone_p_r_f[\"f\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 mml 0.7324313594407584 0.7347101443139104 0.7301666666666667\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 692139 into shape (6000,24,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6217db65b1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmml_pred_log_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmml_prediction_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer_log_p\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mpred_log_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmml_pred_log_ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mpred_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_log_ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mavg_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_macro_PRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 692139 into shape (6000,24,8)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mml_files = {\n",
    "    1: \"relation.mml-pgg-off-sim.run.fold_1.test.predictions.step.4700.csv\",\n",
    "    2: \"relation.mml-pgg-off-sim.run.fold_2.test.predictions.step.400.csv\",\n",
    "    3: \"relation.mml-pgg-off-sim.run.fold_3.test.predictions.step.3600.csv\",\n",
    "    4: \"relation.mml-pgg-off-sim.run.fold_4.test.predictions.step.800.csv\",\n",
    "    5: \"relation.mml-pgg-off-sim.run.fold_5.test.predictions.step.7900.csv\",\n",
    "    6: \"relation.mml-pgg-off-sim.run.fold_6.test.predictions.step.700.csv\",\n",
    "    7: \"relation.mml-pgg-off-sim.run.fold_7.test.predictions.step.2100.csv\",\n",
    "    8: \"relation.mml-pgg-off-sim.run.fold_8.test.predictions.step.6800.csv\",\n",
    "    9: \"relation.mml-pgg-off-sim.run.fold_9.test.predictions.step.4300.csv\",\n",
    "    10: \"relation.mml-pgg-off-sim.run.fold_10.test.predictions.step.1600.csv\"\n",
    "}\n",
    "\n",
    "mml_pgg_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/test.{}.qq.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "    \n",
    "    mml_prediction_file = \"~/may-20/fold_{}/{}\".format(fold_i, mml_files[fold_i])\n",
    "    mml_pred_log_ps = pd.read_csv(mml_prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "\n",
    "    pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(mml_pred_log_ps)), (num_examples, 24, 8)), axis=2))\n",
    "    pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "    mml_pgg_p_r_f[\"f\"].append(f1)\n",
    "    mml_pgg_p_r_f[\"r\"].append(avg_rec)\n",
    "    mml_pgg_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(fold_i, \"mml pgg off\", f1, avg_prec, avg_rec)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"mml pgg off p:\", np.mean(np.array(mml_pgg_p_r_f[\"p\"])))\n",
    "print(\"mml pgg off r:\", np.mean(np.array(mml_pgg_p_r_f[\"r\"])))\n",
    "print(\"mml pgg off f:\", np.mean(np.array(mml_pgg_p_r_f[\"f\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
