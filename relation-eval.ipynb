{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_macro_PRF(predicted_idx, gold_idx, i=-1, empty_label=None):\n",
    "    '''\n",
    "    This evaluation function follows work from Sorokin and Gurevych(https://www.aclweb.org/anthology/D17-1188.pdf)\n",
    "    code borrowed from the following link:\n",
    "    https://github.com/UKPLab/emnlp2017-relation-extraction/blob/master/relation_extraction/evaluation/metrics.py\n",
    "    '''\n",
    "    if i == -1:\n",
    "        i = len(predicted_idx)\n",
    "\n",
    "    complete_rel_set = set(gold_idx) - {empty_label}\n",
    "    avg_prec = 0.0\n",
    "    avg_rec = 0.0\n",
    "\n",
    "    for r in complete_rel_set:\n",
    "        r_indices = (predicted_idx[:i] == r)\n",
    "        tp = len((predicted_idx[:i][r_indices] == gold_idx[:i][r_indices]).nonzero()[0])\n",
    "        tp_fp = len(r_indices.nonzero()[0])\n",
    "        tp_fn = len((gold_idx == r).nonzero()[0])\n",
    "        prec = (tp / tp_fp) if tp_fp > 0 else 0\n",
    "        rec = tp / tp_fn\n",
    "        avg_prec += prec\n",
    "        avg_rec += rec\n",
    "    f1 = 0\n",
    "    avg_prec = avg_prec / len(set(predicted_idx[:i]))\n",
    "    avg_rec = avg_rec / len(complete_rel_set)\n",
    "    if (avg_rec+avg_prec) > 0:\n",
    "        f1 = 2.0 * avg_prec * avg_rec / (avg_prec + avg_rec)\n",
    "\n",
    "    return avg_prec, avg_rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.6645079529607614\n",
      "~/may-20/fold_1/concat/relation.concat.dev.predictions.fold.1.step.3600.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.7355692801363015\n",
      "~/may-20/fold_2/concat/relation.concat.dev.predictions.fold.2.step.4300.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.816466070295921\n",
      "~/may-20/fold_3/concat/relation.concat.dev.predictions.fold.3.step.5200.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.820538067780762\n",
      "~/may-20/fold_4/concat/relation.concat.dev.predictions.fold.4.step.1600.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.7970665456384882\n",
      "~/may-20/fold_5/concat/relation.concat.dev.predictions.fold.5.step.2900.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.9100498471715361\n",
      "~/may-20/fold_6/concat/relation.concat.dev.predictions.fold.6.step.1400.csv\n",
      "\n",
      "\n",
      "7\n",
      "0.7789862082105365\n",
      "~/may-20/fold_7/concat/relation.concat.dev.predictions.fold.7.step.2500.csv\n",
      "\n",
      "\n",
      "8\n",
      "0.7585498509710629\n",
      "~/may-20/fold_8/concat/relation.concat.dev.predictions.fold.8.step.400.csv\n",
      "\n",
      "\n",
      "9\n",
      "0.7690369496615103\n",
      "~/may-20/fold_9/concat/relation.concat.dev.predictions.fold.9.step.2600.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.7394406760740089\n",
      "~/may-20/fold_10/concat/relation.concat.dev.predictions.fold.10.step.800.csv\n",
      "\n",
      "\n",
      "0.7790211448900889\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Concat Templates on the dev data over all the folds.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.concat.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        prediction_file = \"~/may-20/fold_{}/concat/relation.concat.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "        pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "        pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "        avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "        if f1 >= max_f1:\n",
    "            max_f1 = f1\n",
    "            max_file = prediction_file\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 1\n",
      "159 1\n",
      "162 1\n",
      "163 1\n",
      "164 1\n",
      "165 1\n",
      "167 1\n",
      "168 1\n",
      "169 1\n",
      "171 1\n",
      "1\n",
      "0.7958029874558785\n",
      "~/may-20/fold_1/gold/relation.gold.dev.predictions.fold.1.step.600.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.8055480874453981\n",
      "~/may-20/fold_2/gold/relation.gold.dev.predictions.fold.2.step.1900.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.8088784230714176\n",
      "~/may-20/fold_3/gold/relation.gold.dev.predictions.fold.3.step.200.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.7950547270773886\n",
      "~/may-20/fold_4/gold/relation.gold.dev.predictions.fold.4.step.9500.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.8218222460881007\n",
      "~/may-20/fold_5/gold/relation.gold.dev.predictions.fold.5.step.15300.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.9343882793208368\n",
      "~/may-20/fold_6/gold/relation.gold.dev.predictions.fold.6.step.1100.csv\n",
      "\n",
      "\n",
      "7\n",
      "0.7977715930389874\n",
      "~/may-20/fold_7/gold/relation.gold.dev.predictions.fold.7.step.2600.csv\n",
      "\n",
      "\n",
      "8\n",
      "0.8869445616734918\n",
      "~/may-20/fold_8/gold/relation.gold.dev.predictions.fold.8.step.1000.csv\n",
      "\n",
      "\n",
      "9\n",
      "0.8353253359450881\n",
      "~/may-20/fold_9/gold/relation.gold.dev.predictions.fold.9.step.1900.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.8742971188094225\n",
      "~/may-20/fold_10/gold/relation.gold.dev.predictions.fold.10.step.4000.csv\n",
      "\n",
      "\n",
      "0.8355833359926009\n"
     ]
    }
   ],
   "source": [
    "# Eval of the RE-QA using the Gold Templates on the dev data over all the folds.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        try:\n",
    "            prediction_file = \"~/may-20/fold_{}/gold/relation.gold.dev.predictions.fold.{}.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 12)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if f1 >= max_f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(checkpoint_i, fold_i)\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.7021862131500355\n",
      "~/may-20/fold_1/relation.mml-pgg-off-sim.run.fold_1.dev.predictions.step.4700.csv\n",
      "\n",
      "\n",
      "2\n",
      "0.7318462713898469\n",
      "~/may-20/fold_2/relation.mml-pgg-off-sim.run.fold_2.dev.predictions.step.400.csv\n",
      "\n",
      "\n",
      "3\n",
      "0.7766533200558716\n",
      "~/may-20/fold_3/relation.mml-pgg-off-sim.run.fold_3.dev.predictions.step.3600.csv\n",
      "\n",
      "\n",
      "4\n",
      "0.8437707696480834\n",
      "~/may-20/fold_4/relation.mml-pgg-off-sim.run.fold_4.dev.predictions.step.800.csv\n",
      "\n",
      "\n",
      "5\n",
      "0.8300206299665337\n",
      "~/may-20/fold_5/relation.mml-pgg-off-sim.run.fold_5.dev.predictions.step.7900.csv\n",
      "\n",
      "\n",
      "6\n",
      "0.8906375171815566\n",
      "~/may-20/fold_6/relation.mml-pgg-off-sim.run.fold_6.dev.predictions.step.700.csv\n",
      "\n",
      "\n",
      "197\n",
      "198\n",
      "199\n",
      "7\n",
      "0.7827607798234402\n",
      "~/may-20/fold_7/relation.mml-pgg-off-sim.run.fold_7.dev.predictions.step.2100.csv\n",
      "\n",
      "\n",
      "198\n",
      "199\n",
      "8\n",
      "0.795102231532206\n",
      "~/may-20/fold_8/relation.mml-pgg-off-sim.run.fold_8.dev.predictions.step.6800.csv\n",
      "\n",
      "\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "9\n",
      "0.7819016572177454\n",
      "~/may-20/fold_9/relation.mml-pgg-off-sim.run.fold_9.dev.predictions.step.4300.csv\n",
      "\n",
      "\n",
      "10\n",
      "0.7755543602531488\n",
      "~/may-20/fold_10/relation.mml-pgg-off-sim.run.fold_10.dev.predictions.step.1600.csv\n",
      "\n",
      "\n",
      "0.7910433750218469\n"
     ]
    }
   ],
   "source": [
    "# MML-OFF-PGG performance for Relation Extraction on all the dev folds.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mean_f1 = 0.0\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/dev.{}.qq.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 12))\n",
    "\n",
    "    num_examples = len(correct_indices) // 12\n",
    "    gold_indices = np.array(gold_indices)\n",
    "\n",
    "    max_file = None\n",
    "    max_f1 = 0.0\n",
    "    for checkpoint_i in range(1, 200, 1):\n",
    "        try:\n",
    "            prediction_file = \"~/may-20/fold_{}/relation.mml-pgg-off-sim.run.fold_{}.dev.predictions.step.{}.csv\".format(str(fold_i), str(fold_i), str(100 * checkpoint_i))\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "            pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(pred_log_ps)), (num_examples, 12, 8)), axis=2))\n",
    "            pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if f1 >= max_f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(checkpoint_i)\n",
    "\n",
    "    print(fold_i)\n",
    "    print(max_f1)\n",
    "    print(max_file)\n",
    "    print(\"\\r\\n\")\n",
    "    mean_f1 += max_f1\n",
    "\n",
    "print(mean_f1/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 concat alone 0.6851779135044868 0.689066127748157 0.6813333333333333\n",
      "1 gold alone 0.7433432938934399 0.7562889888849941 0.7308333333333333\n",
      "\n",
      "\n",
      "2 concat alone 0.5901669782971629 0.5989194167218461 0.5816666666666667\n",
      "2 gold alone 0.6642954078337273 0.6842181964463796 0.6455000000000001\n",
      "\n",
      "\n",
      "3 concat alone 0.6373039703281808 0.6626408187363189 0.6138333333333333\n",
      "3 gold alone 0.681873757976071 0.6871616100666138 0.6766666666666667\n",
      "\n",
      "\n",
      "4 concat alone 0.5858742474657468 0.6150594189021233 0.5593333333333333\n",
      "4 gold alone 0.6824352310400019 0.7000704484368208 0.6656666666666667\n",
      "\n",
      "\n",
      "5 concat alone 0.622864337200164 0.6281502269876816 0.6176666666666667\n",
      "5 gold alone 0.5005601199498438 0.5060723602043087 0.4951666666666666\n",
      "\n",
      "\n",
      "6 concat alone 0.5752377444829445 0.5954721054962936 0.5563333333333333\n",
      "6 gold alone 0.6651754396604047 0.6719876078130175 0.6585\n",
      "\n",
      "\n",
      "7 concat alone 0.6683183924580341 0.6834597978850874 0.6538333333333333\n",
      "7 gold alone 0.6543720994745615 0.6683140048618551 0.641\n",
      "\n",
      "\n",
      "8 concat alone 0.5976466905286616 0.6104892396256113 0.5853333333333334\n",
      "8 gold alone 0.76734257561607 0.7774442974442916 0.7575\n",
      "\n",
      "\n",
      "9 concat alone 0.6010214403439702 0.6135438179429739 0.589\n",
      "9 gold alone 0.6226748483257762 0.6471308376432654 0.6\n",
      "\n",
      "\n",
      "10 concat alone 0.6176894076003205 0.6142508628482145 0.6211666666666668\n",
      "10 gold alone 0.6597456987087056 0.6692580091015435 0.6505\n",
      "\n",
      "\n",
      "gold alone p: 0.6767946360903091\n",
      "gold alone r: 0.6521333333333332\n",
      "gold alone f: 0.6641818472478602\n",
      "concat alone p: 0.6311051832894308\n",
      "concat alone r: 0.6059500000000001\n",
      "concat alone f: 0.6181301122209673\n"
     ]
    }
   ],
   "source": [
    "# Test set performance over the 10 folds of the RE-QA dataset for the concat and gold models.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gold_files = {\n",
    "    1: \"relation.gold.test.predictions.fold.1.step.600.csv\",\n",
    "    2: \"relation.gold.test.predictions.fold.2.step.1900.csv\",\n",
    "    3: \"relation.gold.test.predictions.fold.3.step.200.csv\",\n",
    "    4: \"relation.gold.test.predictions.fold.4.step.9500.csv\",\n",
    "    5: \"relation.gold.test.predictions.fold.5.step.15300.csv\",\n",
    "    6: \"relation.gold.test.predictions.fold.6.step.1100.csv\",\n",
    "    7: \"relation.gold.test.predictions.fold.7.step.2600.csv\",\n",
    "    8: \"relation.gold.test.predictions.fold.8.step.1000.csv\",\n",
    "    9: \"relation.gold.test.predictions.fold.9.step.1900.csv\",\n",
    "    10: \"relation.gold.test.predictions.fold.10.step.4000.csv\"\n",
    "}\n",
    "\n",
    "concat_files = {\n",
    "    1: \"relation.concat.test.predictions.fold.1.step.3600.csv\",\n",
    "    2: \"relation.concat.test.predictions.fold.2.step.4300.csv\",\n",
    "    3: \"relation.concat.test.predictions.fold.3.step.5200.csv\",\n",
    "    4: \"relation.concat.test.predictions.fold.4.step.1600.csv\",\n",
    "    5: \"relation.concat.test.predictions.fold.5.step.2900.csv\",\n",
    "    6: \"relation.concat.test.predictions.fold.6.step.1400.csv\",\n",
    "    7: \"relation.concat.test.predictions.fold.7.step.2500.csv\",\n",
    "    8: \"relation.concat.test.predictions.fold.8.step.400.csv\",\n",
    "    9: \"relation.concat.test.predictions.fold.9.step.2600.csv\",\n",
    "    10: \"relation.concat.test.predictions.fold.10.step.800.csv\"\n",
    "}\n",
    "\n",
    "gold_alone_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "concat_alone_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/test.{}.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "    \n",
    "    concat_prediction_file = \"~/may-20/fold_{}/concat/{}\".format(fold_i, concat_files[fold_i])\n",
    "    concat_pred_log_ps = pd.read_csv(concat_prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    concat_pred_log_ps = np.reshape(np.array(concat_pred_log_ps), (num_examples, 24))\n",
    "    concat_pred_ids = np.argmax(concat_pred_log_ps, axis=1)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(concat_pred_ids, gold_indices)\n",
    "    concat_alone_p_r_f[\"f\"].append(f1)\n",
    "    concat_alone_p_r_f[\"r\"].append(avg_rec)\n",
    "    concat_alone_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(fold_i, \"concat alone\", f1, avg_prec, avg_rec)\n",
    "    \n",
    "    gold_prediction_file = \"~/may-20/fold_{}/gold/{}\".format(fold_i, gold_files[fold_i])\n",
    "    gold_pred_log_ps = pd.read_csv(gold_prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "    gold_pred_log_ps = np.reshape(np.array(gold_pred_log_ps), (num_examples, 24))\n",
    "    gold_pred_ids = np.argmax(gold_pred_log_ps, axis=1)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(gold_pred_ids, gold_indices)\n",
    "    print(fold_i, \"gold alone\", f1, avg_prec, avg_rec)\n",
    "    gold_alone_p_r_f[\"f\"].append(f1)\n",
    "    gold_alone_p_r_f[\"r\"].append(avg_rec)\n",
    "    gold_alone_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"gold alone p:\", np.mean(np.array(gold_alone_p_r_f[\"p\"])))\n",
    "print(\"gold alone r:\", np.mean(np.array(gold_alone_p_r_f[\"r\"])))\n",
    "print(\"gold alone f:\", np.mean(np.array(gold_alone_p_r_f[\"f\"])))\n",
    "\n",
    "print(\"concat alone p:\", np.mean(np.array(concat_alone_p_r_f[\"p\"])))\n",
    "print(\"concat alone r:\", np.mean(np.array(concat_alone_p_r_f[\"r\"])))\n",
    "print(\"concat alone f:\", np.mean(np.array(concat_alone_p_r_f[\"f\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 mml 0.7324313594407584 0.7347101443139104 0.7301666666666667\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/snajafi/may-20/fold_2/relation.mml-pgg-off-sim.run.fold_2.test.predictions.step.400.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6217db65b1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmml_prediction_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"~/may-20/fold_{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmml_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmml_pred_log_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmml_prediction_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer_log_p\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mpred_log_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmml_pred_log_ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/snajafi/may-20/fold_2/relation.mml-pgg-off-sim.run.fold_2.test.predictions.step.400.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mml_files = {\n",
    "    1: \"relation.mml-pgg-off-sim.run.fold_1.test.predictions.step.4700.csv\",\n",
    "    2: \"relation.mml-pgg-off-sim.run.fold_2.test.predictions.step.400.csv\",\n",
    "    3: \"relation.mml-pgg-off-sim.run.fold_3.test.predictions.step.3600.csv\",\n",
    "    4: \"relation.mml-pgg-off-sim.run.fold_4.test.predictions.step.800.csv\",\n",
    "    5: \"relation.mml-pgg-off-sim.run.fold_5.test.predictions.step.7900.csv\",\n",
    "    6: \"relation.mml-pgg-off-sim.run.fold_6.test.predictions.step.700.csv\",\n",
    "    7: \"relation.mml-pgg-off-sim.run.fold_7.test.predictions.step.2100.csv\",\n",
    "    8: \"relation.mml-pgg-off-sim.run.fold_8.test.predictions.step.6800.csv\",\n",
    "    9: \"relation.mml-pgg-off-sim.run.fold_9.test.predictions.step.4300.csv\",\n",
    "    10: \"relation.mml-pgg-off-sim.run.fold_10.test.predictions.step.1600.csv\"\n",
    "}\n",
    "\n",
    "mml_mml_p_r_f = {'f': [], 'r': [], 'p': []}\n",
    "\n",
    "for fold_i in range(1, 11, 1):\n",
    "    gold_file = \"./zero-shot-extraction/relation_splits/test.{}.qq.relation_data.csv\".format(str(fold_i-1))\n",
    "    gold_indices = []\n",
    "    df = pd.read_csv(gold_file, sep=',')\n",
    "    correct_indices = df[\"correct_indices\"].tolist()\n",
    "    for i, index in enumerate(correct_indices):\n",
    "        if index:\n",
    "            gold_indices.append(int(i % 24))\n",
    "\n",
    "    num_examples = len(correct_indices) // 24\n",
    "    gold_indices = np.array(gold_indices)\n",
    "    \n",
    "    mml_prediction_file = \"~/may-20/fold_{}/{}\".format(fold_i, mml_files[fold_i])\n",
    "    mml_pred_log_ps = pd.read_csv(mml_prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "\n",
    "    pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(mml_pred_log_ps)), (num_examples, 24, 8)), axis=2))\n",
    "    pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "    avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "    mml_mml_p_r_f[\"f\"].append(f1)\n",
    "    mml_mml_p_r_f[\"r\"].append(avg_rec)\n",
    "    mml_mml_p_r_f[\"p\"].append(avg_prec)\n",
    "    print(fold_i, \"mml\", f1, avg_prec, avg_rec)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"mml p:\", np.mean(np.array(mml_mml_p_r_f[\"p\"])))\n",
    "print(\"mml r:\", np.mean(np.array(mml_mml_p_r_f[\"r\"])))\n",
    "print(\"mml f:\", np.mean(np.array(mml_mml_p_r_f[\"f\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ~/may-29/fewrl/concat_run_1/relation.concat.run.0.dev.predictions.step.600.csv 0.5478163622378379\n",
      "2 ~/may-29/fewrl/concat_run_2/relation.concat.run.0.dev.predictions.step.200.csv 0.4564517056171136\n",
      "3 ~/may-29/fewrl/concat_run_3/relation.concat.run.0.dev.predictions.step.800.csv 0.6302340196983017\n",
      "4 ~/may-29/fewrl/concat_run_4/relation.concat.run.1.dev.predictions.step.1000.csv 0.7054889125319359\n",
      "5 ~/may-29/fewrl/concat_run_5/relation.concat.run.0.dev.predictions.step.800.csv 0.6725607501052342\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for concat model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/val_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/val_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/val_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/val_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/val_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {   \n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/val_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/val_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/val_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/val_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/val_data_1300.csv\",\n",
    "}\n",
    "\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [\"~/may-29/fewrl/concat_run_{}/relation.concat.run.0.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/concat_run_{}/relation.concat.run.1.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/concat_run_{}/relation.concat.run.2.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/concat_run_{}/relation.concat.run.3.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 5)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if max_f1 <= f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "    print(run_id, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.29516385929798367 0.3134285714285714 0.3040221405536262\n",
      "2 0.3378839007851588 0.3417142857142857 0.33978829874717886\n",
      "3 0.2634032669335266 0.2602857142857143 0.26183521111849073\n",
      "4 0.27979338063663967 0.2968571428571429 0.2880727934240033\n",
      "5 0.31482565279348057 0.3158095238095238 0.31531682081959495\n",
      "mean_p 0.2982140120893578\n",
      "mean_r 0.30561904761904757\n",
      "mean_f 0.3018070529325788\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for concat model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/test_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/test_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/test_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/test_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/test_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/test_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/test_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/test_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/test_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/test_data_1300.csv\",\n",
    "}\n",
    "test_files = {\n",
    "    1: \"~/may-29/fewrl/concat_run_1/relation.concat.run.0.test.predictions.step.600.csv\",\n",
    "    2: \"~/may-29/fewrl/concat_run_2/relation.concat.run.0.test.predictions.step.200.csv\",\n",
    "    3: \"~/may-29/fewrl/concat_run_3/relation.concat.run.0.test.predictions.step.800.csv\",\n",
    "    4: \"~/may-29/fewrl/concat_run_4/relation.concat.run.1.test.predictions.step.1000.csv\",\n",
    "    5: \"~/may-29/fewrl/concat_run_5/relation.concat.run.0.test.predictions.step.800.csv\",\n",
    "}\n",
    "\n",
    "mean_f1 = 0.0\n",
    "mean_p = 0.0\n",
    "mean_r = 0.0\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [test_files[run_id]]\n",
    "\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_ids = np.argmax(np.reshape(np.array(pred_log_ps), (num_examples, 15)), axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            print(run_id, avg_prec, avg_rec, f1)\n",
    "            mean_f1 += f1\n",
    "            mean_p += avg_prec\n",
    "            mean_r += avg_rec\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "mean_f1 /= 5\n",
    "mean_p /= 5\n",
    "mean_r /= 5\n",
    "print(\"mean_p\", mean_p)\n",
    "print(\"mean_r\", mean_r)\n",
    "print(\"mean_f\", mean_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ~/may-29/fewrl/run_1/relation.mml-pgg-off-sim.0.dev.predictions.step.1800.csv 0.6515373806104654\n",
      "2 ~/may-29/fewrl/run_2/relation.mml-pgg-off-sim.0.dev.predictions.step.800.csv 0.45259672477504315\n",
      "3 ~/may-29/fewrl/run_3/relation.mml-pgg-off-sim.0.dev.predictions.step.2000.csv 0.5664980244133372\n",
      "4 ~/may-29/fewrl/run_4/relation.mml-pgg-off-sim.2.dev.predictions.step.2200.csv 0.6782900293769715\n",
      "5 ~/may-29/fewrl/run_5/relation.mml-pgg-off-sim.2.dev.predictions.step.1200.csv 0.6436118141580857\n"
     ]
    }
   ],
   "source": [
    "# Dev prediction for off-mml-pgg model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/val_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/val_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/val_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/val_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/val_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {   \n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/val_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/val_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/val_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/val_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/val_data_1300.csv\",\n",
    "}\n",
    "\n",
    "for run_id in range(1, 6, 1):\n",
    "    prediction_files = [\"~/may-29/fewrl/run_{}/relation.mml-pgg-off-sim.0.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/run_{}/relation.mml-pgg-off-sim.1.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/run_{}/relation.mml-pgg-off-sim.2.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "    prediction_files += [\"~/may-29/fewrl/run_{}/relation.mml-pgg-off-sim.3.dev.predictions.step.{}.csv\".format(run_id, 200 * i) for i in range(1, 13, 1)]\n",
    "\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 5\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 5)), axis=1)\n",
    "\n",
    "    max_f1 = 0.0\n",
    "    max_file = \"None\"\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            mml_pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"answer_log_p\"].tolist()\n",
    "            pred_log_ps = np.log(np.mean(np.reshape(np.exp(np.array(mml_pred_log_ps)), (num_examples, 5, 8)), axis=2))\n",
    "            pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            if max_f1 <= f1:\n",
    "                max_f1 = f1\n",
    "                max_file = prediction_file\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "    print(run_id, max_file, max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/may-29/fewrl/run_1/relation.mml-pgg-off-sim.0.test.predictions.step.1600.csv 0.2837856810621898 0.2952380952380953 0.2893986304603681\n",
      "~/may-29/fewrl/run_2/relation.mml-pgg-off-sim.1.test.predictions.step.1200.csv 0.3006521275244626 0.28704761904761905 0.29369240967305127\n",
      "~/may-29/fewrl/run_3/relation.mml-pgg-off-sim.1.test.predictions.step.1400.csv 0.24292775046213774 0.22819047619047622 0.23532861146852352\n",
      "~/may-29/fewrl/run_4/relation.mml-pgg-off-sim.0.test.predictions.step.600.csv 0.19035572728301794 0.19876190476190475 0.19446801594815583\n",
      "mean_p 0.25443032158295203\n",
      "mean_r 0.2523095238095238\n",
      "mean_f 0.25322191688752466\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for off-mml-pgg model on the fewrel dataset.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "id_files = {\n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/test_ids_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/test_ids_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/test_ids_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/test_ids_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/test_ids_1300.csv\"\n",
    "}\n",
    "gold_files = {   \n",
    "    1: \"~/codes/QA-ZRE/fewrl_data/test_data_12321.csv\",\n",
    "    2: \"~/codes/QA-ZRE/fewrl_data/test_data_943.csv\",\n",
    "    3: \"~/codes/QA-ZRE/fewrl_data/test_data_111.csv\",\n",
    "    4: \"~/codes/QA-ZRE/fewrl_data/test_data_300.csv\",\n",
    "    5: \"~/codes/QA-ZRE/fewrl_data/test_data_1300.csv\",\n",
    "}\n",
    "\n",
    "test_files = {\n",
    "    1: \"~/may-29/fewrl/run_1/relation.mml-pgg-off-sim.0.test.predictions.step.1800.csv\",\n",
    "    2: \"~/may-29/fewrl/run_2/relation.mml-pgg-off-sim.0.test.predictions.step.800.csv\",\n",
    "    3: \"~/may-29/fewrl/run_3/relation.mml-pgg-off-sim.0.test.predictions.step.2000.csv\",\n",
    "    4: \"~/may-29/fewrl/run_4/relation.mml-pgg-off-sim.2.test.predictions.step.2200.csv\",\n",
    "    5: \"~/may-29/fewrl/run_5/relation.mml-pgg-off-sim.2.test.predictions.step.1200.csv\",\n",
    "}\n",
    "\n",
    "mean_f1 = 0.0\n",
    "mean_p = 0.0\n",
    "mean_r = 0.0\n",
    "for run_id in range(1, 5, 1):\n",
    "    prediction_files = [test_files[run_id]]\n",
    "    df = pd.read_csv(gold_files[run_id], sep=',')\n",
    "    ids = {val:i for i, val in enumerate(pd.read_csv(id_files[run_id], sep=',')[\"relation_ids\"].tolist())}\n",
    "    actual_ids = df[\"actual_ids\"].tolist()\n",
    "    num_examples = len(actual_ids) // 15\n",
    "\n",
    "    gold_indices = []\n",
    "    for each_relation_id in actual_ids:\n",
    "        gold_indices.append(ids[each_relation_id])\n",
    "\n",
    "    gold_indices = np.max(np.reshape(np.array(gold_indices), (num_examples, 15)), axis=1)\n",
    "    for prediction_file in prediction_files:\n",
    "        try:\n",
    "            mml_pred_log_ps = pd.read_csv(prediction_file, sep=',')[\"relation_log_p\"].tolist()\n",
    "            pred_log_ps = np.log(np.sum(np.reshape(np.exp(np.array(mml_pred_log_ps)), (num_examples, 15, 8)), axis=2))\n",
    "            pred_ids = np.argmax(pred_log_ps, axis=1)\n",
    "            avg_prec, avg_rec, f1 = compute_macro_PRF(pred_ids, gold_indices)\n",
    "            mean_f1 += f1\n",
    "            mean_p += avg_prec\n",
    "            mean_r += avg_rec\n",
    "            print(prediction_file, avg_prec, avg_rec, f1)\n",
    "        except:\n",
    "            print(prediction_file)\n",
    "\n",
    "mean_f1 /= 4\n",
    "mean_p /= 4\n",
    "mean_r /= 4\n",
    "print(\"mean_p\", mean_p)\n",
    "print(\"mean_r\", mean_r)\n",
    "print(\"mean_f\", mean_f1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
